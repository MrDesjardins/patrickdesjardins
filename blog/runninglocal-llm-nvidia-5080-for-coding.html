<!DOCTYPE html><html lang="en" class="layout_htmlstyle__PseMz"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/4cb872a2a77e328a.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/dabd5e64a469b0e1.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/be8a59717d6d5849.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/97e0a79122e618e4.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-3bbba27772baeadb.js"/><script src="/_next/static/chunks/2200cc46-73d9c2dcf2e9794f.js" async=""></script><script src="/_next/static/chunks/657-3551bff086733983.js" async=""></script><script src="/_next/static/chunks/main-app-67ffb56f87b9fb11.js" async=""></script><script src="/_next/static/chunks/156-2b9f703633e98ef7.js" async=""></script><script src="/_next/static/chunks/836-7e37630a3372363c.js" async=""></script><script src="/_next/static/chunks/app/blog/%5Bslug%5D/page-2829e3c199d313ca.js" async=""></script><title>Patrick Desjardins Blog - Running Local LLM on a Nvidia 5080 for Coding</title><meta name="description" content="Running Local LLM on a Nvidia 5080 for Coding"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="layout_bodystyle__4ncsS"><div class="layout_blogbodystyle___Uc1w"><div class="BlogBody_BlogBody__600mT"><header class="BlogBody_siteTitle__f7uyb">Patrick Desjardins Blog</header><nav><ul class="BlogBody_navLinks__ZV12t"><li class="BlogBody_navLinkItem__Pml2e"><a class="BlogBody_navLinkText__ZtH2y" href="/">Main Page</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog">Blog</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/search">Search</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2026">2026</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2025">2025</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2024">2024</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2023">2023</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2022">2022</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2021">2021</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2020">2020</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2019">2019</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2018">2018</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2017">2017</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2016">2016</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2015">2015</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2014">2014</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2013">2013</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2012">2012</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2011">2011</a></li></ul></nav><div class="BlogBody_blogPictureContainer__IAbPL"><img alt="Patrick Desjardins picture from a conference" loading="lazy" width="800" height="260" decoding="async" data-nimg="1" class="BlogBody_blogTopPicture__L6lao" style="color:transparent" src="/images/backgrounds/patrickdesjardins_conference_bw.webp"/></div><main class="BlogBody_main__XrdKY"><h1 class="BlogBody_heading__bYRBe">Running Local LLM on a Nvidia 5080 for Coding</h1><div class="Page_blogPostContainer__AUIcf"><p class="Page_blogPostDate__wVWWB">Posted on: <!-- -->2026-02-09</p><h1>Goal</h1>
<p>Few weekends ago, I wanted to see what would be the best model of coding that I could run locally on my Intel 9 with 32 gig of ram and my Nvidia 5080 with 8gig of vram. The idea was to run <a href="https://opencode.ai/">Open Code</a> to QWEN 3.0 to have a local Claude. The result was impressive in term of how fast the response occured but the final product wasn&#x27;t the quality of Claude.</p>
<h1>How to do it?</h1>
<p>I started with QWEN 2.5 and the result was horrible in term of connection with tools like simply reading and writing files. It was fine with general question but that wasn&#x27;t the goal.</p>
<p>Moving to Qwen3-8B-AWQ did the job but with some tweaking, otherwise it was crashing or returning response too slow.</p>
<p>Installation:</p>
<pre class="language-plaintext"><code class="language-plaintext code-highlight"><span class="code-line">sh
</span><span class="code-line">nvidia-smi
</span><span class="code-line">pip install --upgrade pip
</span><span class="code-line">pip install torch torchvision torchaudio \
</span><span class="code-line">  --index-url https://download.pytorch.org/whl/cu121
</span><span class="code-line">pip install vllm
</span><span class="code-line">pip install autoawq
</span><span class="code-line">pip install huggingface_hub
</span><span class="code-line">huggingface-cli login
</span></code></pre>
<p>Everytime to use:</p>
<pre class="language-sh"><code class="language-sh code-highlight"><span class="code-line"><span class="token builtin class-name">cd</span> ~/llm/llm
</span><span class="code-line">pyenv activate vllm
</span><span class="code-line">
</span><span class="code-line"><span class="token builtin class-name">unset</span> VLLM_ATTENTION_BACKEND
</span><span class="code-line"><span class="token builtin class-name">unset</span> VLLM_USE_FLASHINFER_SAMPLER
</span><span class="code-line">
</span><span class="code-line"><span class="token function">pkill</span> <span class="token parameter variable">-f</span> vllm
</span><span class="code-line">
</span><span class="code-line">vllm serve <span class="token punctuation">\</span>
</span><span class="code-line">  Qwen/Qwen3-8B-AWQ <span class="token punctuation">\</span>
</span><span class="code-line">  <span class="token parameter variable">--quantization</span> awq <span class="token punctuation">\</span>
</span><span class="code-line">  <span class="token parameter variable">--dtype</span> float16 <span class="token punctuation">\</span>
</span><span class="code-line">  --gpu-memory-utilization <span class="token number">0.9</span> <span class="token punctuation">\</span>
</span><span class="code-line">  --max-model-len <span class="token number">32768</span> <span class="token punctuation">\</span>
</span><span class="code-line">  <span class="token parameter variable">--port</span> <span class="token number">7555</span> <span class="token punctuation">\</span>
</span><span class="code-line">  --api-key <span class="token string">&quot;opencode_local&quot;</span> <span class="token punctuation">\</span>
</span><span class="code-line">  --enable-auto-tool-choice <span class="token punctuation">\</span>
</span><span class="code-line">  --tool-call-parser hermes <span class="token punctuation">\</span>
</span><span class="code-line">  --reasoning-parser qwen3
</span></code></pre>
<p>Loading everything takes less than 30 seconds:</p>
<pre class="language-plaintext"><code class="language-plaintext code-highlight"><span class="code-line">(EngineCore_DP0 pid=36318) INFO 02-03 19:53:24 [default_loader.py:291] Loading weights took 4.14 seconds
</span><span class="code-line">(EngineCore_DP0 pid=36318) INFO 02-03 19:53:24 [gpu_model_runner.py:3905] Model loading took 5.71 GiB memory and 5.326229 seconds
</span><span class="code-line">(EngineCore_DP0 pid=36318) INFO 02-03 19:53:30 [backends.py:644] Using cache directory: /home/miste/.cache/vllm/torch_compile_cache/252055f4c9/rank_0_0/backbone for vLLM&#x27;s torch.compile
</span><span class="code-line">(EngineCore_DP0 pid=36318) INFO 02-03 19:53:30 [backends.py:704] Dynamo bytecode transform time: 5.01 s
</span><span class="code-line">(EngineCore_DP0 pid=36318) INFO 02-03 19:53:35 [backends.py:226] Directly load the compiled graph(s) for compile range (1, 2048) from the cache, took 1.098 s
</span><span class="code-line">(EngineCore_DP0 pid=36318) INFO 02-03 19:53:35 [monitor.py:34] torch.compile takes 6.11 s in total
</span><span class="code-line">(EngineCore_DP0 pid=36318) INFO 02-03 19:53:36 [gpu_worker.py:358] Available KV cache memory: 7.19 GiB
</span><span class="code-line">(EngineCore_DP0 pid=36318) INFO 02-03 19:53:36 [kv_cache_utils.py:1305] GPU KV cache size: 52,368 tokens
</span><span class="code-line">(EngineCore_DP0 pid=36318) INFO 02-03 19:53:36 [kv_cache_utils.py:1310] Maximum concurrency for 32,768 tokens per request: 1.60x
</span><span class="code-line">(EngineCore_DP0 pid=36318) 2026-02-03 19:53:36,340 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
</span><span class="code-line">(EngineCore_DP0 pid=36318) 2026-02-03 19:53:36,363 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
</span><span class="code-line">Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:07&lt;00:00,  6.51it/s]
</span><span class="code-line">Capturing CUDA graphs (decode, FULL): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:05&lt;00:00,  6.77it/s]
</span><span class="code-line">(EngineCore_DP0 pid=36318) INFO 02-03 19:53:49 [gpu_model_runner.py:4856] Graph capturing finished in 13 secs, took 0.00 GiB
</span><span class="code-line">(EngineCore_DP0 pid=36318) INFO 02-03 19:53:49 [core.py:273] init engine (profile, create kv cache, warmup model) took 25.12 seconds
</span><span class="code-line">(EngineCore_DP0 pid=36318) INFO 02-03 19:53:51 [vllm.py:630] Asynchronous scheduling is enabled.
</span><span class="code-line">(APIServer pid=36148) INFO 02-03 19:53:51 [api_server.py:1014] Supported tasks: [&#x27;generate&#x27;]
</span><span class="code-line">(APIServer pid=36148) WARNING 02-03 19:53:51 [model.py:1358] Default sampling parameters have been overridden by the model&#x27;s Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
</span><span class="code-line">(APIServer pid=36148) INFO 02-03 19:53:51 [serving_responses.py:224] Using default chat sampling params from model: {&#x27;temperature&#x27;: 0.6, &#x27;top_k&#x27;: 20, &#x27;top_p&#x27;: 0.95}
</span><span class="code-line">(APIServer pid=36148) INFO 02-03 19:53:51 [serving_engine.py:271] &quot;auto&quot; tool choice has been enabled.
</span><span class="code-line">(APIServer pid=36148) INFO 02-03 19:53:51 [serving_engine.py:271] &quot;auto&quot; tool choice has been enabled.
</span><span class="code-line">(APIServer pid=36148) INFO 02-03 19:53:51 [serving_chat.py:146] Using default chat sampling params from model: {&#x27;temperature&#x27;: 0.6, &#x27;top_k&#x27;: 20, &#x27;top_p&#x27;: 0.95}
</span><span class="code-line">(APIServer pid=36148) INFO 02-03 19:53:51 [serving_chat.py:182] Warming up chat template processing...
</span><span class="code-line">(APIServer pid=36148) INFO 02-03 19:53:52 [chat_utils.py:599] Detected the chat template content format to be &#x27;string&#x27;. You can set `--chat-template-content-format` to override this.
</span><span class="code-line">(APIServer pid=36148) INFO 02-03 19:53:52 [serving_chat.py:218] Chat template warmup completed in 1254.3ms
</span><span class="code-line">(APIServer pid=36148) INFO 02-03 19:53:53 [serving_completion.py:78] Using default completion sampling params from model: {&#x27;temperature&#x27;: 0.6, &#x27;top_k&#x27;: 20, &#x27;top_p&#x27;: 0.95}
</span><span class="code-line">(APIServer pid=36148) INFO 02-03 19:53:53 [serving_engine.py:271] &quot;auto&quot; tool choice has been enabled.
</span><span class="code-line">(APIServer pid=36148) INFO 02-03 19:53:53 [serving_chat.py:146] Using default chat sampling params from model: {&#x27;temperature&#x27;: 0.6, &#x27;top_k&#x27;: 20, &#x27;top_p&#x27;: 0.95}
</span><span class="code-line">(APIServer pid=36148) INFO 02-03 19:53:53 [api_server.py:1346] Starting vLLM API server 0 on http://0.0.0.0:7555
</span></code></pre>
<p>Configuring OpenCode:</p>
<pre class="language-plaintext"><code class="language-plaintext code-highlight"><span class="code-line">nano ~/.config/opencode/config.json
</span></code></pre>
<p>By copying:</p>
<pre class="language-json"><code class="language-json code-highlight"><span class="code-line"><span class="token punctuation">{</span>
</span><span class="code-line">  <span class="token property">&quot;$schema&quot;</span><span class="token operator">:</span> <span class="token string">&quot;https://opencode.ai/config.json&quot;</span><span class="token punctuation">,</span>
</span><span class="code-line">  <span class="token property">&quot;provider&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
</span><span class="code-line">    <span class="token property">&quot;vllm_local&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
</span><span class="code-line">      <span class="token property">&quot;npm&quot;</span><span class="token operator">:</span> <span class="token string">&quot;@ai-sdk/openai-compatible&quot;</span><span class="token punctuation">,</span>
</span><span class="code-line">      <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;vLLM (local)&quot;</span><span class="token punctuation">,</span>
</span><span class="code-line">      <span class="token property">&quot;options&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
</span><span class="code-line">        <span class="token property">&quot;baseURL&quot;</span><span class="token operator">:</span> <span class="token string">&quot;http://127.0.0.1:7555/v1&quot;</span><span class="token punctuation">,</span>
</span><span class="code-line">        <span class="token property">&quot;apiKey&quot;</span><span class="token operator">:</span> <span class="token string">&quot;opencode_local&quot;</span>
</span><span class="code-line">      <span class="token punctuation">}</span><span class="token punctuation">,</span>
</span><span class="code-line">      <span class="token property">&quot;models&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
</span><span class="code-line">        <span class="token property">&quot;Qwen/Qwen3-8B-AWQ&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
</span><span class="code-line">          <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Qwen 3.0 (8B Agent)&quot;</span><span class="token punctuation">,</span>
</span><span class="code-line">          <span class="token property">&quot;tools&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
</span><span class="code-line">            <span class="token property">&quot;write&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
</span><span class="code-line">            <span class="token property">&quot;bash&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
</span><span class="code-line">            <span class="token property">&quot;read&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
</span><span class="code-line">            <span class="token property">&quot;edit&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span>
</span><span class="code-line">          <span class="token punctuation">}</span><span class="token punctuation">,</span>
</span><span class="code-line">          <span class="token property">&quot;limit&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
</span><span class="code-line">            <span class="token property">&quot;context&quot;</span><span class="token operator">:</span> <span class="token number">32768</span><span class="token punctuation">,</span>
</span><span class="code-line">            <span class="token property">&quot;output&quot;</span><span class="token operator">:</span> <span class="token number">4096</span>
</span><span class="code-line">          <span class="token punctuation">}</span><span class="token punctuation">,</span>
</span><span class="code-line">          <span class="token property">&quot;supportsToolCalling&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
</span><span class="code-line">          <span class="token property">&quot;supportsReasoning&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span>
</span><span class="code-line">        <span class="token punctuation">}</span>
</span><span class="code-line">      <span class="token punctuation">}</span>
</span><span class="code-line">    <span class="token punctuation">}</span>
</span><span class="code-line">  <span class="token punctuation">}</span>
</span><span class="code-line"><span class="token punctuation">}</span>
</span></code></pre>
<p>The OpenCode configuration required a lot of trial and error. Even ChatGPT could not find the right configuration. Moving to QWEN 3.0 and explicitly enabling tools helped move things forward.</p>
<p>Then, running OpenCode. Here is a command that asks how many unit tests are in the repository.</p>
<video src="/videos/blog/LocalLLM.mp4" controls=""></video>
<p>The full answer took 2 minutes and 22 seconds.</p>
<p>Here is the full transcript:</p>
<pre class="language-md"><code class="language-md code-highlight"><span class="code-line">
</span><span class="code-line"><span class="token title important"><span class="token punctuation">##</span> User</span>
</span><span class="code-line">
</span><span class="code-line">How many tests in this repository?
</span><span class="code-line">
</span><span class="code-line"><span class="token hr punctuation">---</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token title important"><span class="token punctuation">##</span> Assistant (Build · Qwen/Qwen3-8B-AWQ · 100.8s)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token italic"><span class="token punctuation">_</span><span class="token content">Thinking:</span><span class="token punctuation">_</span></span>
</span><span class="code-line">
</span><span class="code-line">
</span><span class="code-line">Okay, the user is asking how many tests are in the repository. Let me think about how to approach this.
</span><span class="code-line">
</span><span class="code-line">First, I remember that the project is a FastAPI application, and the documentation mentions testing. In the CLAUDE.md file, there are sections about testing, including commands to run tests and requirements for test coverage. 
</span><span class="code-line">
</span><span class="code-line">The user probably wants to know the total number of tests, maybe to check if they meet the coverage requirements mentioned (minimum 76%). The test commands listed include using <span class="token code-snippet code keyword">`uv run pytest`</span> with options for coverage and speed. 
</span><span class="code-line">
</span><span class="code-line">I need to find a way to count the tests. The <span class="token code-snippet code keyword">`pytest`</span> command can give a summary when run with the <span class="token code-snippet code keyword">`-v`</span> flag, but maybe there&#x27;s a better way. Alternatively, the <span class="token code-snippet code keyword">`pytest`</span> command with <span class="token code-snippet code keyword">`--help`</span> might show options related to counting tests. Wait, the <span class="token code-snippet code keyword">`uv run pytest`</span> command is mentioned, so maybe running <span class="token code-snippet code keyword">`uv run pytest --help`</span> could show options. But the user might not have pytest installed, but since the project uses <span class="token code-snippet code keyword">`uv`</span> (uvicorn), it&#x27;s likely that pytest is installed as a dependency.
</span><span class="code-line">
</span><span class="code-line">Wait, the user is asking for the number of tests, not to run them. So maybe the best approach is to check the test files. The project structure includes a <span class="token code-snippet code keyword">`tests`</span> directory, as mentioned in the CLAUDE.md under &quot;Development Commands&quot;. The <span class="token code-snippet code keyword">`tests/services`</span> directory is mentioned, and there are specific test files like <span class="token code-snippet code keyword">`test_database.py`</span>.
</span><span class="code-line">
</span><span class="code-line">But how to count them without running the tests? The user might not have the environment set up, so I can&#x27;t run the tests directly. However, the <span class="token code-snippet code keyword">`pytest`</span> tool can list the tests when run with <span class="token code-snippet code keyword">`--help`</span> or <span class="token code-snippet code keyword">`--collect-only`</span>, but that might not be straightforward. Alternatively, the <span class="token code-snippet code keyword">`pytest`</span> command can be used with <span class="token code-snippet code keyword">`--help`</span> to see available options.
</span><span class="code-line">
</span><span class="code-line">Wait, the user might be looking for the number of test files or test cases. The <span class="token code-snippet code keyword">`pytest`</span> command can count test cases using <span class="token code-snippet code keyword">`--count`</span> or other flags. Let me check the pytest documentation. Oh, right, <span class="token code-snippet code keyword">`pytest`</span> has a <span class="token code-snippet code keyword">`--count`</span> option to count the number of tests. But I need to confirm if that&#x27;s available.
</span><span class="code-line">
</span><span class="code-line">Alternatively, the <span class="token code-snippet code keyword">`pytest`</span> command can be run with <span class="token code-snippet code keyword">`--help`</span> to see available options. So, the steps would be:
</span><span class="code-line">
</span><span class="code-line"><span class="token list punctuation">1.</span> Check if <span class="token code-snippet code keyword">`pytest`</span> is installed. Since the project uses <span class="token code-snippet code keyword">`uv`</span> and the <span class="token code-snippet code keyword">`uv run pytest`</span> command is mentioned, it&#x27;s likely installed.
</span><span class="code-line"><span class="token list punctuation">2.</span> Run <span class="token code-snippet code keyword">`uv run pytest --help`</span> to see available options.
</span><span class="code-line"><span class="token list punctuation">3.</span> Use the <span class="token code-snippet code keyword">`--count`</span> option to get the number of tests.
</span><span class="code-line">
</span><span class="code-line">But the user might not have the environment set up, so maybe the best approach is to suggest running the test commands provided in the documentation. However, the user is asking for the number, not to run them. 
</span><span class="code-line">
</span><span class="code-line">Alternatively, the <span class="token code-snippet code keyword">`pytest`</span> command can be run with <span class="token code-snippet code keyword">`--help`</span> to see if there&#x27;s an option to count tests. If not, maybe the <span class="token code-snippet code keyword">`pytest`</span> command can be used with <span class="token code-snippet code keyword">`--collect-only`</span> to list all test files, which can then be counted. 
</span><span class="code-line">
</span><span class="code-line">But without running the tests, it&#x27;s hard to get the exact number. The user might need to run the tests to get the count. However, the answer should be based on the information provided in the CLAUDE.md. The documentation mentions that the test suite is run with <span class="token code-snippet code keyword">`uv run pytest`</span>, and there are specific test files mentioned like <span class="token code-snippet code keyword">`tests/services/test_database.py`</span>. 
</span><span class="code-line">
</span><span class="code-line">Wait, the user is asking for the number of tests, but the CLAUDE.md doesn&#x27;t specify the exact count. So, the answer would be that the number of tests can be determined by running <span class="token code-snippet code keyword">`uv run pytest --count`</span> or similar command. However, without actual execution, I can&#x27;t provide the exact number. 
</span><span class="code-line">
</span><span class="code-line">But the user might be expecting a specific number based on the project structure. The <span class="token code-snippet code keyword">`tests/services`</span> directory has multiple test files, but the exact count isn&#x27;t given. Therefore, the correct approach is to inform the user that they need to run the test command to get the count, or check the test files. 
</span><span class="code-line">
</span><span class="code-line">Alternatively, if the user is in a Git repository, they could use <span class="token code-snippet code keyword">`git ls-files tests/`</span> to list test files and count them. But that&#x27;s not reliable as some tests might be in subdirectories. 
</span><span class="code-line">
</span><span class="code-line">In conclusion, the answer should guide the user to run the test command to get the count, as the exact number isn&#x27;t provided in the documentation.
</span><span class="code-line">
</span><span class="code-line">
</span><span class="code-line">
</span><span class="code-line"><span class="token bold"><span class="token punctuation">**</span><span class="token content">Tool: bash</span><span class="token punctuation">**</span></span>
</span><span class="code-line">
</span><span class="code-line"><span class="token bold"><span class="token punctuation">**</span><span class="token content">Input:</span><span class="token punctuation">**</span></span>
</span><span class="code-line">json
</span><span class="code-line">{
</span><span class="code-line">  &quot;command&quot;: &quot;uv run pytest --help&quot;,
</span><span class="code-line">  &quot;description&quot;: &quot;Check pytest options for test counting&quot;
</span><span class="code-line">}
</span><span class="code-line">
</span><span class="code-line">
</span><span class="code-line"><span class="token bold"><span class="token punctuation">**</span><span class="token content">Output:</span><span class="token punctuation">**</span></span>
</span><span class="code-line">
</span><span class="code-line">usage: pytest <span class="token url">[<span class="token content">options</span>] [<span class="token variable">file_or_dir</span>]</span> <span class="token url">[<span class="token content">file_or_dir</span>] [<span class="token variable">...</span>]</span>
</span><span class="code-line">
</span><span class="code-line">positional arguments:
</span><span class="code-line">  file_or_dir
</span><span class="code-line">
</span><span class="code-line">general:
</span><span class="code-line">  -k EXPRESSION         Only run tests which match the given substring
</span><span class="code-line">                        expression. An expression is a Python evaluable
</span><span class="code-line">                        expression where all names are substring-matched against
</span><span class="code-line">                        test names and their parent classes. Example: -k
</span><span class="code-line">                        &#x27;test_method or test_other&#x27; matches all test functions
</span><span class="code-line">                        and classes whose name contains &#x27;test_method&#x27; or
</span><span class="code-line">                        &#x27;test_other&#x27;, while -k &#x27;not test_method&#x27; matches those
</span><span class="code-line">                        that don&#x27;t contain &#x27;test_method&#x27; in their names. -k &#x27;not
</span><span class="code-line">                        test_method and not test_other&#x27; will eliminate the
</span><span class="code-line">                        matches. Additionally keywords are matched to classes
</span><span class="code-line">                        and functions containing extra names in their
</span><span class="code-line">                        &#x27;extra_keyword_matches&#x27; set, as well as functions which
</span><span class="code-line">                        have names assigned directly to them. The matching is
</span><span class="code-line">                        case-insensitive.
</span><span class="code-line">  -m MARKEXPR           Only run tests matching given mark expression. For
</span><span class="code-line">                        example: -m &#x27;mark1 and not mark2&#x27;.
</span><span class="code-line">  --markers             show markers (builtin, plugin and per-project ones).
</span><span class="code-line">  -x, --exitfirst       Exit instantly on first error or failed test
</span><span class="code-line">  --maxfail=num         Exit after first num failures or errors
</span><span class="code-line">  --strict-config       Enables the strict_config option
</span><span class="code-line">  --strict-markers      Enables the strict_markers option
</span><span class="code-line">  --strict              Enables the strict option
</span><span class="code-line">  --fixtures, --funcargs
</span><span class="code-line">                        Show available fixtures, sorted by plugin appearance
</span><span class="code-line">                        (fixtures with leading &#x27;_&#x27; are only shown with &#x27;-v&#x27;)
</span><span class="code-line">  --fixtures-per-test   Show fixtures per test
</span><span class="code-line">  --pdb                 Start the interactive Python debugger on errors or
</span><span class="code-line">                        KeyboardInterrupt
</span><span class="code-line">  --pdbcls=modulename:classname
</span><span class="code-line">                        Specify a custom interactive Python debugger for use
</span><span class="code-line">                        with --pdb.For example:
</span><span class="code-line">                        --pdbcls=IPython.terminal.debugger:TerminalPdb
</span><span class="code-line">  --trace               Immediately break when running each test
</span><span class="code-line">  --capture=method      Per-test capturing method: one of fd|sys|no|tee-sys
</span><span class="code-line">  -s                    Shortcut for --capture=no
</span><span class="code-line">  --runxfail            Report the results of xfail tests as if they were not
</span><span class="code-line">                        marked
</span><span class="code-line">  --lf, --last-failed   Rerun only the tests that failed at the last run (or all
</span><span class="code-line">                        if none failed)
</span><span class="code-line">  --ff, --failed-first  Run all tests, but run the last failures first. This may
</span><span class="code-line">                        re-order tests and thus lead to repeated fixture
</span><span class="code-line">                        setup/teardown.
</span><span class="code-line">  --nf, --new-first     Run tests from new files first, then the rest of the
</span><span class="code-line">                        tests sorted by file mtime
</span><span class="code-line">  --cache-show=[CACHESHOW]
</span><span class="code-line">                        Show cache contents, don&#x27;t perform collection or tests.
</span><span class="code-line">                        Optional argument: glob (default: &#x27;*&#x27;).
</span><span class="code-line">  --cache-clear         Remove all cache contents at start of test run
</span><span class="code-line">  --lfnf={all,none}, --last-failed-no-failures={all,none}
</span><span class="code-line">                        With <span class="token code-snippet code keyword">``--lf``</span>, determines whether to execute tests when
</span><span class="code-line">                        there are no previously (known) failures or when no
</span><span class="code-line">                        cached <span class="token code-snippet code keyword">``lastfailed``</span> data was found. <span class="token code-snippet code keyword">``all``</span> (the
</span><span class="code-line">                        default) runs the full test suite again. <span class="token code-snippet code keyword">``none``</span> just
</span><span class="code-line">                        emits a message about no known failures and exits
</span><span class="code-line">                        successfully.
</span><span class="code-line">  --sw, --stepwise      Exit on test failure and continue from last failing test
</span><span class="code-line">                        next time
</span><span class="code-line">  --sw-skip, --stepwise-skip
</span><span class="code-line">                        Ignore the first failing test but stop on the next
</span><span class="code-line">                        failing test. Implicitly enables --stepwise.
</span><span class="code-line">  --sw-reset, --stepwise-reset
</span><span class="code-line">                        Resets stepwise state, restarting the stepwise workflow.
</span><span class="code-line">                        Implicitly enables --stepwise.
</span><span class="code-line">
</span><span class="code-line">Reporting:
</span><span class="code-line">  --durations=N         Show N slowest setup/test durations (N=0 for all)
</span><span class="code-line">  --durations-min=N     Minimal duration in seconds for inclusion in slowest
</span><span class="code-line">                        list. Default: 0.005 (or 0.0 if -vv is given).
</span><span class="code-line">  -v, --verbose         Increase verbosity
</span><span class="code-line">  --no-header           Disable header
</span><span class="code-line">  --no-summary          Disable summary
</span><span class="code-line">  --no-fold-skipped     Do not fold skipped tests in short summary.
</span><span class="code-line">  --force-short-summary
</span><span class="code-line">                        Force condensed summary output regardless of verbosity
</span><span class="code-line">                        level.
</span><span class="code-line">  -q, --quiet           Decrease verbosity
</span><span class="code-line">  --verbosity=VERBOSE   Set verbosity. Default: 0.
</span><span class="code-line">  -r chars              Show extra test summary info as specified by chars:
</span><span class="code-line">                        (f)ailed, (E)rror, (s)kipped, (x)failed, (X)passed,
</span><span class="code-line">                        (p)assed, (P)assed with output, (a)ll except passed
</span><span class="code-line">                        (p/P), or (A)ll. (w)arnings are enabled by default (see
</span><span class="code-line">                        --disable-warnings), &#x27;N&#x27; can be used to reset the list.
</span><span class="code-line">                        (default: &#x27;fE&#x27;).
</span><span class="code-line">  --disable-warnings, --disable-pytest-warnings
</span><span class="code-line">                        Disable warnings summary
</span><span class="code-line">  -l, --showlocals      Show locals in tracebacks (disabled by default)
</span><span class="code-line">  --no-showlocals       Hide locals in tracebacks (negate --showlocals passed
</span><span class="code-line">                        through addopts)
</span><span class="code-line">  --tb=style            Traceback print mode (auto/long/short/line/native/no)
</span><span class="code-line">  --xfail-tb            Show tracebacks for xfail (as long as --tb != no)
</span><span class="code-line">  --show-capture={no,stdout,stderr,log,all}
</span><span class="code-line">                        Controls how captured stdout/stderr/log is shown on
</span><span class="code-line">                        failed tests. Default: all.
</span><span class="code-line">  --full-trace          Don&#x27;t cut any tracebacks (default is to cut)
</span><span class="code-line">  --color=color         Color terminal output (yes/no/auto)
</span><span class="code-line">  --code-highlight={yes,no}
</span><span class="code-line">                        Whether code should be highlighted (only if --color is
</span><span class="code-line">                        also enabled). Default: yes.
</span><span class="code-line">  --pastebin=mode       Send failed|all info to bpaste.net pastebin service
</span><span class="code-line">  --junit-xml=path      Create junit-xml style report file at given path
</span><span class="code-line">  --junit-prefix=str    Prepend prefix to classnames in junit-xml output
</span><span class="code-line">
</span><span class="code-line">pytest-warnings:
</span><span class="code-line">  -W PYTHONWARNINGS, --pythonwarnings=PYTHONWARNINGS
</span><span class="code-line">                        Set which warnings to report, see -W option of Python
</span><span class="code-line">                        itself
</span><span class="code-line">
</span><span class="code-line">collection:
</span><span class="code-line">  --collect-only, --co  Only collect tests, don&#x27;t execute them
</span><span class="code-line">  --pyargs              Try to interpret all arguments as Python packages
</span><span class="code-line">  --ignore=path         Ignore path during collection (multi-allowed)
</span><span class="code-line">  --ignore-glob=path    Ignore path pattern during collection (multi-allowed)
</span><span class="code-line">  --deselect=nodeid_prefix
</span><span class="code-line">                        Deselect item (via node id prefix) during collection
</span><span class="code-line">                        (multi-allowed)
</span><span class="code-line">  --confcutdir=dir      Only load conftest.py&#x27;s relative to specified dir
</span><span class="code-line">  --noconftest          Don&#x27;t load any conftest.py files
</span><span class="code-line">  --keep-duplicates     Keep duplicate tests
</span><span class="code-line">  --collect-in-virtualenv
</span><span class="code-line">                        Don&#x27;t ignore tests in a local virtualenv directory
</span><span class="code-line">  --continue-on-collection-errors
</span><span class="code-line">                        Force test execution even if collection errors occur
</span><span class="code-line">  --import-mode={prepend,append,importlib}
</span><span class="code-line">                        Prepend/append to sys.path when importing test modules
</span><span class="code-line">                        and conftest files. Default: prepend.
</span><span class="code-line">  --doctest-modules     Run doctests in all .py modules
</span><span class="code-line">  --doctest-report={none,cdiff,ndiff,udiff,only_first_failure}
</span><span class="code-line">                        Choose another output format for diffs on doctest
</span><span class="code-line">                        failure
</span><span class="code-line">  --doctest-glob=pat    Doctests file matching pattern, default: test*.txt
</span><span class="code-line">  --doctest-ignore-import-errors
</span><span class="code-line">                        Ignore doctest collection errors
</span><span class="code-line">  --doctest-continue-on-failure
</span><span class="code-line">                        For a given doctest, continue to run after the first
</span><span class="code-line">                        failure
</span><span class="code-line">
</span><span class="code-line">test session debugging and configuration:
</span><span class="code-line">  -c FILE, --config-file=FILE
</span><span class="code-line">                        Load configuration from <span class="token code-snippet code keyword">`FILE`</span> instead of trying to
</span><span class="code-line">                        locate one of the implicit configuration files.
</span><span class="code-line">  --rootdir=ROOTDIR     Define root directory for tests. Can be relative path:
</span><span class="code-line">                        &#x27;root_dir&#x27;, &#x27;./root_dir&#x27;, &#x27;root_dir/another_dir/&#x27;;
</span><span class="code-line">                        absolute path: &#x27;/home/user/root_dir&#x27;; path with
</span><span class="code-line">                        variables: &#x27;$HOME/root_dir&#x27;.
</span><span class="code-line">  --basetemp=dir        Base temporary directory for this test run. (Warning:
</span><span class="code-line">                        this directory is removed if it exists.)
</span><span class="code-line">  -V, --version         Display pytest version and information about plugins.
</span><span class="code-line">                        When given twice, also display information about
</span><span class="code-line">                        plugins.
</span><span class="code-line">  -h, --help            Show help message and configuration info
</span><span class="code-line">  -p name               Early-load given plugin module name or entry point
</span><span class="code-line">                        (multi-allowed). To avoid loading of plugins, use the
</span><span class="code-line">                        <span class="token code-snippet code keyword">`no:`</span> prefix, e.g. <span class="token code-snippet code keyword">`no:doctest`</span>. See also --disable-
</span><span class="code-line">                        plugin-autoload.
</span><span class="code-line">  --disable-plugin-autoload
</span><span class="code-line">                        Disable plugin auto-loading through entry point
</span><span class="code-line">                        packaging metadata. Only plugins explicitly specified in
</span><span class="code-line">                        -p or env var PYTEST_PLUGINS will be loaded.
</span><span class="code-line">  --trace-config        Trace considerations of conftest.py files
</span><span class="code-line">  --debug=[DEBUG_FILE_NAME]
</span><span class="code-line">                        Store internal tracing debug information in this log
</span><span class="code-line">                        file. This file is opened with &#x27;w&#x27; and truncated as a
</span><span class="code-line">                        result, care advised. Default: pytestdebug.log.
</span><span class="code-line">  -o OVERRIDE_INI, --override-ini=OVERRIDE_INI
</span><span class="code-line">                        Override configuration option with &quot;option=value&quot; style,
</span><span class="code-line">                        e.g. <span class="token code-snippet code keyword">`-o strict_xfail=True -o cache_dir=cache`</span>.
</span><span class="code-line">  --assert=MODE         Control assertion debugging tools.
</span><span class="code-line">                        &#x27;plain&#x27; performs no assertion debugging.
</span><span class="code-line">                        &#x27;rewrite&#x27; (the default) rewrites assert statements in
</span><span class="code-line">                        test modules on import to provide assert expression
</span><span class="code-line">                        information.
</span><span class="code-line">  --setup-only          Only setup fixtures, do not execute tests
</span><span class="code-line">  --setup-show          Show setup of fixtures while executing tests
</span><span class="code-line">  --setup-plan          Show what fixtures and tests would be executed but don&#x27;t
</span><span class="code-line">                        execute anything
</span><span class="code-line">
</span><span class="code-line">logging:
</span><span class="code-line">  --log-level=LEVEL     Level of messages to catch/display. Not set by default,
</span><span class="code-line">                        so it depends on the root/parent log handler&#x27;s effective
</span><span class="code-line">                        level, where it is &quot;WARNING&quot; by default.
</span><span class="code-line">  --log-format=LOG_FORMAT
</span><span class="code-line">                        Log format used by the logging module
</span><span class="code-line">  --log-date-format=LOG_DATE_FORMAT
</span><span class="code-line">                        Log date format used by the logging module
</span><span class="code-line">  --log-cli-level=LOG_CLI_LEVEL
</span><span class="code-line">                        CLI logging level
</span><span class="code-line">  --log-cli-format=LOG_CLI_FORMAT
</span><span class="code-line">                        Log format used by the logging module
</span><span class="code-line">  --log-cli-date-format=LOG_CLI_DATE_FORMAT
</span><span class="code-line">                        Log date format used by the logging module
</span><span class="code-line">  --log-file=LOG_FILE   Path to a file when logging will be written to
</span><span class="code-line">  --log-file-mode={w,a}
</span><span class="code-line">                        Log file open mode
</span><span class="code-line">  --log-file-level=LOG_FILE_LEVEL
</span><span class="code-line">                        Log file logging level
</span><span class="code-line">  --log-file-format=LOG_FILE_FORMAT
</span><span class="code-line">                        Log format used by the logging module
</span><span class="code-line">  --log-file-date-format=LOG_FILE_DATE_FORMAT
</span><span class="code-line">                        Log date format used by the logging module
</span><span class="code-line">  --log-auto-indent=LOG_AUTO_INDENT
</span><span class="code-line">                        Auto-indent multiline messages passed to the logging
</span><span class="code-line">                        module. Accepts true|on, false|off or an integer.
</span><span class="code-line">  --log-disable=LOGGER_DISABLE
</span><span class="code-line">                        Disable a logger by name. Can be passed multiple times.
</span><span class="code-line">
</span><span class="code-line">asyncio:
</span><span class="code-line">  --asyncio-mode=MODE   &#x27;auto&#x27; - for automatically handling all async functions
</span><span class="code-line">                        by the plugin
</span><span class="code-line">                        &#x27;strict&#x27; - for autoprocessing disabling (useful if
</span><span class="code-line">                        different async frameworks should be tested together,
</span><span class="code-line">                        e.g. both pytest-asyncio and pytest-trio are used in the
</span><span class="code-line">                        same project)
</span><span class="code-line">  --asyncio-debug       enable asyncio debug mode for the default event loop
</span><span class="code-line">
</span><span class="code-line">coverage reporting with distributed testing support:
</span><span class="code-line">  --cov=[SOURCE]        Path or package name to measure during execution (multi-
</span><span class="code-line">                        allowed). Use --cov= to not do any source filtering and
</span><span class="code-line">                        record everything.
</span><span class="code-line">  --cov-reset           Reset cov sources accumulated in options so far.
</span><span class="code-line">  --cov-report=TYPE     Type of report to generate: term, term-missing,
</span><span class="code-line">                        annotate, html, xml, json, markdown, markdown-append,
</span><span class="code-line">                        lcov (multi-allowed). term, term-missing may be followed
</span><span class="code-line">                        by &quot;:skip-covered&quot;. annotate, html, xml, json, markdown,
</span><span class="code-line">                        markdown-append and lcov may be followed by &quot;:DEST&quot;
</span><span class="code-line">                        where DEST specifies the output location. Use --cov-
</span><span class="code-line">                        report= to not generate any output.
</span><span class="code-line">  --cov-config=PATH     Config file for coverage. Default: .coveragerc
</span><span class="code-line">  --no-cov-on-fail      Do not report coverage if test run fails. Default: False
</span><span class="code-line">  --no-cov              Disable coverage report completely (useful for
</span><span class="code-line">                        debuggers). Default: False
</span><span class="code-line">  --cov-fail-under=MIN  Fail if the total coverage is less than MIN.
</span><span class="code-line">  --cov-append          Do not delete coverage but append to current. Default:
</span><span class="code-line">                        False
</span><span class="code-line">  --cov-branch          Enable branch coverage.
</span><span class="code-line">  --cov-precision=COV_PRECISION
</span><span class="code-line">                        Override the reporting precision.
</span><span class="code-line">  --cov-context=CONTEXT
</span><span class="code-line">                        Dynamic contexts to use. &quot;test&quot; for now.
</span><span class="code-line">
</span><span class="code-line">[pytest] configuration options in the first pytest.toml|pytest.ini|tox.ini|setup.cfg|pyproject.toml file found:
</span><span class="code-line">
</span><span class="code-line">  markers (linelist):   Register new markers for test functions
</span><span class="code-line">  empty_parameter_set_mark (string):
</span><span class="code-line">                        Default marker for empty parametersets
</span><span class="code-line">  strict_config (bool): Any warnings encountered while parsing the <span class="token code-snippet code keyword">`pytest`</span>
</span><span class="code-line">                        section of the configuration file raise errors
</span><span class="code-line">  strict_markers (bool):
</span><span class="code-line">                        Markers not registered in the <span class="token code-snippet code keyword">`markers`</span> section of the
</span><span class="code-line">                        configuration file raise errors
</span><span class="code-line">  strict (bool):        Enables all strictness options, currently:
</span><span class="code-line">                        strict_config, strict_markers, strict_xfail,
</span><span class="code-line">                        strict_parametrization_ids
</span><span class="code-line">  filterwarnings (linelist):
</span><span class="code-line">                        Each line specifies a pattern for
</span><span class="code-line">                        warnings.filterwarnings. Processed after
</span><span class="code-line">                        -W/--pythonwarnings.
</span><span class="code-line">  norecursedirs (args): Directory patterns to avoid for recursion
</span><span class="code-line">  testpaths (args):     Directories to search for tests when no files or
</span><span class="code-line">                        directories are given on the command line
</span><span class="code-line">  collect_imported_tests (bool):
</span><span class="code-line">                        Whether to collect tests in imported modules outside
</span><span class="code-line">                        <span class="token code-snippet code keyword">`testpaths`</span>
</span><span class="code-line">  consider_namespace_packages (bool):
</span><span class="code-line">                        Consider namespace packages when resolving module names
</span><span class="code-line">                        during import
</span><span class="code-line">  usefixtures (args):   List of default fixtures to be used with this project
</span><span class="code-line">  python_files (args):  Glob-style file patterns for Python test module
</span><span class="code-line">                        discovery
</span><span class="code-line">  python_classes (args):
</span><span class="code-line">                        Prefixes or glob names for Python test class discovery
</span><span class="code-line">  python_functions (args):
</span><span class="code-line">                        Prefixes or glob names for Python test function and
</span><span class="code-line">                        method discovery
</span><span class="code-line">  disable_test_id_escaping_and_forfeit_all_rights_to_community_support (bool):
</span><span class="code-line">                        Disable string escape non-ASCII characters, might cause
</span><span class="code-line">                        unwanted side effects(use at your own risk)
</span><span class="code-line">  strict_parametrization_ids (bool):
</span><span class="code-line">                        Emit an error if non-unique parameter set IDs are
</span><span class="code-line">                        detected
</span><span class="code-line">  console_output_style (string):
</span><span class="code-line">                        Console output: &quot;classic&quot;, or with additional progress
</span><span class="code-line">                        information (&quot;progress&quot; (percentage) | &quot;count&quot; |
</span><span class="code-line">                        &quot;progress-even-when-capture-no&quot; (forces progress even
</span><span class="code-line">                        when capture=no)
</span><span class="code-line">  verbosity_test_cases (string):
</span><span class="code-line">                        Specify a verbosity level for test case execution,
</span><span class="code-line">                        overriding the main level. Higher levels will provide
</span><span class="code-line">                        more detailed information about each test case executed.
</span><span class="code-line">  strict_xfail (bool):  Default for the strict parameter of xfail markers when
</span><span class="code-line">                        not given explicitly (default: False) (alias:
</span><span class="code-line">                        xfail_strict)
</span><span class="code-line">  tmp_path_retention_count (string):
</span><span class="code-line">                        How many sessions should we keep the <span class="token code-snippet code keyword">`tmp_path`</span>
</span><span class="code-line">                        directories, according to <span class="token code-snippet code keyword">`tmp_path_retention_policy`</span>.
</span><span class="code-line">  tmp_path_retention_policy (string):
</span><span class="code-line">                        Controls which directories created by the <span class="token code-snippet code keyword">`tmp_path`</span>
</span><span class="code-line">                        fixture are kept around, based on test outcome.
</span><span class="code-line">                        (all/failed/none)
</span><span class="code-line">  enable_assertion_pass_hook (bool):
</span><span class="code-line">                        Enables the pytest_assertion_pass hook. Make sure to
</span><span class="code-line">                        delete any previously generated pyc cache files.
</span><span class="code-line">  truncation_limit_lines (string):
</span><span class="code-line">                        Set threshold of LINES after which truncation will take
</span><span class="code-line">                        effect
</span><span class="code-line">  truncation_limit_chars (string):
</span><span class="code-line">                        Set threshold of CHARS after which truncation will take
</span><span class="code-line">                        effect
</span><span class="code-line">  verbosity_assertions (string):
</span><span class="code-line">                        Specify a verbosity level for assertions, overriding the
</span><span class="code-line">                        main level. Higher levels will provide more detailed
</span><span class="code-line">                        explanation when an assertion fails.
</span><span class="code-line">  junit_suite_name (string):
</span><span class="code-line">                        Test suite name for JUnit report
</span><span class="code-line">  junit_logging (string):
</span><span class="code-line">                        Write captured log messages to JUnit report: one of
</span><span class="code-line">                        no|log|system-out|system-err|out-err|all
</span><span class="code-line">  junit_log_passing_tests (bool):
</span><span class="code-line">                        Capture log information for passing tests to JUnit
</span><span class="code-line">                        report:
</span><span class="code-line">  junit_duration_report (string):
</span><span class="code-line">                        Duration time to report: one of total|call
</span><span class="code-line">  junit_family (string):
</span><span class="code-line">                        Emit XML for schema: one of legacy|xunit1|xunit2
</span><span class="code-line">  doctest_optionflags (args):
</span><span class="code-line">                        Option flags for doctests
</span><span class="code-line">  doctest_encoding (string):
</span><span class="code-line">                        Encoding used for doctest files
</span><span class="code-line">  cache_dir (string):   Cache directory path
</span><span class="code-line">  log_level (string):   Default value for --log-level
</span><span class="code-line">  log_format (string):  Default value for --log-format
</span><span class="code-line">  log_date_format (string):
</span><span class="code-line">                        Default value for --log-date-format
</span><span class="code-line">  log_cli (bool):       Enable log display during test run (also known as &quot;live
</span><span class="code-line">                        logging&quot;)
</span><span class="code-line">  log_cli_level (string):
</span><span class="code-line">                        Default value for --log-cli-level
</span><span class="code-line">  log_cli_format (string):
</span><span class="code-line">                        Default value for --log-cli-format
</span><span class="code-line">  log_cli_date_format (string):
</span><span class="code-line">                        Default value for --log-cli-date-format
</span><span class="code-line">  log_file (string):    Default value for --log-file
</span><span class="code-line">  log_file_mode (string):
</span><span class="code-line">                        Default value for --log-file-mode
</span><span class="code-line">  log_file_level (string):
</span><span class="code-line">                        Default value for --log-file-level
</span><span class="code-line">  log_file_format (string):
</span><span class="code-line">                        Default value for --log-file-format
</span><span class="code-line">  log_file_date_format (string):
</span><span class="code-line">                        Default value for --log-file-date-format
</span><span class="code-line">  log_auto_indent (string):
</span><span class="code-line">                        Default value for --log-auto-indent
</span><span class="code-line">  faulthandler_timeout (string):
</span><span class="code-line">                        Dump the traceback of all threads if a test takes more
</span><span class="code-line">                        than TIMEOUT seconds to finish
</span><span class="code-line">  faulthandler_exit_on_timeout (bool):
</span><span class="code-line">                        Exit the test process if a test takes more than
</span><span class="code-line">                        faulthandler_timeout seconds to finish
</span><span class="code-line">  verbosity_subtests (string):
</span><span class="code-line">                        Specify verbosity level for subtests. Higher levels will
</span><span class="code-line">                        generate output for passed subtests. Failed subtests are
</span><span class="code-line">                        always reported.
</span><span class="code-line">  addopts (args):       Extra command line options
</span><span class="code-line">  minversion (string):  Minimally required pytest version
</span><span class="code-line">  pythonpath (paths):   Add paths to sys.path
</span><span class="code-line">  required_plugins (args):
</span><span class="code-line">                        Plugins that must be present for pytest to run
</span><span class="code-line">  anyio_mode (string):  AnyIO plugin mode (either &quot;strict&quot; or &quot;auto&quot;)
</span><span class="code-line">  mock_traceback_monkeypatch (string):
</span><span class="code-line">                        Monkeypatch the mock library to improve reporting of the
</span><span class="code-line">                        assert_called_... methods
</span><span class="code-line">  mock_use_standalone_module (string):
</span><span class="code-line">                        Use standalone &quot;mock&quot; (from PyPI) instead of builtin
</span><span class="code-line">                        &quot;unittest.mock&quot; on Python 3
</span><span class="code-line">  asyncio_mode (string):
</span><span class="code-line">                        default value for --asyncio-mode
</span><span class="code-line">  asyncio_debug (bool): enable asyncio debug mode for the default event loop
</span><span class="code-line">  asyncio_default_fixture_loop_scope (string):
</span><span class="code-line">                        default scope of the asyncio event loop used to execute
</span><span class="code-line">                        async fixtures
</span><span class="code-line">  asyncio_default_test_loop_scope (string):
</span><span class="code-line">                        default scope of the asyncio event loop used to execute
</span><span class="code-line">                        tests
</span><span class="code-line">
</span><span class="code-line">Environment variables:
</span><span class="code-line">  CI                       When set to a non-empty value, pytest knows it is running in a CI process and does not truncate summary info
</span><span class="code-line">  BUILD_NUMBER             Equivalent to CI
</span><span class="code-line">  PYTEST_ADDOPTS           Extra command line options
</span><span class="code-line">  PYTEST_PLUGINS           Comma-separated plugins to load during startup
</span><span class="code-line">  PYTEST_DISABLE_PLUGIN_AUTOLOAD Set to disable plugin auto-loading
</span><span class="code-line">  PYTEST_DEBUG             Set to enable debug tracing of pytest&#x27;s internals
</span><span class="code-line">  PYTEST_DEBUG_TEMPROOT    Override the system temporary directory
</span><span class="code-line">  PYTEST_THEME             The Pygments style to use for code output
</span><span class="code-line">  PYTEST_THEME_MODE        Set the PYTEST_THEME to be either &#x27;dark&#x27; or &#x27;light&#x27;
</span><span class="code-line">
</span><span class="code-line">
</span><span class="code-line">to see available markers type: pytest --markers
</span><span class="code-line">to see available fixtures type: pytest --fixtures
</span><span class="code-line">(shown according to specified file_or_dir or current dir if not specified; fixtures with leading &#x27;_&#x27; are only shown with the &#x27;-v&#x27; option
</span><span class="code-line">
</span><span class="code-line">
</span><span class="code-line">
</span><span class="code-line"><span class="token hr punctuation">---</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token title important"><span class="token punctuation">##</span> Assistant (Build · Qwen/Qwen3-8B-AWQ · 29.8s)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>think</span><span class="token punctuation">&gt;</span></span>
</span><span class="code-line">Okay, the user wants to know how many tests are in the repository. Let me check the information provided.
</span><span class="code-line">
</span><span class="code-line">In the CLAUDE.md file, there&#x27;s a section about testing. It mentions running tests with <span class="token code-snippet code keyword">`uv run pytest`</span> and specifies that the test suite has a minimum coverage of 76%. There&#x27;s also a note about running specific test files, like <span class="token code-snippet code keyword">`tests/services/test_database.py`</span>.
</span><span class="code-line">
</span><span class="code-line">The user&#x27;s question is about the number of tests. The documentation doesn&#x27;t explicitly state the count, but it does mention that tests are run with <span class="token code-snippet code keyword">`uv run pytest`</span>. To find the number of tests, I should check the test files. The <span class="token code-snippet code keyword">`tests`</span> directory likely contains multiple test files. For example, <span class="token code-snippet code keyword">`test_database.py`</span> is mentioned, and there might be others like <span class="token code-snippet code keyword">`test_queue.py`</span> or <span class="token code-snippet code keyword">`test_streaming.py`</span> based on the project structure.
</span><span class="code-line">
</span><span class="code-line">Since the user can&#x27;t run the tests directly, I can infer that the number of tests is determined by the number of test files in the <span class="token code-snippet code keyword">`tests`</span> directory. The exact count isn&#x27;t provided, but the answer should guide the user to check the test files or run the test command to get the count. However, the user might need to run <span class="token code-snippet code keyword">`uv run pytest --count`</span> or use a tool like <span class="token code-snippet code keyword">`find`</span> to count the test files. Alternatively, the answer could be that the number of tests is determined by the test files in the <span class="token code-snippet code keyword">`tests`</span> directory, and the exact count can be found by listing those files.
</span><span class="code-line"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>think</span><span class="token punctuation">&gt;</span></span>
</span><span class="code-line">
</span><span class="code-line"><span class="token bold"><span class="token punctuation">**</span><span class="token content">Tool: bash</span><span class="token punctuation">**</span></span>
</span><span class="code-line">
</span><span class="code-line"><span class="token bold"><span class="token punctuation">**</span><span class="token content">Input:</span><span class="token punctuation">**</span></span>
</span><span class="code-line">json
</span><span class="code-line">{
</span><span class="code-line">  &quot;command&quot;: &quot;find tests/ -name \&quot;test_*.py\&quot; | wc -l&quot;,
</span><span class="code-line">  &quot;description&quot;: &quot;Count test files in tests directory&quot;
</span><span class="code-line">}
</span><span class="code-line">
</span><span class="code-line">
</span><span class="code-line"><span class="token bold"><span class="token punctuation">**</span><span class="token content">Output:</span><span class="token punctuation">**</span></span>
</span><span class="code-line">
</span><span class="code-line">20
</span><span class="code-line">
</span><span class="code-line"><span class="token hr punctuation">---</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token title important"><span class="token punctuation">##</span> Assistant (Build · Qwen/Qwen3-8B-AWQ · 12.1s)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>think</span><span class="token punctuation">&gt;</span></span>
</span><span class="code-line">Okay, the user asked how many tests are in the repository. I first checked the pytest help to see if there was a way to count tests directly, but that didn&#x27;t give the exact number. Then I decided to count the test files in the <span class="token code-snippet code keyword">`tests`</span> directory. Using the <span class="token code-snippet code keyword">`find`</span> command, I located all files matching <span class="token code-snippet code keyword">`test_*.py`</span> and counted them. The result was 20 files. So, there are 20 test files in the repository. The answer is 20.
</span><span class="code-line"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>think</span><span class="token punctuation">&gt;</span></span>
</span><span class="code-line">
</span><span class="code-line">There are <span class="token bold"><span class="token punctuation">**</span><span class="token content">20 test files</span><span class="token punctuation">**</span></span> in the repository, matching the pattern <span class="token code-snippet code keyword">`test_*.py`</span> in the <span class="token code-snippet code keyword">`tests/`</span> directory.
</span><span class="code-line">
</span><span class="code-line"><span class="token hr punctuation">---</span>
</span></code></pre>
<p>The problem is how verbose the model is and how inaccurate the initial answer was, since I wanted to know the number of tests, not the number of test files. Adding a second prompt specifying the total number of tests inside those files resulted in the model trying a few approaches using pytest.</p>
<p>It took three prompts, with me explicitly telling the model that files starting with <code>test_</code> are test files and that inside those files there are many test functions also starting with <code>test_</code>. From there, I finally got <code>427</code> tests, which is a good answer.</p>
<h1>Speed</h1>
<p>Here is a copy of the logs of the LLM during the previous talk with OpenCode:</p>
<pre class="language-plaintext"><code class="language-plaintext code-highlight"><span class="code-line">(APIServer pid=21042) INFO:     127.0.0.1:38596 - &quot;POST /v1/chat/completions HTTP/1.1&quot; 200 OK
</span><span class="code-line">(APIServer pid=21042) INFO 02-03 20:23:46 [loggers.py:257] Engine 000: Avg prompt throughput: 1682.8 tokens/s, Avg generation throughput: 9.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 48.4%, Prefix cache hit rate: 0.0%
</span><span class="code-line">(APIServer pid=21042) INFO 02-03 20:23:56 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 48.7%, Prefix cache hit rate: 0.0%
</span><span class="code-line">(APIServer pid=21042) INFO 02-03 20:24:07 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 49.0%, Prefix cache hit rate: 0.0%
</span><span class="code-line">(APIServer pid=21042) INFO 02-03 20:24:17 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 49.2%, Prefix cache hit rate: 0.0%
</span><span class="code-line">(APIServer pid=21042) INFO 02-03 20:24:27 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 49.5%, Prefix cache hit rate: 0.0%
</span><span class="code-line">(APIServer pid=21042) INFO 02-03 20:24:37 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 10.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 49.7%, Prefix cache hit rate: 0.0%
</span><span class="code-line">(APIServer pid=21042) INFO 02-03 20:24:47 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 50.1%, Prefix cache hit rate: 0.0%
</span><span class="code-line">(APIServer pid=21042) INFO 02-03 20:24:57 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 50.4%, Prefix cache hit rate: 0.0%
</span><span class="code-line">(APIServer pid=21042) INFO 02-03 20:25:07 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 50.8%, Prefix cache hit rate: 0.0%
</span><span class="code-line">(APIServer pid=21042) INFO:     127.0.0.1:38596 - &quot;POST /v1/chat/completions HTTP/1.1&quot; 200 OK
</span></code></pre>
<p>The 10 tokens per second is slow but not terrible. I was surprise to get such good result on my machine.</p>
<h1>Conclusion</h1>
<p>QWEN 3.0 is a good model, but 8B parameters is not ideal. That said, it runs at $0, understands me, and can interact with the source code like Claude. While not extremely useful yet, having a local specialized model running is very interesting.</p>
<p>I could see having a financial model, a coding model, and other specialized models that we can plug and play locally for specific tasks, which would help quite a lot in reducing costs in the long term.</p></div></main><div class="BlogBody_paginationBar__1gsMc"><div class="BlogBody_paginationTitle__H_eFX">Chronological Blog Articles by Page</div><div class="BlogBody_paginationLinks__nk8zd"><a class="" href="/blog/page/1">1</a><a class="" href="/blog/page/2">2</a><a class="" href="/blog/page/3">3</a><a class="" href="/blog/page/4">4</a><a class="" href="/blog/page/5">5</a><a class="" href="/blog/page/6">6</a><a class="" href="/blog/page/7">7</a><a class="" href="/blog/page/8">8</a><a class="" href="/blog/page/9">9</a><a class="" href="/blog/page/10">10</a><a class="" href="/blog/page/11">11</a><a class="" href="/blog/page/12">12</a><a class="" href="/blog/page/13">13</a><a class="" href="/blog/page/14">14</a><a class="" href="/blog/page/15">15</a><a class="" href="/blog/page/16">16</a><a class="" href="/blog/page/17">17</a><a class="" href="/blog/page/18">18</a><a class="" href="/blog/page/19">19</a><a class="" href="/blog/page/20">20</a><a class="" href="/blog/page/21">21</a><a class="" href="/blog/page/22">22</a><a class="" href="/blog/page/23">23</a><a class="" href="/blog/page/24">24</a><a class="" href="/blog/page/25">25</a><a class="" href="/blog/page/26">26</a><a class="" href="/blog/page/27">27</a><a class="" href="/blog/page/28">28</a><a class="" href="/blog/page/29">29</a><a class="" href="/blog/page/30">30</a><a class="" href="/blog/page/31">31</a><a class="" href="/blog/page/32">32</a><a class="" href="/blog/page/33">33</a><a class="" href="/blog/page/34">34</a><a class="" href="/blog/page/35">35</a><a class="" href="/blog/page/36">36</a><a class="" href="/blog/page/37">37</a><a class="" href="/blog/page/38">38</a><a class="" href="/blog/page/39">39</a><a class="" href="/blog/page/40">40</a><a class="" href="/blog/page/41">41</a><a class="" href="/blog/page/42">42</a><a class="" href="/blog/page/43">43</a><a class="" href="/blog/page/44">44</a><a class="" href="/blog/page/45">45</a><a class="" href="/blog/page/46">46</a><a class="" href="/blog/page/47">47</a><a class="" href="/blog/page/48">48</a><a class="" href="/blog/page/49">49</a><a class="" href="/blog/page/50">50</a><a class="" href="/blog/page/51">51</a><a class="" href="/blog/page/52">52</a><a class="" href="/blog/page/53">53</a><a class="" href="/blog/page/54">54</a><a class="" href="/blog/page/55">55</a><a class="" href="/blog/page/56">56</a><a class="" href="/blog/page/57">57</a><a class="" href="/blog/page/58">58</a><a class="" href="/blog/page/59">59</a><a class="" href="/blog/page/60">60</a><a class="" href="/blog/page/61">61</a><a class="" href="/blog/page/62">62</a><a class="" href="/blog/page/63">63</a><a class="" href="/blog/page/64">64</a><a class="" href="/blog/page/65">65</a><a class="" href="/blog/page/66">66</a><a class="" href="/blog/page/67">67</a><a class="" href="/blog/page/68">68</a><a class="" href="/blog/page/69">69</a><a class="" href="/blog/page/70">70</a><a class="" href="/blog/page/71">71</a><a class="" href="/blog/page/72">72</a><a class="" href="/blog/page/73">73</a><a class="" href="/blog/page/74">74</a><a class="" href="/blog/page/75">75</a><a class="" href="/blog/page/76">76</a><a class="" href="/blog/page/77">77</a><a class="" href="/blog/page/78">78</a><a class="" href="/blog/page/79">79</a><a class="" href="/blog/page/80">80</a><a class="" href="/blog/page/81">81</a></div></div></div></div><script src="/_next/static/chunks/webpack-3bbba27772baeadb.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/4cb872a2a77e328a.css\",\"style\"]\n2:HL[\"/_next/static/css/dabd5e64a469b0e1.css\",\"style\"]\n3:HL[\"/_next/static/css/be8a59717d6d5849.css\",\"style\"]\n4:HL[\"/_next/static/css/97e0a79122e618e4.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"5:I[1200,[],\"\"]\n8:I[6405,[],\"\"]\na:I[5337,[],\"\"]\nb:I[156,[\"156\",\"static/chunks/156-2b9f703633e98ef7.js\",\"836\",\"static/chunks/836-7e37630a3372363c.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-2829e3c199d313ca.js\"],\"\"]\nd:I[4688,[],\"\"]\n9:[\"slug\",\"runninglocal-llm-nvidia-5080-for-coding\",\"d\"]\ne:[]\n"])</script><script>self.__next_f.push([1,"0:[\"$\",\"$L5\",null,{\"buildId\":\"bWiF5I26zELnCuh0Cm-Zx\",\"assetPrefix\":\"\",\"urlParts\":[\"\",\"blog\",\"runninglocal-llm-nvidia-5080-for-coding\"],\"initialTree\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"runninglocal-llm-nvidia-5080-for-coding\",\"d\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":\\\"runninglocal-llm-nvidia-5080-for-coding\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"runninglocal-llm-nvidia-5080-for-coding\",\"d\"],{\"children\":[\"__PAGE__\",{},[[\"$L6\",\"$L7\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/be8a59717d6d5849.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/97e0a79122e618e4.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]],null],null]},[null,[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\",\"$9\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/dabd5e64a469b0e1.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"div\",null,{\"className\":\"layout_blogbodystyle___Uc1w\",\"children\":[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]}]],null],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/4cb872a2a77e328a.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"layout_htmlstyle__PseMz\",\"children\":[\"$\",\"body\",null,{\"className\":\"layout_bodystyle__4ncsS\",\"children\":[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"style\":{\"display\":\"flex\",\"alignItems\":\"center\",\"justifyContent\":\"center\",\"height\":\"100vh\"},\"children\":[\"$\",\"div\",null,{\"style\":{\"width\":\"50%\",\"height\":\"20%\",\"backgroundColor\":\"#ffeded\",\"borderRadius\":12,\"padding\":12,\"textAlign\":\"center\"},\"children\":[[\"$\",\"h1\",null,{\"children\":\"Not Found\"}],[\"$\",\"p\",null,{\"children\":\"Could not find requested resource\"}],[\"$\",\"$Lb\",null,{\"href\":\"/\",\"children\":\"Return Home\"}]]}]}],\"notFoundStyles\":[]}]}]}]],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Lc\"],\"globalErrorComponent\":\"$d\",\"missingSlots\":\"$We\"}]\n"])</script><script>self.__next_f.push([1,"f:I[836,[\"156\",\"static/chunks/156-2b9f703633e98ef7.js\",\"836\",\"static/chunks/836-7e37630a3372363c.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-2829e3c199d313ca.js\"],\"Image\"]\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"div\",null,{\"className\":\"BlogBody_BlogBody__600mT\",\"children\":[[\"$\",\"header\",null,{\"className\":\"BlogBody_siteTitle__f7uyb\",\"children\":\"Patrick Desjardins Blog\"}],[\"$\",\"nav\",null,{\"children\":[\"$\",\"ul\",null,{\"className\":\"BlogBody_navLinks__ZV12t\",\"children\":[\"$\",\"li\",null,{\"className\":\"BlogBody_navLinkItem__Pml2e\",\"children\":[[\"$\",\"$Lb\",null,{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/\",\"children\":\"Main Page\"}],[\"$\",\"$Lb\",null,{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog\",\"children\":\"Blog\"}],[\"$\",\"$Lb\",null,{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/search\",\"children\":\"Search\"}],[[\"$\",\"$Lb\",\"2026\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2026\",\"children\":2026}],[\"$\",\"$Lb\",\"2025\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2025\",\"children\":2025}],[\"$\",\"$Lb\",\"2024\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2024\",\"children\":2024}],[\"$\",\"$Lb\",\"2023\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2023\",\"children\":2023}],[\"$\",\"$Lb\",\"2022\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2022\",\"children\":2022}],[\"$\",\"$Lb\",\"2021\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2021\",\"children\":2021}],[\"$\",\"$Lb\",\"2020\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2020\",\"children\":2020}],[\"$\",\"$Lb\",\"2019\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2019\",\"children\":2019}],[\"$\",\"$Lb\",\"2018\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2018\",\"children\":2018}],[\"$\",\"$Lb\",\"2017\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2017\",\"children\":2017}],[\"$\",\"$Lb\",\"2016\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2016\",\"children\":2016}],[\"$\",\"$Lb\",\"2015\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2015\",\"children\":2015}],[\"$\",\"$Lb\",\"2014\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2014\",\"children\":2014}],[\"$\",\"$Lb\",\"2013\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2013\",\"children\":2013}],[\"$\",\"$Lb\",\"2012\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2012\",\"children\":2012}],[\"$\",\"$Lb\",\"2011\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2011\",\"children\":2011}]]]}]}]}],[\"$\",\"div\",null,{\"className\":\"BlogBody_blogPictureContainer__IAbPL\",\"children\":[\"$\",\"$Lf\",null,{\"className\":\"BlogBody_blogTopPicture__L6lao\",\"alt\":\"Patrick Desjardins picture from a conference\",\"src\":\"/images/backgrounds/patrickdesjardins_conference_bw.webp\",\"width\":800,\"height\":260}]}],[\"$\",\"main\",null,{\"className\":\"BlogBody_main__XrdKY\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"BlogBody_heading__bYRBe\",\"children\":\"Running Local LLM on a Nvidia 5080 for Coding\"}],[\"$\",\"div\",null,{\"className\":\"Page_blogPostContainer__AUIcf\",\"children\":[[\"$\",\"p\",null,{\"className\":\"Page_blogPostDate__wVWWB\",\"children\":[\"Posted on: \",\"2026-02-09\"]}],[[\"$\",\"h1\",null,{\"children\":\"Goal\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Few weekends ago, I wanted to see what would be the best model of coding that I could run locally on my Intel 9 with 32 gig of ram and my Nvidia 5080 with 8gig of vram. The idea was to run \",[\"$\",\"a\",null,{\"href\":\"https://opencode.ai/\",\"children\":\"Open Code\"}],\" to QWEN 3.0 to have a local Claude. The result was impressive in term of how fast the response occured but the final product wasn't the quality of Claude.\"]}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"How to do it?\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"I started with QWEN 2.5 and the result was horrible in term of connection with tools like simply reading and writing files. It was fine with general question but that wasn't the goal.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Moving to Qwen3-8B-AWQ did the job but with some tweaking, otherwise it was crashing or returning response too slow.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Installation:\"}],\"\\n\",[\"$\",\"pre\",null,{\"className\":\"language-plaintext\",\"children\":[\"$\",\"code\",null,{\"className\":\"language-plaintext code-highlight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"sh\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"nvidia-smi\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"pip install --upgrade pip\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"pip install torch torchvision torchaudio \\\\\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --index-url https://download.pytorch.org/whl/cu121\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"pip install vllm\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"pip install autoawq\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"pip install huggingface_hub\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"huggingface-cli login\\n\"}]]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Everytime to use:\"}],\"\\n\",[\"$\",\"pre\",null,{\"className\":\"language-sh\",\"children\":[\"$\",\"code\",null,{\"className\":\"language-sh code-highlight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token builtin class-name\",\"children\":\"cd\"}],\" ~/llm/llm\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"pyenv activate vllm\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token builtin class-name\",\"children\":\"unset\"}],\" VLLM_ATTENTION_BACKEND\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token builtin class-name\",\"children\":\"unset\"}],\" VLLM_USE_FLASHINFER_SAMPLER\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token function\",\"children\":\"pkill\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token parameter variable\",\"children\":\"-f\"}],\" vllm\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"vllm serve \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\\\\\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"  Qwen/Qwen3-8B-AWQ \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\\\\\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"  \",[\"$\",\"span\",null,{\"className\":\"token parameter variable\",\"children\":\"--quantization\"}],\" awq \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\\\\\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"  \",[\"$\",\"span\",null,{\"className\":\"token parameter variable\",\"children\":\"--dtype\"}],\" float16 \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\\\\\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"  --gpu-memory-utilization \",[\"$\",\"span\",null,{\"className\":\"token number\",\"children\":\"0.9\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\\\\\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"  --max-model-len \",[\"$\",\"span\",null,{\"className\":\"token number\",\"children\":\"32768\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\\\\\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"  \",[\"$\",\"span\",null,{\"className\":\"token parameter variable\",\"children\":\"--port\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token number\",\"children\":\"7555\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\\\\\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"  --api-key \",[\"$\",\"span\",null,{\"className\":\"token string\",\"children\":\"\\\"opencode_local\\\"\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\\\\\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"  --enable-auto-tool-choice \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\\\\\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"  --tool-call-parser hermes \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\\\\\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --reasoning-parser qwen3\\n\"}]]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Loading everything takes less than 30 seconds:\"}],\"\\n\",[\"$\",\"pre\",null,{\"className\":\"language-plaintext\",\"children\":[\"$\",\"code\",null,{\"className\":\"language-plaintext code-highlight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(EngineCore_DP0 pid=36318) INFO 02-03 19:53:24 [default_loader.py:291] Loading weights took 4.14 seconds\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(EngineCore_DP0 pid=36318) INFO 02-03 19:53:24 [gpu_model_runner.py:3905] Model loading took 5.71 GiB memory and 5.326229 seconds\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(EngineCore_DP0 pid=36318) INFO 02-03 19:53:30 [backends.py:644] Using cache directory: /home/miste/.cache/vllm/torch_compile_cache/252055f4c9/rank_0_0/backbone for vLLM's torch.compile\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(EngineCore_DP0 pid=36318) INFO 02-03 19:53:30 [backends.py:704] Dynamo bytecode transform time: 5.01 s\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(EngineCore_DP0 pid=36318) INFO 02-03 19:53:35 [backends.py:226] Directly load the compiled graph(s) for compile range (1, 2048) from the cache, took 1.098 s\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(EngineCore_DP0 pid=36318) INFO 02-03 19:53:35 [monitor.py:34] torch.compile takes 6.11 s in total\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(EngineCore_DP0 pid=36318) INFO 02-03 19:53:36 [gpu_worker.py:358] Available KV cache memory: 7.19 GiB\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(EngineCore_DP0 pid=36318) INFO 02-03 19:53:36 [kv_cache_utils.py:1305] GPU KV cache size: 52,368 tokens\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(EngineCore_DP0 pid=36318) INFO 02-03 19:53:36 [kv_cache_utils.py:1310] Maximum concurrency for 32,768 tokens per request: 1.60x\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(EngineCore_DP0 pid=36318) 2026-02-03 19:53:36,340 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(EngineCore_DP0 pid=36318) 2026-02-03 19:53:36,363 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:07\u003c00:00,  6.51it/s]\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"Capturing CUDA graphs (decode, FULL): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:05\u003c00:00,  6.77it/s]\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(EngineCore_DP0 pid=36318) INFO 02-03 19:53:49 [gpu_model_runner.py:4856] Graph capturing finished in 13 secs, took 0.00 GiB\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(EngineCore_DP0 pid=36318) INFO 02-03 19:53:49 [core.py:273] init engine (profile, create kv cache, warmup model) took 25.12 seconds\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(EngineCore_DP0 pid=36318) INFO 02-03 19:53:51 [vllm.py:630] Asynchronous scheduling is enabled.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=36148) INFO 02-03 19:53:51 [api_server.py:1014] Supported tasks: ['generate']\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=36148) WARNING 02-03 19:53:51 [model.py:1358] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=36148) INFO 02-03 19:53:51 [serving_responses.py:224] Using default chat sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=36148) INFO 02-03 19:53:51 [serving_engine.py:271] \\\"auto\\\" tool choice has been enabled.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=36148) INFO 02-03 19:53:51 [serving_engine.py:271] \\\"auto\\\" tool choice has been enabled.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=36148) INFO 02-03 19:53:51 [serving_chat.py:146] Using default chat sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=36148) INFO 02-03 19:53:51 [serving_chat.py:182] Warming up chat template processing...\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=36148) INFO 02-03 19:53:52 [chat_utils.py:599] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=36148) INFO 02-03 19:53:52 [serving_chat.py:218] Chat template warmup completed in 1254.3ms\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=36148) INFO 02-03 19:53:53 [serving_completion.py:78] Using default completion sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=36148) INFO 02-03 19:53:53 [serving_engine.py:271] \\\"auto\\\" tool choice has been enabled.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=36148) INFO 02-03 19:53:53 [serving_chat.py:146] Using default chat sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=36148) INFO 02-03 19:53:53 [api_server.py:1346] Starting vLLM API server 0 on http://0.0.0.0:7555\\n\"}]]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Configuring OpenCode:\"}],\"\\n\",[\"$\",\"pre\",null,{\"className\":\"language-plaintext\",\"children\":[\"$\",\"code\",null,{\"className\":\"language-plaintext code-highlight\",\"children\":[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"nano ~/.config/opencode/config.json\\n\"}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"By copying:\"}],\"\\n\",[\"$\",\"pre\",null,{\"className\":\"language-json\",\"children\":[\"$\",\"code\",null,{\"className\":\"language-json code-highlight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"{\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"  \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"$schema\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token string\",\"children\":\"\\\"https://opencode.ai/config.json\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"  \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"provider\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"{\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"    \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"vllm_local\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"{\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"      \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"npm\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token string\",\"children\":\"\\\"@ai-sdk/openai-compatible\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"      \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"name\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token string\",\"children\":\"\\\"vLLM (local)\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"      \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"options\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"{\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"        \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"baseURL\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token string\",\"children\":\"\\\"http://127.0.0.1:7555/v1\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"        \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"apiKey\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token string\",\"children\":\"\\\"opencode_local\\\"\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"      \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"}\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"      \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"models\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"{\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"        \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"Qwen/Qwen3-8B-AWQ\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"{\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"          \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"name\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token string\",\"children\":\"\\\"Qwen 3.0 (8B Agent)\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"          \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"tools\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"{\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"            \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"write\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token boolean\",\"children\":\"true\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"            \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"bash\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token boolean\",\"children\":\"true\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"            \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"read\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token boolean\",\"children\":\"true\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"            \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"edit\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token boolean\",\"children\":\"true\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"          \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"}\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"          \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"limit\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"{\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"            \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"context\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token number\",\"children\":\"32768\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"            \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"output\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token number\",\"children\":\"4096\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"          \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"}\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"          \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"supportsToolCalling\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token boolean\",\"children\":\"true\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"          \",[\"$\",\"span\",null,{\"className\":\"token property\",\"children\":\"\\\"supportsReasoning\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token operator\",\"children\":\":\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token boolean\",\"children\":\"true\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"        \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"}\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"      \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"}\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"    \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"}\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"  \",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"}\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"}\"}],\"\\n\"]}]]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The OpenCode configuration required a lot of trial and error. Even ChatGPT could not find the right configuration. Moving to QWEN 3.0 and explicitly enabling tools helped move things forward.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Then, running OpenCode. Here is a command that asks how many unit tests are in the repository.\"}],\"\\n\",[\"$\",\"video\",null,{\"src\":\"/videos/blog/LocalLLM.mp4\",\"controls\":true}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The full answer took 2 minutes and 22 seconds.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Here is the full transcript:\"}],\"\\n\",[\"$\",\"pre\",null,{\"className\":\"language-md\",\"children\":[\"$\",\"code\",null,{\"className\":\"language-md code-highlight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token title important\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"##\"}],\" User\"]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"How many tests in this repository?\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token hr punctuation\",\"children\":\"---\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token title important\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"##\"}],\" Assistant (Build · Qwen/Qwen3-8B-AWQ · 100.8s)\"]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token italic\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"_\"}],[\"$\",\"span\",null,{\"className\":\"token content\",\"children\":\"Thinking:\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"_\"}]]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"Okay, the user is asking how many tests are in the repository. Let me think about how to approach this.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"First, I remember that the project is a FastAPI application, and the documentation mentions testing. In the CLAUDE.md file, there are sections about testing, including commands to run tests and requirements for test coverage. \\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"The user probably wants to know the total number of tests, maybe to check if they meet the coverage requirements mentioned (minimum 76%). The test commands listed include using \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`uv run pytest`\"}],\" with options for coverage and speed. \\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"I need to find a way to count the tests. The \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`pytest`\"}],\" command can give a summary when run with the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`-v`\"}],\" flag, but maybe there's a better way. Alternatively, the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`pytest`\"}],\" command with \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`--help`\"}],\" might show options related to counting tests. Wait, the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`uv run pytest`\"}],\" command is mentioned, so maybe running \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`uv run pytest --help`\"}],\" could show options. But the user might not have pytest installed, but since the project uses \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`uv`\"}],\" (uvicorn), it's likely that pytest is installed as a dependency.\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"Wait, the user is asking for the number of tests, not to run them. So maybe the best approach is to check the test files. The project structure includes a \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`tests`\"}],\" directory, as mentioned in the CLAUDE.md under \\\"Development Commands\\\". The \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`tests/services`\"}],\" directory is mentioned, and there are specific test files like \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`test_database.py`\"}],\".\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"But how to count them without running the tests? The user might not have the environment set up, so I can't run the tests directly. However, the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`pytest`\"}],\" tool can list the tests when run with \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`--help`\"}],\" or \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`--collect-only`\"}],\", but that might not be straightforward. Alternatively, the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`pytest`\"}],\" command can be used with \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`--help`\"}],\" to see available options.\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"Wait, the user might be looking for the number of test files or test cases. The \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`pytest`\"}],\" command can count test cases using \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`--count`\"}],\" or other flags. Let me check the pytest documentation. Oh, right, \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`pytest`\"}],\" has a \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`--count`\"}],\" option to count the number of tests. But I need to confirm if that's available.\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"Alternatively, the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`pytest`\"}],\" command can be run with \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`--help`\"}],\" to see available options. So, the steps would be:\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token list punctuation\",\"children\":\"1.\"}],\" Check if \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`pytest`\"}],\" is installed. Since the project uses \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`uv`\"}],\" and the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`uv run pytest`\"}],\" command is mentioned, it's likely installed.\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token list punctuation\",\"children\":\"2.\"}],\" Run \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`uv run pytest --help`\"}],\" to see available options.\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token list punctuation\",\"children\":\"3.\"}],\" Use the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`--count`\"}],\" option to get the number of tests.\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"But the user might not have the environment set up, so maybe the best approach is to suggest running the test commands provided in the documentation. However, the user is asking for the number, not to run them. \\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"Alternatively, the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`pytest`\"}],\" command can be run with \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`--help`\"}],\" to see if there's an option to count tests. If not, maybe the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`pytest`\"}],\" command can be used with \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`--collect-only`\"}],\" to list all test files, which can then be counted. \\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"But without running the tests, it's hard to get the exact number. The user might need to run the tests to get the count. However, the answer should be based on the information provided in the CLAUDE.md. The documentation mentions that the test suite is run with \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`uv run pytest`\"}],\", and there are specific test files mentioned like \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`tests/services/test_database.py`\"}],\". \\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"Wait, the user is asking for the number of tests, but the CLAUDE.md doesn't specify the exact count. So, the answer would be that the number of tests can be determined by running \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`uv run pytest --count`\"}],\" or similar command. However, without actual execution, I can't provide the exact number. \\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"But the user might be expecting a specific number based on the project structure. The \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`tests/services`\"}],\" directory has multiple test files, but the exact count isn't given. Therefore, the correct approach is to inform the user that they need to run the test command to get the count, or check the test files. \\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"Alternatively, if the user is in a Git repository, they could use \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`git ls-files tests/`\"}],\" to list test files and count them. But that's not reliable as some tests might be in subdirectories. \\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"In conclusion, the answer should guide the user to run the test command to get the count, as the exact number isn't provided in the documentation.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token bold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"**\"}],[\"$\",\"span\",null,{\"className\":\"token content\",\"children\":\"Tool: bash\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"**\"}]]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token bold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"**\"}],[\"$\",\"span\",null,{\"className\":\"token content\",\"children\":\"Input:\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"**\"}]]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"json\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"{\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  \\\"command\\\": \\\"uv run pytest --help\\\",\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  \\\"description\\\": \\\"Check pytest options for test counting\\\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"}\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token bold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"**\"}],[\"$\",\"span\",null,{\"className\":\"token content\",\"children\":\"Output:\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"**\"}]]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"usage: pytest \",[\"$\",\"span\",null,{\"className\":\"token url\",\"children\":[\"[\",[\"$\",\"span\",null,{\"className\":\"token content\",\"children\":\"options\"}],\"] [\",[\"$\",\"span\",null,{\"className\":\"token variable\",\"children\":\"file_or_dir\"}],\"]\"]}],\" \",[\"$\",\"span\",null,{\"className\":\"token url\",\"children\":[\"[\",[\"$\",\"span\",null,{\"className\":\"token content\",\"children\":\"file_or_dir\"}],\"] [\",[\"$\",\"span\",null,{\"className\":\"token variable\",\"children\":\"...\"}],\"]\"]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"positional arguments:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  file_or_dir\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"general:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  -k EXPRESSION         Only run tests which match the given substring\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        expression. An expression is a Python evaluable\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        expression where all names are substring-matched against\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        test names and their parent classes. Example: -k\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        'test_method or test_other' matches all test functions\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        and classes whose name contains 'test_method' or\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        'test_other', while -k 'not test_method' matches those\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        that don't contain 'test_method' in their names. -k 'not\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        test_method and not test_other' will eliminate the\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        matches. Additionally keywords are matched to classes\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        and functions containing extra names in their\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        'extra_keyword_matches' set, as well as functions which\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        have names assigned directly to them. The matching is\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        case-insensitive.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  -m MARKEXPR           Only run tests matching given mark expression. For\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        example: -m 'mark1 and not mark2'.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --markers             show markers (builtin, plugin and per-project ones).\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  -x, --exitfirst       Exit instantly on first error or failed test\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --maxfail=num         Exit after first num failures or errors\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --strict-config       Enables the strict_config option\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --strict-markers      Enables the strict_markers option\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --strict              Enables the strict option\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --fixtures, --funcargs\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Show available fixtures, sorted by plugin appearance\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        (fixtures with leading '_' are only shown with '-v')\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --fixtures-per-test   Show fixtures per test\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --pdb                 Start the interactive Python debugger on errors or\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        KeyboardInterrupt\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --pdbcls=modulename:classname\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Specify a custom interactive Python debugger for use\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        with --pdb.For example:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        --pdbcls=IPython.terminal.debugger:TerminalPdb\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --trace               Immediately break when running each test\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --capture=method      Per-test capturing method: one of fd|sys|no|tee-sys\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  -s                    Shortcut for --capture=no\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --runxfail            Report the results of xfail tests as if they were not\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        marked\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --lf, --last-failed   Rerun only the tests that failed at the last run (or all\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        if none failed)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --ff, --failed-first  Run all tests, but run the last failures first. This may\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        re-order tests and thus lead to repeated fixture\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        setup/teardown.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --nf, --new-first     Run tests from new files first, then the rest of the\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        tests sorted by file mtime\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --cache-show=[CACHESHOW]\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Show cache contents, don't perform collection or tests.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Optional argument: glob (default: '*').\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --cache-clear         Remove all cache contents at start of test run\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --lfnf={all,none}, --last-failed-no-failures={all,none}\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"                        With \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"``--lf``\"}],\", determines whether to execute tests when\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        there are no previously (known) failures or when no\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"                        cached \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"``lastfailed``\"}],\" data was found. \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"``all``\"}],\" (the\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"                        default) runs the full test suite again. \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"``none``\"}],\" just\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        emits a message about no known failures and exits\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        successfully.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --sw, --stepwise      Exit on test failure and continue from last failing test\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        next time\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --sw-skip, --stepwise-skip\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Ignore the first failing test but stop on the next\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        failing test. Implicitly enables --stepwise.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --sw-reset, --stepwise-reset\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Resets stepwise state, restarting the stepwise workflow.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Implicitly enables --stepwise.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"Reporting:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --durations=N         Show N slowest setup/test durations (N=0 for all)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --durations-min=N     Minimal duration in seconds for inclusion in slowest\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        list. Default: 0.005 (or 0.0 if -vv is given).\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  -v, --verbose         Increase verbosity\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --no-header           Disable header\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --no-summary          Disable summary\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --no-fold-skipped     Do not fold skipped tests in short summary.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --force-short-summary\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Force condensed summary output regardless of verbosity\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        level.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  -q, --quiet           Decrease verbosity\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --verbosity=VERBOSE   Set verbosity. Default: 0.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  -r chars              Show extra test summary info as specified by chars:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        (f)ailed, (E)rror, (s)kipped, (x)failed, (X)passed,\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        (p)assed, (P)assed with output, (a)ll except passed\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        (p/P), or (A)ll. (w)arnings are enabled by default (see\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        --disable-warnings), 'N' can be used to reset the list.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        (default: 'fE').\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --disable-warnings, --disable-pytest-warnings\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Disable warnings summary\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  -l, --showlocals      Show locals in tracebacks (disabled by default)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --no-showlocals       Hide locals in tracebacks (negate --showlocals passed\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        through addopts)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --tb=style            Traceback print mode (auto/long/short/line/native/no)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --xfail-tb            Show tracebacks for xfail (as long as --tb != no)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --show-capture={no,stdout,stderr,log,all}\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Controls how captured stdout/stderr/log is shown on\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        failed tests. Default: all.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --full-trace          Don't cut any tracebacks (default is to cut)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --color=color         Color terminal output (yes/no/auto)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --code-highlight={yes,no}\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Whether code should be highlighted (only if --color is\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        also enabled). Default: yes.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --pastebin=mode       Send failed|all info to bpaste.net pastebin service\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --junit-xml=path      Create junit-xml style report file at given path\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --junit-prefix=str    Prepend prefix to classnames in junit-xml output\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"pytest-warnings:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  -W PYTHONWARNINGS, --pythonwarnings=PYTHONWARNINGS\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Set which warnings to report, see -W option of Python\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        itself\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"collection:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --collect-only, --co  Only collect tests, don't execute them\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --pyargs              Try to interpret all arguments as Python packages\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --ignore=path         Ignore path during collection (multi-allowed)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --ignore-glob=path    Ignore path pattern during collection (multi-allowed)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --deselect=nodeid_prefix\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Deselect item (via node id prefix) during collection\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        (multi-allowed)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --confcutdir=dir      Only load conftest.py's relative to specified dir\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --noconftest          Don't load any conftest.py files\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --keep-duplicates     Keep duplicate tests\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --collect-in-virtualenv\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Don't ignore tests in a local virtualenv directory\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --continue-on-collection-errors\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Force test execution even if collection errors occur\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --import-mode={prepend,append,importlib}\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Prepend/append to sys.path when importing test modules\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        and conftest files. Default: prepend.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --doctest-modules     Run doctests in all .py modules\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --doctest-report={none,cdiff,ndiff,udiff,only_first_failure}\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Choose another output format for diffs on doctest\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        failure\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --doctest-glob=pat    Doctests file matching pattern, default: test*.txt\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --doctest-ignore-import-errors\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Ignore doctest collection errors\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --doctest-continue-on-failure\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        For a given doctest, continue to run after the first\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        failure\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"test session debugging and configuration:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  -c FILE, --config-file=FILE\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"                        Load configuration from \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`FILE`\"}],\" instead of trying to\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        locate one of the implicit configuration files.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --rootdir=ROOTDIR     Define root directory for tests. Can be relative path:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        'root_dir', './root_dir', 'root_dir/another_dir/';\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        absolute path: '/home/user/root_dir'; path with\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        variables: '$HOME/root_dir'.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --basetemp=dir        Base temporary directory for this test run. (Warning:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        this directory is removed if it exists.)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  -V, --version         Display pytest version and information about plugins.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        When given twice, also display information about\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        plugins.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  -h, --help            Show help message and configuration info\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  -p name               Early-load given plugin module name or entry point\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        (multi-allowed). To avoid loading of plugins, use the\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"                        \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`no:`\"}],\" prefix, e.g. \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`no:doctest`\"}],\". See also --disable-\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        plugin-autoload.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --disable-plugin-autoload\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Disable plugin auto-loading through entry point\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        packaging metadata. Only plugins explicitly specified in\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        -p or env var PYTEST_PLUGINS will be loaded.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --trace-config        Trace considerations of conftest.py files\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --debug=[DEBUG_FILE_NAME]\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Store internal tracing debug information in this log\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        file. This file is opened with 'w' and truncated as a\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        result, care advised. Default: pytestdebug.log.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  -o OVERRIDE_INI, --override-ini=OVERRIDE_INI\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Override configuration option with \\\"option=value\\\" style,\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"                        e.g. \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`-o strict_xfail=True -o cache_dir=cache`\"}],\".\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --assert=MODE         Control assertion debugging tools.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        'plain' performs no assertion debugging.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        'rewrite' (the default) rewrites assert statements in\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        test modules on import to provide assert expression\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        information.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --setup-only          Only setup fixtures, do not execute tests\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --setup-show          Show setup of fixtures while executing tests\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --setup-plan          Show what fixtures and tests would be executed but don't\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        execute anything\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"logging:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --log-level=LEVEL     Level of messages to catch/display. Not set by default,\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        so it depends on the root/parent log handler's effective\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        level, where it is \\\"WARNING\\\" by default.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --log-format=LOG_FORMAT\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Log format used by the logging module\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --log-date-format=LOG_DATE_FORMAT\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Log date format used by the logging module\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --log-cli-level=LOG_CLI_LEVEL\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        CLI logging level\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --log-cli-format=LOG_CLI_FORMAT\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Log format used by the logging module\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --log-cli-date-format=LOG_CLI_DATE_FORMAT\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Log date format used by the logging module\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --log-file=LOG_FILE   Path to a file when logging will be written to\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --log-file-mode={w,a}\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Log file open mode\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --log-file-level=LOG_FILE_LEVEL\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Log file logging level\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --log-file-format=LOG_FILE_FORMAT\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Log format used by the logging module\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --log-file-date-format=LOG_FILE_DATE_FORMAT\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Log date format used by the logging module\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --log-auto-indent=LOG_AUTO_INDENT\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Auto-indent multiline messages passed to the logging\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        module. Accepts true|on, false|off or an integer.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --log-disable=LOGGER_DISABLE\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Disable a logger by name. Can be passed multiple times.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"asyncio:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --asyncio-mode=MODE   'auto' - for automatically handling all async functions\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        by the plugin\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        'strict' - for autoprocessing disabling (useful if\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        different async frameworks should be tested together,\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        e.g. both pytest-asyncio and pytest-trio are used in the\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        same project)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --asyncio-debug       enable asyncio debug mode for the default event loop\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"coverage reporting with distributed testing support:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --cov=[SOURCE]        Path or package name to measure during execution (multi-\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        allowed). Use --cov= to not do any source filtering and\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        record everything.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --cov-reset           Reset cov sources accumulated in options so far.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --cov-report=TYPE     Type of report to generate: term, term-missing,\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        annotate, html, xml, json, markdown, markdown-append,\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        lcov (multi-allowed). term, term-missing may be followed\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        by \\\":skip-covered\\\". annotate, html, xml, json, markdown,\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        markdown-append and lcov may be followed by \\\":DEST\\\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        where DEST specifies the output location. Use --cov-\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        report= to not generate any output.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --cov-config=PATH     Config file for coverage. Default: .coveragerc\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --no-cov-on-fail      Do not report coverage if test run fails. Default: False\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --no-cov              Disable coverage report completely (useful for\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        debuggers). Default: False\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --cov-fail-under=MIN  Fail if the total coverage is less than MIN.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --cov-append          Do not delete coverage but append to current. Default:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        False\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --cov-branch          Enable branch coverage.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --cov-precision=COV_PRECISION\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Override the reporting precision.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  --cov-context=CONTEXT\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Dynamic contexts to use. \\\"test\\\" for now.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"[pytest] configuration options in the first pytest.toml|pytest.ini|tox.ini|setup.cfg|pyproject.toml file found:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  markers (linelist):   Register new markers for test functions\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  empty_parameter_set_mark (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Default marker for empty parametersets\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"  strict_config (bool): Any warnings encountered while parsing the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`pytest`\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        section of the configuration file raise errors\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  strict_markers (bool):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"                        Markers not registered in the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`markers`\"}],\" section of the\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        configuration file raise errors\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  strict (bool):        Enables all strictness options, currently:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        strict_config, strict_markers, strict_xfail,\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        strict_parametrization_ids\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  filterwarnings (linelist):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Each line specifies a pattern for\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        warnings.filterwarnings. Processed after\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        -W/--pythonwarnings.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  norecursedirs (args): Directory patterns to avoid for recursion\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  testpaths (args):     Directories to search for tests when no files or\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        directories are given on the command line\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  collect_imported_tests (bool):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Whether to collect tests in imported modules outside\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"                        \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`testpaths`\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  consider_namespace_packages (bool):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Consider namespace packages when resolving module names\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        during import\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  usefixtures (args):   List of default fixtures to be used with this project\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  python_files (args):  Glob-style file patterns for Python test module\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        discovery\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  python_classes (args):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Prefixes or glob names for Python test class discovery\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  python_functions (args):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Prefixes or glob names for Python test function and\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        method discovery\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  disable_test_id_escaping_and_forfeit_all_rights_to_community_support (bool):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Disable string escape non-ASCII characters, might cause\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        unwanted side effects(use at your own risk)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  strict_parametrization_ids (bool):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Emit an error if non-unique parameter set IDs are\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        detected\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  console_output_style (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Console output: \\\"classic\\\", or with additional progress\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        information (\\\"progress\\\" (percentage) | \\\"count\\\" |\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        \\\"progress-even-when-capture-no\\\" (forces progress even\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        when capture=no)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  verbosity_test_cases (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Specify a verbosity level for test case execution,\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        overriding the main level. Higher levels will provide\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        more detailed information about each test case executed.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  strict_xfail (bool):  Default for the strict parameter of xfail markers when\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        not given explicitly (default: False) (alias:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        xfail_strict)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  tmp_path_retention_count (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"                        How many sessions should we keep the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`tmp_path`\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"                        directories, according to \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`tmp_path_retention_policy`\"}],\".\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  tmp_path_retention_policy (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"                        Controls which directories created by the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`tmp_path`\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        fixture are kept around, based on test outcome.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        (all/failed/none)\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  enable_assertion_pass_hook (bool):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Enables the pytest_assertion_pass hook. Make sure to\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        delete any previously generated pyc cache files.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  truncation_limit_lines (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Set threshold of LINES after which truncation will take\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        effect\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  truncation_limit_chars (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Set threshold of CHARS after which truncation will take\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        effect\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  verbosity_assertions (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Specify a verbosity level for assertions, overriding the\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        main level. Higher levels will provide more detailed\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        explanation when an assertion fails.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  junit_suite_name (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Test suite name for JUnit report\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  junit_logging (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Write captured log messages to JUnit report: one of\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        no|log|system-out|system-err|out-err|all\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  junit_log_passing_tests (bool):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Capture log information for passing tests to JUnit\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        report:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  junit_duration_report (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Duration time to report: one of total|call\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  junit_family (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Emit XML for schema: one of legacy|xunit1|xunit2\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  doctest_optionflags (args):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Option flags for doctests\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  doctest_encoding (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Encoding used for doctest files\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  cache_dir (string):   Cache directory path\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  log_level (string):   Default value for --log-level\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  log_format (string):  Default value for --log-format\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  log_date_format (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Default value for --log-date-format\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  log_cli (bool):       Enable log display during test run (also known as \\\"live\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        logging\\\")\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  log_cli_level (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Default value for --log-cli-level\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  log_cli_format (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Default value for --log-cli-format\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  log_cli_date_format (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Default value for --log-cli-date-format\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  log_file (string):    Default value for --log-file\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  log_file_mode (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Default value for --log-file-mode\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  log_file_level (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Default value for --log-file-level\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  log_file_format (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Default value for --log-file-format\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  log_file_date_format (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Default value for --log-file-date-format\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  log_auto_indent (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Default value for --log-auto-indent\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  faulthandler_timeout (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Dump the traceback of all threads if a test takes more\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        than TIMEOUT seconds to finish\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  faulthandler_exit_on_timeout (bool):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Exit the test process if a test takes more than\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        faulthandler_timeout seconds to finish\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  verbosity_subtests (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Specify verbosity level for subtests. Higher levels will\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        generate output for passed subtests. Failed subtests are\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        always reported.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  addopts (args):       Extra command line options\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  minversion (string):  Minimally required pytest version\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  pythonpath (paths):   Add paths to sys.path\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  required_plugins (args):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Plugins that must be present for pytest to run\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  anyio_mode (string):  AnyIO plugin mode (either \\\"strict\\\" or \\\"auto\\\")\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  mock_traceback_monkeypatch (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Monkeypatch the mock library to improve reporting of the\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        assert_called_... methods\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  mock_use_standalone_module (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        Use standalone \\\"mock\\\" (from PyPI) instead of builtin\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        \\\"unittest.mock\\\" on Python 3\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  asyncio_mode (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        default value for --asyncio-mode\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  asyncio_debug (bool): enable asyncio debug mode for the default event loop\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  asyncio_default_fixture_loop_scope (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        default scope of the asyncio event loop used to execute\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        async fixtures\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  asyncio_default_test_loop_scope (string):\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        default scope of the asyncio event loop used to execute\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"                        tests\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"Environment variables:\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  CI                       When set to a non-empty value, pytest knows it is running in a CI process and does not truncate summary info\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  BUILD_NUMBER             Equivalent to CI\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  PYTEST_ADDOPTS           Extra command line options\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  PYTEST_PLUGINS           Comma-separated plugins to load during startup\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  PYTEST_DISABLE_PLUGIN_AUTOLOAD Set to disable plugin auto-loading\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  PYTEST_DEBUG             Set to enable debug tracing of pytest's internals\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  PYTEST_DEBUG_TEMPROOT    Override the system temporary directory\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  PYTEST_THEME             The Pygments style to use for code output\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  PYTEST_THEME_MODE        Set the PYTEST_THEME to be either 'dark' or 'light'\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"to see available markers type: pytest --markers\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"to see available fixtures type: pytest --fixtures\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(shown according to specified file_or_dir or current dir if not specified; fixtures with leading '_' are only shown with the '-v' option\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token hr punctuation\",\"children\":\"---\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token title important\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"##\"}],\" Assistant (Build · Qwen/Qwen3-8B-AWQ · 29.8s)\"]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token tag\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token tag\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\u003c\"}],\"think\"]}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\u003e\"}]]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"Okay, the user wants to know how many tests are in the repository. Let me check the information provided.\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"In the CLAUDE.md file, there's a section about testing. It mentions running tests with \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`uv run pytest`\"}],\" and specifies that the test suite has a minimum coverage of 76%. There's also a note about running specific test files, like \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`tests/services/test_database.py`\"}],\".\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"The user's question is about the number of tests. The documentation doesn't explicitly state the count, but it does mention that tests are run with \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`uv run pytest`\"}],\". To find the number of tests, I should check the test files. The \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`tests`\"}],\" directory likely contains multiple test files. For example, \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`test_database.py`\"}],\" is mentioned, and there might be others like \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`test_queue.py`\"}],\" or \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`test_streaming.py`\"}],\" based on the project structure.\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"Since the user can't run the tests directly, I can infer that the number of tests is determined by the number of test files in the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`tests`\"}],\" directory. The exact count isn't provided, but the answer should guide the user to check the test files or run the test command to get the count. However, the user might need to run \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`uv run pytest --count`\"}],\" or use a tool like \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`find`\"}],\" to count the test files. Alternatively, the answer could be that the number of tests is determined by the test files in the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`tests`\"}],\" directory, and the exact count can be found by listing those files.\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token tag\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token tag\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\u003c/\"}],\"think\"]}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\u003e\"}]]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token bold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"**\"}],[\"$\",\"span\",null,{\"className\":\"token content\",\"children\":\"Tool: bash\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"**\"}]]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token bold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"**\"}],[\"$\",\"span\",null,{\"className\":\"token content\",\"children\":\"Input:\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"**\"}]]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"json\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"{\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  \\\"command\\\": \\\"find tests/ -name \\\\\\\"test_*.py\\\\\\\" | wc -l\\\",\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"  \\\"description\\\": \\\"Count test files in tests directory\\\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"}\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token bold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"**\"}],[\"$\",\"span\",null,{\"className\":\"token content\",\"children\":\"Output:\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"**\"}]]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"20\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token hr punctuation\",\"children\":\"---\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token title important\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"##\"}],\" Assistant (Build · Qwen/Qwen3-8B-AWQ · 12.1s)\"]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token tag\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token tag\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\u003c\"}],\"think\"]}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\u003e\"}]]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"Okay, the user asked how many tests are in the repository. I first checked the pytest help to see if there was a way to count tests directly, but that didn't give the exact number. Then I decided to count the test files in the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`tests`\"}],\" directory. Using the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`find`\"}],\" command, I located all files matching \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`test_*.py`\"}],\" and counted them. The result was 20 files. So, there are 20 test files in the repository. The answer is 20.\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token tag\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token tag\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\u003c/\"}],\"think\"]}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"\u003e\"}]]}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\"There are \",[\"$\",\"span\",null,{\"className\":\"token bold\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"**\"}],[\"$\",\"span\",null,{\"className\":\"token content\",\"children\":\"20 test files\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"**\"}]]}],\" in the repository, matching the pattern \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`test_*.py`\"}],\" in the \",[\"$\",\"span\",null,{\"className\":\"token code-snippet code keyword\",\"children\":\"`tests/`\"}],\" directory.\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token hr punctuation\",\"children\":\"---\"}],\"\\n\"]}]]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The problem is how verbose the model is and how inaccurate the initial answer was, since I wanted to know the number of tests, not the number of test files. Adding a second prompt specifying the total number of tests inside those files resulted in the model trying a few approaches using pytest.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"It took three prompts, with me explicitly telling the model that files starting with \",[\"$\",\"code\",null,{\"children\":\"test_\"}],\" are test files and that inside those files there are many test functions also starting with \",[\"$\",\"code\",null,{\"children\":\"test_\"}],\". From there, I finally got \",[\"$\",\"code\",null,{\"children\":\"427\"}],\" tests, which is a good answer.\"]}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Speed\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Here is a copy of the logs of the LLM during the previous talk with OpenCode:\"}],\"\\n\",[\"$\",\"pre\",null,{\"className\":\"language-plaintext\",\"children\":[\"$\",\"code\",null,{\"className\":\"language-plaintext code-highlight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=21042) INFO:     127.0.0.1:38596 - \\\"POST /v1/chat/completions HTTP/1.1\\\" 200 OK\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=21042) INFO 02-03 20:23:46 [loggers.py:257] Engine 000: Avg prompt throughput: 1682.8 tokens/s, Avg generation throughput: 9.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 48.4%, Prefix cache hit rate: 0.0%\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=21042) INFO 02-03 20:23:56 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 48.7%, Prefix cache hit rate: 0.0%\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=21042) INFO 02-03 20:24:07 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 8.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 49.0%, Prefix cache hit rate: 0.0%\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=21042) INFO 02-03 20:24:17 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 49.2%, Prefix cache hit rate: 0.0%\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=21042) INFO 02-03 20:24:27 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 49.5%, Prefix cache hit rate: 0.0%\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=21042) INFO 02-03 20:24:37 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 10.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 49.7%, Prefix cache hit rate: 0.0%\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=21042) INFO 02-03 20:24:47 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 50.1%, Prefix cache hit rate: 0.0%\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=21042) INFO 02-03 20:24:57 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 50.4%, Prefix cache hit rate: 0.0%\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=21042) INFO 02-03 20:25:07 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 11.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 50.8%, Prefix cache hit rate: 0.0%\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"(APIServer pid=21042) INFO:     127.0.0.1:38596 - \\\"POST /v1/chat/completions HTTP/1.1\\\" 200 OK\\n\"}]]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The 10 tokens per second is slow but not terrible. I was surprise to get such good result on my machine.\"}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Conclusion\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"QWEN 3.0 is a good model, but 8B parameters is not ideal. That said, it runs at $0, understands me, and can interact with the source code like Claude. While not extremely useful yet, having a local specialized model running is very interesting.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"I could see having a financial model, a coding model, and other specialized models that we can plug and play locally for specific tasks, which would help quite a lot in reducing costs in the long term.\"}]]]}]]}],[\"$\",\"div\",null,{\"className\":\"BlogBody_paginationBar__1gsMc\",\"children\":[[\"$\",\"div\",null,{\"className\":\"BlogBody_paginationTitle__H_eFX\",\"children\":\"Chronological Blog Articles by Page\"}],[\"$\",\"div\",null,{\"className\":\"BlogBody_paginationLinks__nk8zd\",\"children\":[[\"$\",\"$Lb\",\"1\",{\"className\":\"\",\"href\":\"/blog/page/1\",\"children\":1}],[\"$\",\"$Lb\",\"2\",{\"className\":\"\",\"href\":\"/blog/page/2\",\"children\":2}],[\"$\",\"$Lb\",\"3\",{\"className\":\"\",\"href\":\"/blog/page/3\",\"children\":3}],[\"$\",\"$Lb\",\"4\",{\"className\":\"\",\"href\":\"/blog/page/4\",\"children\":4}],[\"$\",\"$Lb\",\"5\",{\"className\":\"\",\"href\":\"/blog/page/5\",\"children\":5}],[\"$\",\"$Lb\",\"6\",{\"className\":\"\",\"href\":\"/blog/page/6\",\"children\":6}],[\"$\",\"$Lb\",\"7\",{\"className\":\"\",\"href\":\"/blog/page/7\",\"children\":7}],[\"$\",\"$Lb\",\"8\",{\"className\":\"\",\"href\":\"/blog/page/8\",\"children\":8}],[\"$\",\"$Lb\",\"9\",{\"className\":\"\",\"href\":\"/blog/page/9\",\"children\":9}],[\"$\",\"$Lb\",\"10\",{\"className\":\"\",\"href\":\"/blog/page/10\",\"children\":10}],[\"$\",\"$Lb\",\"11\",{\"className\":\"\",\"href\":\"/blog/page/11\",\"children\":11}],[\"$\",\"$Lb\",\"12\",{\"className\":\"\",\"href\":\"/blog/page/12\",\"children\":12}],[\"$\",\"$Lb\",\"13\",{\"className\":\"\",\"href\":\"/blog/page/13\",\"children\":13}],[\"$\",\"$Lb\",\"14\",{\"className\":\"\",\"href\":\"/blog/page/14\",\"children\":14}],[\"$\",\"$Lb\",\"15\",{\"className\":\"\",\"href\":\"/blog/page/15\",\"children\":15}],[\"$\",\"$Lb\",\"16\",{\"className\":\"\",\"href\":\"/blog/page/16\",\"children\":16}],[\"$\",\"$Lb\",\"17\",{\"className\":\"\",\"href\":\"/blog/page/17\",\"children\":17}],[\"$\",\"$Lb\",\"18\",{\"className\":\"\",\"href\":\"/blog/page/18\",\"children\":18}],[\"$\",\"$Lb\",\"19\",{\"className\":\"\",\"href\":\"/blog/page/19\",\"children\":19}],[\"$\",\"$Lb\",\"20\",{\"className\":\"\",\"href\":\"/blog/page/20\",\"children\":20}],[\"$\",\"$Lb\",\"21\",{\"className\":\"\",\"href\":\"/blog/page/21\",\"children\":21}],[\"$\",\"$Lb\",\"22\",{\"className\":\"\",\"href\":\"/blog/page/22\",\"children\":22}],[\"$\",\"$Lb\",\"23\",{\"className\":\"\",\"href\":\"/blog/page/23\",\"children\":23}],[\"$\",\"$Lb\",\"24\",{\"className\":\"\",\"href\":\"/blog/page/24\",\"children\":24}],[\"$\",\"$Lb\",\"25\",{\"className\":\"\",\"href\":\"/blog/page/25\",\"children\":25}],[\"$\",\"$Lb\",\"26\",{\"className\":\"\",\"href\":\"/blog/page/26\",\"children\":26}],[\"$\",\"$Lb\",\"27\",{\"className\":\"\",\"href\":\"/blog/page/27\",\"children\":27}],[\"$\",\"$Lb\",\"28\",{\"className\":\"\",\"href\":\"/blog/page/28\",\"children\":28}],[\"$\",\"$Lb\",\"29\",{\"className\":\"\",\"href\":\"/blog/page/29\",\"children\":29}],[\"$\",\"$Lb\",\"30\",{\"className\":\"\",\"href\":\"/blog/page/30\",\"children\":30}],[\"$\",\"$Lb\",\"31\",{\"className\":\"\",\"href\":\"/blog/page/31\",\"children\":31}],[\"$\",\"$Lb\",\"32\",{\"className\":\"\",\"href\":\"/blog/page/32\",\"children\":32}],[\"$\",\"$Lb\",\"33\",{\"className\":\"\",\"href\":\"/blog/page/33\",\"children\":33}],[\"$\",\"$Lb\",\"34\",{\"className\":\"\",\"href\":\"/blog/page/34\",\"children\":34}],[\"$\",\"$Lb\",\"35\",{\"className\":\"\",\"href\":\"/blog/page/35\",\"children\":35}],[\"$\",\"$Lb\",\"36\",{\"className\":\"\",\"href\":\"/blog/page/36\",\"children\":36}],[\"$\",\"$Lb\",\"37\",{\"className\":\"\",\"href\":\"/blog/page/37\",\"children\":37}],[\"$\",\"$Lb\",\"38\",{\"className\":\"\",\"href\":\"/blog/page/38\",\"children\":38}],[\"$\",\"$Lb\",\"39\",{\"className\":\"\",\"href\":\"/blog/page/39\",\"children\":39}],[\"$\",\"$Lb\",\"40\",{\"className\":\"\",\"href\":\"/blog/page/40\",\"children\":40}],[\"$\",\"$Lb\",\"41\",{\"className\":\"\",\"href\":\"/blog/page/41\",\"children\":41}],[\"$\",\"$Lb\",\"42\",{\"className\":\"\",\"href\":\"/blog/page/42\",\"children\":42}],[\"$\",\"$Lb\",\"43\",{\"className\":\"\",\"href\":\"/blog/page/43\",\"children\":43}],[\"$\",\"$Lb\",\"44\",{\"className\":\"\",\"href\":\"/blog/page/44\",\"children\":44}],[\"$\",\"$Lb\",\"45\",{\"className\":\"\",\"href\":\"/blog/page/45\",\"children\":45}],[\"$\",\"$Lb\",\"46\",{\"className\":\"\",\"href\":\"/blog/page/46\",\"children\":46}],[\"$\",\"$Lb\",\"47\",{\"className\":\"\",\"href\":\"/blog/page/47\",\"children\":47}],[\"$\",\"$Lb\",\"48\",{\"className\":\"\",\"href\":\"/blog/page/48\",\"children\":48}],[\"$\",\"$Lb\",\"49\",{\"className\":\"\",\"href\":\"/blog/page/49\",\"children\":49}],[\"$\",\"$Lb\",\"50\",{\"className\":\"\",\"href\":\"/blog/page/50\",\"children\":50}],[\"$\",\"$Lb\",\"51\",{\"className\":\"\",\"href\":\"/blog/page/51\",\"children\":51}],[\"$\",\"$Lb\",\"52\",{\"className\":\"\",\"href\":\"/blog/page/52\",\"children\":52}],[\"$\",\"$Lb\",\"53\",{\"className\":\"\",\"href\":\"/blog/page/53\",\"children\":53}],[\"$\",\"$Lb\",\"54\",{\"className\":\"\",\"href\":\"/blog/page/54\",\"children\":54}],[\"$\",\"$Lb\",\"55\",{\"className\":\"\",\"href\":\"/blog/page/55\",\"children\":55}],[\"$\",\"$Lb\",\"56\",{\"className\":\"\",\"href\":\"/blog/page/56\",\"children\":56}],[\"$\",\"$Lb\",\"57\",{\"className\":\"\",\"href\":\"/blog/page/57\",\"children\":57}],[\"$\",\"$Lb\",\"58\",{\"className\":\"\",\"href\":\"/blog/page/58\",\"children\":58}],[\"$\",\"$Lb\",\"59\",{\"className\":\"\",\"href\":\"/blog/page/59\",\"children\":59}],[\"$\",\"$Lb\",\"60\",{\"className\":\"\",\"href\":\"/blog/page/60\",\"children\":60}],[\"$\",\"$Lb\",\"61\",{\"className\":\"\",\"href\":\"/blog/page/61\",\"children\":61}],[\"$\",\"$Lb\",\"62\",{\"className\":\"\",\"href\":\"/blog/page/62\",\"children\":62}],[\"$\",\"$Lb\",\"63\",{\"className\":\"\",\"href\":\"/blog/page/63\",\"children\":63}],[\"$\",\"$Lb\",\"64\",{\"className\":\"\",\"href\":\"/blog/page/64\",\"children\":64}],[\"$\",\"$Lb\",\"65\",{\"className\":\"\",\"href\":\"/blog/page/65\",\"children\":65}],[\"$\",\"$Lb\",\"66\",{\"className\":\"\",\"href\":\"/blog/page/66\",\"children\":66}],[\"$\",\"$Lb\",\"67\",{\"className\":\"\",\"href\":\"/blog/page/67\",\"children\":67}],[\"$\",\"$Lb\",\"68\",{\"className\":\"\",\"href\":\"/blog/page/68\",\"children\":68}],[\"$\",\"$Lb\",\"69\",{\"className\":\"\",\"href\":\"/blog/page/69\",\"children\":69}],[\"$\",\"$Lb\",\"70\",{\"className\":\"\",\"href\":\"/blog/page/70\",\"children\":70}],[\"$\",\"$Lb\",\"71\",{\"className\":\"\",\"href\":\"/blog/page/71\",\"children\":71}],[\"$\",\"$Lb\",\"72\",{\"className\":\"\",\"href\":\"/blog/page/72\",\"children\":72}],[\"$\",\"$Lb\",\"73\",{\"className\":\"\",\"href\":\"/blog/page/73\",\"children\":73}],[\"$\",\"$Lb\",\"74\",{\"className\":\"\",\"href\":\"/blog/page/74\",\"children\":74}],[\"$\",\"$Lb\",\"75\",{\"className\":\"\",\"href\":\"/blog/page/75\",\"children\":75}],[\"$\",\"$Lb\",\"76\",{\"className\":\"\",\"href\":\"/blog/page/76\",\"children\":76}],[\"$\",\"$Lb\",\"77\",{\"className\":\"\",\"href\":\"/blog/page/77\",\"children\":77}],[\"$\",\"$Lb\",\"78\",{\"className\":\"\",\"href\":\"/blog/page/78\",\"children\":78}],[\"$\",\"$Lb\",\"79\",{\"className\":\"\",\"href\":\"/blog/page/79\",\"children\":79}],[\"$\",\"$Lb\",\"80\",{\"className\":\"\",\"href\":\"/blog/page/80\",\"children\":80}],[\"$\",\"$Lb\",\"81\",{\"className\":\"\",\"href\":\"/blog/page/81\",\"children\":81}]]}]]}],null]}]\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Patrick Desjardins Blog - Running Local LLM on a Nvidia 5080 for Coding\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Running Local LLM on a Nvidia 5080 for Coding\"}]]\n6:null\n"])</script></body></html>