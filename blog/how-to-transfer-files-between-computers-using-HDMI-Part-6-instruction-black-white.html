<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/c9a5bc6a7c948fb0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/images/blog/hdmi-file-transfer-frame-rainbow.png"/><link rel="preload" as="image" href="/images/blog/hdmi-file-transfer-frame-diagonal.png"/><link rel="stylesheet" href="/_next/static/css/f7004a68ac8d367c.css" crossorigin="" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/e917b4f00bcb2347.css" crossorigin="" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-692a33e6ebc06ff4.js" crossorigin=""/><script src="/_next/static/chunks/fd9d1056-cc48c28d170fddc2.js" async="" crossorigin=""></script><script src="/_next/static/chunks/69-c7efea4b65083e7f.js" async="" crossorigin=""></script><script src="/_next/static/chunks/main-app-f550f103b66f998a.js" async="" crossorigin=""></script><script src="/_next/static/chunks/674-a46cce5ee161a346.js" async=""></script><script src="/_next/static/chunks/app/blog/%5Bslug%5D/page-e23445258eb56deb.js" async=""></script><title>Patrick Desjardins Website and Blog</title><meta name="next-size-adjust"/><script src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js" crossorigin="" noModule=""></script></head><body class="layout_bodystyle__4ncsS"><div class="__className_aaf875"><div class="layout_container__Tovb9"><header class="layout_siteTitle__k5U8g">Patrick Desjardins Blog</header><nav><ul class="layout_navLinks__mf70r"><li class="layout_navLinkItem__1L8fB"><a class="layout_navLinkText__bt28R" href="/">Main Page</a><a class="layout_navLinkText__bt28R" href="/blog">Blog</a><a class="layout_navLinkText__bt28R" href="/blog/for/2024">2024</a><a class="layout_navLinkText__bt28R" href="/blog/for/2023">2023</a><a class="layout_navLinkText__bt28R" href="/blog/for/2022">2022</a><a class="layout_navLinkText__bt28R" href="/blog/for/2021">2021</a><a class="layout_navLinkText__bt28R" href="/blog/for/2020">2020</a><a class="layout_navLinkText__bt28R" href="/blog/for/2019">2019</a><a class="layout_navLinkText__bt28R" href="/blog/for/2018">2018</a><a class="layout_navLinkText__bt28R" href="/blog/for/2017">2017</a><a class="layout_navLinkText__bt28R" href="/blog/for/2016">2016</a><a class="layout_navLinkText__bt28R" href="/blog/for/2015">2015</a><a class="layout_navLinkText__bt28R" href="/blog/for/2014">2014</a><a class="layout_navLinkText__bt28R" href="/blog/for/2013">2013</a><a class="layout_navLinkText__bt28R" href="/blog/for/2012">2012</a><a class="layout_navLinkText__bt28R" href="/blog/for/2011">2011</a></li></ul></nav><div><img alt="Patrick Desjardins picture from a conference" loading="lazy" width="1000" height="300" decoding="async" data-nimg="1" class="layout_blogTopPicture__RJHNN" style="color:transparent" src="/images/backgrounds/patrickdesjardins_conference_bw.jpeg"/></div><main class="layout_main__mXTwS"><h1>How to Transfer Files Between Computers Using HDMI (Part 6: Instruction and Black and White)</h1><div class="layout_blogPostContainer__WYELx"><p class="layout_blogPostDate__LUvx5">Posted on: <!-- -->2023-06-14</p><p>Last time, we determined that the original idea of relying on a insignificant character to fill the frame is not great. It causes non-text content to break as soon as the selected character can be found in the middle of the content. The solution is to reserve space at the beginning of the first frame (after the red frame) to inject the number of byte to retrieve. Then, the rest of the frame can be filled with null character to have a full video frame.</p>
<h1>Instruction Header</h1>
<p>The video frame structure has now a function to inject into the frame the instruction:</p>
<figure data-rehype-pretty-code-figure=""><pre style="background-color:#fff;color:#24292e" tabindex="0" data-language="rust" data-theme="github-light"><code data-language="rust" data-theme="github-light" style="display:grid"><span data-line=""><span>pub fn write_instruction(&amp;mut self, instruction: &amp;Instruction, size: u8) -&gt; (u16, u16) {</span></span>
<span data-line=""><span>    let mut instruction_index = 0;</span></span>
<span data-line=""><span>    let mut x: u16 = 0;</span></span>
<span data-line=""><span>    let mut y: u16 = 0;</span></span>
<span data-line=""><span>    &#x27;outer: for i in (0..self.frame_size.height as u16).step_by(size as usize) {</span></span>
<span data-line=""><span>        for j in (0..self.frame_size.width as u16).step_by(size as usize) {</span></span>
<span data-line=""><span>            if instruction_index &lt; 64 {</span></span>
<span data-line=""><span>                let (r, g, b) = get_rgb_for_bit(</span></span>
<span data-line=""><span>                    instruction.relevant_byte_count_in_64bits[instruction_index],</span></span>
<span data-line=""><span>                );</span></span>
<span data-line=""><span>                self.write(r, g, b, j, i, size);</span></span>
<span data-line=""><span>                x = j + size as u16;</span></span>
<span data-line=""><span>                instruction_index += 1;</span></span>
<span data-line=""><span>            } else {</span></span>
<span data-line=""><span>                break &#x27;outer;</span></span>
<span data-line=""><span>            }</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""> </span>
<span data-line=""><span>        y = i + size as u16;</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>    if x == self.frame_size.width as u16 {</span></span>
<span data-line=""><span>        x = 0; // y is already increased</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>    return (x, y);</span></span>
<span data-line=""><span>}</span></span></code></pre></figure>
<p>The function works well with the <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>size</span></span></code></span> meaning that if each data is set to be stored into a bigger size than 1 pixel, the instruction will also be biggest. The instruction stores its data into the first 64 spaces. If we use a <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>size</span></span></code></span> of 1, it takes 64 pixels of the first frame of the whole video. With that information on hand, we can store the remaining data after. At extraction time, once the red frame is found, we can extract the first 64 pixels (if size 1) and know how many byte of data to extract.</p>
<p>The solution works well!</p>
<h1>Loseless</h1>
<p>Most video frame were written using Open CV using the <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>VideoWriter::fourcc(&#x27;p&#x27;, &#x27;n&#x27;, &#x27;g&#x27;, &#x27; &#x27;)</span></span></code></span>. Using this fourcc make the code work well locally to inject data and extract locally. However, when it is time to transfer using the capture card and the HDMI cable it does not work. Colors are shifted with R, G and B lossing their original value. Also, the format does not let me open the file on the source computer with VLC. However, using the black and white algorithm with <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>VideoWriter::fourcc(&#x27;a&#x27;, &#x27;v&#x27;, &#x27;c&#x27;, &#x27;1&#x27;)</span></span></code></span> worked well locally even if the format is not loseless. Mostly because each color are not taken the value straigh. It always round it up to the most black or white. Because the range is from 0 to 255, it gives some space to imperfection that we can easily put back.</p>
<figure data-rehype-pretty-code-figure=""><pre style="background-color:#fff;color:#24292e" tabindex="0" data-language="rust" data-theme="github-light"><code data-language="rust" data-theme="github-light" style="display:grid"><span data-line=""><span>pub fn get_bit_from_rgb(rgb: &amp;Vec&lt;u8&gt;) -&gt; bool {</span></span>
<span data-line=""><span>    let sum: u32 = rgb.iter().map(|x| *x as u32).sum();</span></span>
<span data-line=""><span>    sum &gt;= (255_u32 * (rgb.len() as u32) / 2)</span></span>
<span data-line=""><span>}</span></span></code></pre></figure>
<p>The function shows that it takes a collection of color (<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>u8</span></span></code></span> because 0 to 255) and make the sum and divides. So if the color is <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>10,10,40</span></span></code></span> instead of <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>0,0,0</span></span></code></span> the sum is <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>60</span></span></code></span>. Then, divided by the amount of color. In that case three. It gives <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>20</span></span></code></span>. Because <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>20</span></span></code></span> is &lt; than half of the to 126 it is considered black.</p>
<h1>Video Encoding</h1>
<p>To be more faitful to the transmission format, the video encoding is now dynamically chosen depending of the algorithm.</p>
<figure data-rehype-pretty-code-figure=""><pre style="background-color:#fff;color:#24292e" tabindex="0" data-language="rust" data-theme="github-light"><code data-language="rust" data-theme="github-light" style="display:grid"><span data-line=""><span>let fourcc = if options.algo == options::AlgoFrame::RGB {</span></span>
<span data-line=""><span>    VideoWriter::fourcc(&#x27;p&#x27;, &#x27;n&#x27;, &#x27;g&#x27;, &#x27; &#x27;)</span></span>
<span data-line=""><span>} else {</span></span>
<span data-line=""><span>    VideoWriter::fourcc(&#x27;a&#x27;, &#x27;v&#x27;, &#x27;c&#x27;, &#x27;1&#x27;)</span></span>
<span data-line=""><span>};</span></span></code></pre></figure>
<p>That being said, the RGB solution is and will never be suitable to transfer data without rethinking to a mechanism to bring resiliency on data corruption which happen massively with video compression.</p>
<h1>Testing Locally</h1>
<p>Injecting a zip file of 13.3 megs produces a video file of 47.1 megs in 5 seconds. The video length is 1 second.</p>
<figure data-rehype-pretty-code-figure=""><pre style="background-color:#fff;color:#24292e" tabindex="0" data-language="sh" data-theme="github-light"><code data-language="sh" data-theme="github-light" style="display:grid"><span data-line=""><span>cargo run --release -- -m inject -i outputs/test2.zip -o outputs/test2zip.mp4 --fps 30 --height 1080 --width 1920 --size 1 -p true -a bw</span></span></code></pre></figure>
<p>Extracting the zip file takes 15 seconds.</p>
<figure data-rehype-pretty-code-figure=""><pre style="background-color:#fff;color:#24292e" tabindex="0" data-language="sh" data-theme="github-light"><code data-language="sh" data-theme="github-light" style="display:grid"><span data-line=""><span>cargo run --release -- -m extract -i outputs/test2zip.mp4 -o outputs/test2_extract.zip --fps 30 --height 1080 --width 1920 --size 1 -p true -a bw</span></span></code></pre></figure>
<h1>Testing with Capture Card and HDMI</h1>
<p>The first test was a picture of 2 megs. I started using 15 fps and pixel size of 5. The slowest fps was to ensure that more duplicate would be there to avoid missing frame. I would still read at 30 fps on the target computer. The size of 5 is also to ensure the video well received. The source computer with VLC couldn&#x27;t play the <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>acv1</span></span></code></span> format and I had to use the <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>mp4v</span></span></code></span> fourcc. More investigation is needed to understand the reason. The produced video size is 104 megs and has 13 seconds length.</p>
<p>However, I see in the terminal when closing ffmpeg using <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>q</span></span></code></span> this message:</p>
<blockquote>
<p>real-time buffer too full or near too full frame dropped!</p>
</blockquote>
<p>Also, during the extraction process, the instruction gives zero byte. The pixel colors were all black. Maybe the two are related? Adding <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>-rtbufsize</span></span></code></span> to ffmpeg resolved the error message but the data could not be more extracted.</p>
<figure data-rehype-pretty-code-figure=""><pre style="background-color:#fff;color:#24292e" tabindex="0" data-language="sh" data-theme="github-light"><code data-language="sh" data-theme="github-light" style="display:grid"><span data-line=""><span>ffmpeg  -r 30 -f dshow -s 1920x1080 -vcodec mjpeg -rtbufsize 200M -i video=&quot;USB Video&quot; -r 30 out1.mp4</span></span></code></pre></figure>
<p>The next step was to ensure we are not missing data on the frame. To verify this hypothesis I decided to start with creating a small video that do a square of <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>size</span></span></code></span> pixel of different color. It looks like a rainbow from the outside skirt to the inside. Then, passing the video into the capture card and comparing to see if some colors were missing on any edge. I performed few tests with different size without finding anything clear.</p>
<p><img src="/images/blog/hdmi-file-transfer-frame-rainbow.png" alt=""/></p>
<p>Then, I decided to perform a second test. This time, using diagonal of 10 pixels on each corner. By using a bigger size than 1 pixel for each square, I can count the square. I did with 1 pixel to ensure the integrity since using bigger size for each square is easier to count but might have the corner pixel missing few pixels.</p>
<p><img src="/images/blog/hdmi-file-transfer-frame-diagonal.png" alt=""/></p>
<p>After several different configurations, I confirmed that what is recorded by the ffmpeg was full frames. Thus, the last explanation was that reading the frames, especially the one containing the instruction, was faulty. Could the frame with the instruction be missing? Maybe frames are not all captured causing a stream of video with few gaps which are not perceptive visually but are critical to form a comprehensible message back.</p>
<h1>Conclusion</h1>
<p>In this section we saw that adding instruction and using black and white frame work well locally but then again using an HDMI cable with a capture card cause some issues like not being able to decrypt the size of the data. We validated that every pixel projected into the capture card is showing up in the produced video in the computer that read the video. In the next post, we will see how to mitigate the issue by analyzing what is happening by creating an additional test and changing the assumption that we capture every frame.</p></div></main><div class="layout_paginationBar__jnuuR"><div class="layout_paginationTitle__PsOw5">Chronological Blog Articles by Page</div><div class="layout_paginationLinks__LdBaH"><a class="" href="/blog/page/1">1</a><a class="" href="/blog/page/2">2</a><a class="" href="/blog/page/3">3</a><a class="" href="/blog/page/4">4</a><a class="" href="/blog/page/5">5</a><a class="" href="/blog/page/6">6</a><a class="" href="/blog/page/7">7</a><a class="" href="/blog/page/8">8</a><a class="" href="/blog/page/9">9</a><a class="" href="/blog/page/10">10</a><a class="" href="/blog/page/11">11</a><a class="" href="/blog/page/12">12</a><a class="" href="/blog/page/13">13</a><a class="" href="/blog/page/14">14</a><a class="" href="/blog/page/15">15</a><a class="" href="/blog/page/16">16</a><a class="" href="/blog/page/17">17</a><a class="" href="/blog/page/18">18</a><a class="" href="/blog/page/19">19</a><a class="" href="/blog/page/20">20</a><a class="" href="/blog/page/21">21</a><a class="" href="/blog/page/22">22</a><a class="" href="/blog/page/23">23</a><a class="" href="/blog/page/24">24</a><a class="" href="/blog/page/25">25</a><a class="" href="/blog/page/26">26</a><a class="" href="/blog/page/27">27</a><a class="" href="/blog/page/28">28</a><a class="" href="/blog/page/29">29</a><a class="" href="/blog/page/30">30</a><a class="" href="/blog/page/31">31</a><a class="" href="/blog/page/32">32</a><a class="" href="/blog/page/33">33</a><a class="" href="/blog/page/34">34</a><a class="" href="/blog/page/35">35</a><a class="" href="/blog/page/36">36</a><a class="" href="/blog/page/37">37</a><a class="" href="/blog/page/38">38</a><a class="" href="/blog/page/39">39</a><a class="" href="/blog/page/40">40</a><a class="" href="/blog/page/41">41</a><a class="" href="/blog/page/42">42</a><a class="" href="/blog/page/43">43</a><a class="" href="/blog/page/44">44</a><a class="" href="/blog/page/45">45</a><a class="" href="/blog/page/46">46</a><a class="" href="/blog/page/47">47</a><a class="" href="/blog/page/48">48</a><a class="" href="/blog/page/49">49</a><a class="" href="/blog/page/50">50</a><a class="" href="/blog/page/51">51</a><a class="" href="/blog/page/52">52</a><a class="" href="/blog/page/53">53</a><a class="" href="/blog/page/54">54</a><a class="" href="/blog/page/55">55</a><a class="" href="/blog/page/56">56</a><a class="" href="/blog/page/57">57</a><a class="" href="/blog/page/58">58</a><a class="" href="/blog/page/59">59</a><a class="" href="/blog/page/60">60</a><a class="" href="/blog/page/61">61</a><a class="" href="/blog/page/62">62</a><a class="" href="/blog/page/63">63</a><a class="" href="/blog/page/64">64</a><a class="" href="/blog/page/65">65</a><a class="" href="/blog/page/66">66</a><a class="" href="/blog/page/67">67</a><a class="" href="/blog/page/68">68</a><a class="" href="/blog/page/69">69</a><a class="" href="/blog/page/70">70</a><a class="" href="/blog/page/71">71</a><a class="" href="/blog/page/72">72</a><a class="" href="/blog/page/73">73</a><a class="" href="/blog/page/74">74</a><a class="" href="/blog/page/75">75</a><a class="" href="/blog/page/76">76</a><a class="" href="/blog/page/77">77</a></div></div></div></div><script src="/_next/static/chunks/webpack-692a33e6ebc06ff4.js" crossorigin="" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/f7004a68ac8d367c.css\",\"style\",{\"crossOrigin\":\"\"}]\n0:\"$L2\"\n"])</script><script>self.__next_f.push([1,"3:HL[\"/_next/static/media/c9a5bc6a7c948fb0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n4:HL[\"/_next/static/css/e917b4f00bcb2347.css\",\"style\",{\"crossOrigin\":\"\"}]\n"])</script><script>self.__next_f.push([1,"5:I[7690,[],\"\"]\n8:I[5613,[],\"\"]\na:I[1778,[],\"\"]\nc:I[8955,[],\"\"]\n9:[\"slug\",\"how-to-transfer-files-between-computers-using-HDMI-Part-6-instruction-black-white\",\"d\"]\nd:[]\n"])</script><script>self.__next_f.push([1,"2:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/f7004a68ac8d367c.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]],[\"$\",\"$L5\",null,{\"buildId\":\"U9WHEHP9m9dAVmOepwIU5\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/blog/how-to-transfer-files-between-computers-using-HDMI-Part-6-instruction-black-white\",\"initialTree\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"how-to-transfer-files-between-computers-using-HDMI-Part-6-instruction-black-white\",\"d\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":\\\"how-to-transfer-files-between-computers-using-HDMI-Part-6-instruction-black-white\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"how-to-transfer-files-between-computers-using-HDMI-Part-6-instruction-black-white\",\"d\"],{\"children\":[\"__PAGE__\",{},[\"$L6\",\"$L7\",null]]},[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\",\"$9\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/e917b4f00bcb2347.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]]}]]},[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}]]},[null,[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"title\",null,{\"children\":\"Patrick Desjardins Website and Blog\"}],[\"$\",\"meta\",null,{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1, shrink-to-fit=no\"}]]}],[\"$\",\"body\",null,{\"className\":\"layout_bodystyle__4ncsS\",\"children\":[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}]}]]}],null]],\"initialHead\":[false,\"$Lb\"],\"globalErrorComponent\":\"$c\",\"missingSlots\":\"$Wd\"}]]\n"])</script><script>self.__next_f.push([1,"e:I[5250,[\"674\",\"static/chunks/674-a46cce5ee161a346.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-e23445258eb56deb.js\"],\"\"]\nf:I[1749,[\"674\",\"static/chunks/674-a46cce5ee161a346.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-e23445258eb56deb.js\"],\"Image\"]\nb:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"2\",{\"name\":\"next-size-adjust\"}]]\n6:null\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"div\",null,{\"className\":\"__className_aaf875\",\"children\":[\"$\",\"div\",null,{\"className\":\"layout_container__Tovb9\",\"children\":[[\"$\",\"header\",null,{\"className\":\"layout_siteTitle__k5U8g\",\"children\":\"Patrick Desjardins Blog\"}],[\"$\",\"nav\",null,{\"children\":[\"$\",\"ul\",null,{\"className\":\"layout_navLinks__mf70r\",\"children\":[\"$\",\"li\",null,{\"className\":\"layout_navLinkItem__1L8fB\",\"children\":[[\"$\",\"$Le\",null,{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/\",\"children\":\"Main Page\"}],[\"$\",\"$Le\",null,{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog\",\"children\":\"Blog\"}],[[\"$\",\"$Le\",\"2024\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2024\",\"children\":2024}],[\"$\",\"$Le\",\"2023\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2023\",\"children\":2023}],[\"$\",\"$Le\",\"2022\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2022\",\"children\":2022}],[\"$\",\"$Le\",\"2021\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2021\",\"children\":2021}],[\"$\",\"$Le\",\"2020\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2020\",\"children\":2020}],[\"$\",\"$Le\",\"2019\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2019\",\"children\":2019}],[\"$\",\"$Le\",\"2018\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2018\",\"children\":2018}],[\"$\",\"$Le\",\"2017\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2017\",\"children\":2017}],[\"$\",\"$Le\",\"2016\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2016\",\"children\":2016}],[\"$\",\"$Le\",\"2015\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2015\",\"children\":2015}],[\"$\",\"$Le\",\"2014\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2014\",\"children\":2014}],[\"$\",\"$Le\",\"2013\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2013\",\"children\":2013}],[\"$\",\"$Le\",\"2012\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2012\",\"children\":2012}],[\"$\",\"$Le\",\"2011\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2011\",\"children\":2011}]]]}]}]}],[\"$\",\"div\",null,{\"children\":[\"$\",\"$Lf\",null,{\"className\":\"layout_blogTopPicture__RJHNN\",\"alt\":\"Patrick Desjardins picture from a conference\",\"src\":\"/images/backgrounds/patrickdesjardins_conference_bw.jpeg\",\"width\":1000,\"height\":300}]}],[\"$\",\"main\",null,{\"className\":\"layout_main__mXTwS\",\"children\":[[\"$\",\"h1\",null,{\"children\":\"How to Transfer Files Between Computers Using HDMI (Part 6: Instruction and Black and White)\"}],[\"$\",\"div\",null,{\"className\":\"layout_blogPostContainer__WYELx\",\"children\":[[\"$\",\"p\",null,{\"className\":\"layout_blogPostDate__LUvx5\",\"children\":[\"Posted on: \",\"2023-06-14\"]}],[[\"$\",\"p\",null,{\"children\":\"Last time, we determined that the original idea of relying on a insignificant character to fill the frame is not great. It causes non-text content to break as soon as the selected character can be found in the middle of the content. The solution is to reserve space at the beginning of the first frame (after the red frame) to inject the number of byte to retrieve. Then, the rest of the frame can be filled with null character to have a full video frame.\"}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Instruction Header\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The video frame structure has now a function to inject into the frame the instruction:\"}],\"\\n\",[\"$\",\"figure\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"tabIndex\":\"0\",\"data-language\":\"rust\",\"data-theme\":\"github-light\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"rust\",\"data-theme\":\"github-light\",\"style\":{\"display\":\"grid\"},\"children\":[[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"pub fn write_instruction(\u0026mut self, instruction: \u0026Instruction, size: u8) -\u003e (u16, u16) {\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"    let mut instruction_index = 0;\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"    let mut x: u16 = 0;\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"    let mut y: u16 = 0;\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"    'outer: for i in (0..self.frame_size.height as u16).step_by(size as usize) {\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"        for j in (0..self.frame_size.width as u16).step_by(size as usize) {\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"            if instruction_index \u003c 64 {\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"                let (r, g, b) = get_rgb_for_bit(\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"                    instruction.relevant_byte_count_in_64bits[instruction_index],\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"                );\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"                self.write(r, g, b, j, i, size);\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"                x = j + size as u16;\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"                instruction_index += 1;\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"            } else {\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"                break 'outer;\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"            }\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"        }\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":\" \"}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"        y = i + size as u16;\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"    }\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"    if x == self.frame_size.width as u16 {\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"        x = 0; // y is already increased\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"    }\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"    return (x, y);\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"}\"}]}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"The function works well with the \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"size\"}]}]}]}],\" meaning that if each data is set to be stored into a bigger size than 1 pixel, the instruction will also be biggest. The instruction stores its data into the first 64 spaces. If we use a \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"size\"}]}]}]}],\" of 1, it takes 64 pixels of the first frame of the whole video. With that information on hand, we can store the remaining data after. At extraction time, once the red frame is found, we can extract the first 64 pixels (if size 1) and know how many byte of data to extract.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The solution works well!\"}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Loseless\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Most video frame were written using Open CV using the \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"VideoWriter::fourcc('p', 'n', 'g', ' ')\"}]}]}]}],\". Using this fourcc make the code work well locally to inject data and extract locally. However, when it is time to transfer using the capture card and the HDMI cable it does not work. Colors are shifted with R, G and B lossing their original value. Also, the format does not let me open the file on the source computer with VLC. However, using the black and white algorithm with \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"VideoWriter::fourcc('a', 'v', 'c', '1')\"}]}]}]}],\" worked well locally even if the format is not loseless. Mostly because each color are not taken the value straigh. It always round it up to the most black or white. Because the range is from 0 to 255, it gives some space to imperfection that we can easily put back.\"]}],\"\\n\",[\"$\",\"figure\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"tabIndex\":\"0\",\"data-language\":\"rust\",\"data-theme\":\"github-light\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"rust\",\"data-theme\":\"github-light\",\"style\":{\"display\":\"grid\"},\"children\":[[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"pub fn get_bit_from_rgb(rgb: \u0026Vec\u003cu8\u003e) -\u003e bool {\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"    let sum: u32 = rgb.iter().map(|x| *x as u32).sum();\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"    sum \u003e= (255_u32 * (rgb.len() as u32) / 2)\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"}\"}]}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"The function shows that it takes a collection of color (\",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"u8\"}]}]}]}],\" because 0 to 255) and make the sum and divides. So if the color is \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"10,10,40\"}]}]}]}],\" instead of \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"0,0,0\"}]}]}]}],\" the sum is \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"60\"}]}]}]}],\". Then, divided by the amount of color. In that case three. It gives \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"20\"}]}]}]}],\". Because \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"20\"}]}]}]}],\" is \u003c than half of the to 126 it is considered black.\"]}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Video Encoding\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"To be more faitful to the transmission format, the video encoding is now dynamically chosen depending of the algorithm.\"}],\"\\n\",[\"$\",\"figure\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"tabIndex\":\"0\",\"data-language\":\"rust\",\"data-theme\":\"github-light\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"rust\",\"data-theme\":\"github-light\",\"style\":{\"display\":\"grid\"},\"children\":[[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"let fourcc = if options.algo == options::AlgoFrame::RGB {\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"    VideoWriter::fourcc('p', 'n', 'g', ' ')\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"} else {\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"    VideoWriter::fourcc('a', 'v', 'c', '1')\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"};\"}]}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"That being said, the RGB solution is and will never be suitable to transfer data without rethinking to a mechanism to bring resiliency on data corruption which happen massively with video compression.\"}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Testing Locally\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Injecting a zip file of 13.3 megs produces a video file of 47.1 megs in 5 seconds. The video length is 1 second.\"}],\"\\n\",[\"$\",\"figure\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"tabIndex\":\"0\",\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"style\":{\"display\":\"grid\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"cargo run --release -- -m inject -i outputs/test2.zip -o outputs/test2zip.mp4 --fps 30 --height 1080 --width 1920 --size 1 -p true -a bw\"}]}]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Extracting the zip file takes 15 seconds.\"}],\"\\n\",[\"$\",\"figure\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"tabIndex\":\"0\",\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"style\":{\"display\":\"grid\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"cargo run --release -- -m extract -i outputs/test2zip.mp4 -o outputs/test2_extract.zip --fps 30 --height 1080 --width 1920 --size 1 -p true -a bw\"}]}]}]}]}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Testing with Capture Card and HDMI\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"The first test was a picture of 2 megs. I started using 15 fps and pixel size of 5. The slowest fps was to ensure that more duplicate would be there to avoid missing frame. I would still read at 30 fps on the target computer. The size of 5 is also to ensure the video well received. The source computer with VLC couldn't play the \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"acv1\"}]}]}]}],\" format and I had to use the \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"mp4v\"}]}]}]}],\" fourcc. More investigation is needed to understand the reason. The produced video size is 104 megs and has 13 seconds length.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"However, I see in the terminal when closing ffmpeg using \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"q\"}]}]}]}],\" this message:\"]}],\"\\n\",[\"$\",\"blockquote\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"real-time buffer too full or near too full frame dropped!\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Also, during the extraction process, the instruction gives zero byte. The pixel colors were all black. Maybe the two are related? Adding \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"-rtbufsize\"}]}]}]}],\" to ffmpeg resolved the error message but the data could not be more extracted.\"]}],\"\\n\",[\"$\",\"figure\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"tabIndex\":\"0\",\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"style\":{\"display\":\"grid\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"ffmpeg  -r 30 -f dshow -s 1920x1080 -vcodec mjpeg -rtbufsize 200M -i video=\\\"USB Video\\\" -r 30 out1.mp4\"}]}]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"The next step was to ensure we are not missing data on the frame. To verify this hypothesis I decided to start with creating a small video that do a square of \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"size\"}]}]}]}],\" pixel of different color. It looks like a rainbow from the outside skirt to the inside. Then, passing the video into the capture card and comparing to see if some colors were missing on any edge. I performed few tests with different size without finding anything clear.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"src\":\"/images/blog/hdmi-file-transfer-frame-rainbow.png\",\"alt\":\"\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Then, I decided to perform a second test. This time, using diagonal of 10 pixels on each corner. By using a bigger size than 1 pixel for each square, I can count the square. I did with 1 pixel to ensure the integrity since using bigger size for each square is easier to count but might have the corner pixel missing few pixels.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"src\":\"/images/blog/hdmi-file-transfer-frame-diagonal.png\",\"alt\":\"\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"After several different configurations, I confirmed that what is recorded by the ffmpeg was full frames. Thus, the last explanation was that reading the frames, especially the one containing the instruction, was faulty. Could the frame with the instruction be missing? Maybe frames are not all captured causing a stream of video with few gaps which are not perceptive visually but are critical to form a comprehensible message back.\"}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Conclusion\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"In this section we saw that adding instruction and using black and white frame work well locally but then again using an HDMI cable with a capture card cause some issues like not being able to decrypt the size of the data. We validated that every pixel projected into the capture card is showing up in the produced video in the computer that read the video. In the next post, we will see how to mitigate the issue by analyzing what is happening by creating an additional test and changing the assumption that we capture every frame.\"}]]]}]]}],[\"$\",\"div\",null,{\"className\":\"layout_paginationBar__jnuuR\",\"children\":[[\"$\",\"div\",null,{\"className\":\"layout_paginationTitle__PsOw5\",\"children\":\"Chronological Blog Articles by Page\"}],[\"$\",\"div\",null,{\"className\":\"layout_paginationLinks__LdBaH\",\"children\":[[\"$\",\"$Le\",\"1\",{\"className\":\"\",\"href\":\"/blog/page/1\",\"children\":1}],[\"$\",\"$Le\",\"2\",{\"className\":\"\",\"href\":\"/blog/page/2\",\"children\":2}],[\"$\",\"$Le\",\"3\",{\"className\":\"\",\"href\":\"/blog/page/3\",\"children\":3}],[\"$\",\"$Le\",\"4\",{\"className\":\"\",\"href\":\"/blog/page/4\",\"children\":4}],[\"$\",\"$Le\",\"5\",{\"className\":\"\",\"href\":\"/blog/page/5\",\"children\":5}],[\"$\",\"$Le\",\"6\",{\"className\":\"\",\"href\":\"/blog/page/6\",\"children\":6}],[\"$\",\"$Le\",\"7\",{\"className\":\"\",\"href\":\"/blog/page/7\",\"children\":7}],[\"$\",\"$Le\",\"8\",{\"className\":\"\",\"href\":\"/blog/page/8\",\"children\":8}],[\"$\",\"$Le\",\"9\",{\"className\":\"\",\"href\":\"/blog/page/9\",\"children\":9}],[\"$\",\"$Le\",\"10\",{\"className\":\"\",\"href\":\"/blog/page/10\",\"children\":10}],[\"$\",\"$Le\",\"11\",{\"className\":\"\",\"href\":\"/blog/page/11\",\"children\":11}],[\"$\",\"$Le\",\"12\",{\"className\":\"\",\"href\":\"/blog/page/12\",\"children\":12}],[\"$\",\"$Le\",\"13\",{\"className\":\"\",\"href\":\"/blog/page/13\",\"children\":13}],[\"$\",\"$Le\",\"14\",{\"className\":\"\",\"href\":\"/blog/page/14\",\"children\":14}],[\"$\",\"$Le\",\"15\",{\"className\":\"\",\"href\":\"/blog/page/15\",\"children\":15}],[\"$\",\"$Le\",\"16\",{\"className\":\"\",\"href\":\"/blog/page/16\",\"children\":16}],[\"$\",\"$Le\",\"17\",{\"className\":\"\",\"href\":\"/blog/page/17\",\"children\":17}],[\"$\",\"$Le\",\"18\",{\"className\":\"\",\"href\":\"/blog/page/18\",\"children\":18}],[\"$\",\"$Le\",\"19\",{\"className\":\"\",\"href\":\"/blog/page/19\",\"children\":19}],[\"$\",\"$Le\",\"20\",{\"className\":\"\",\"href\":\"/blog/page/20\",\"children\":20}],[\"$\",\"$Le\",\"21\",{\"className\":\"\",\"href\":\"/blog/page/21\",\"children\":21}],[\"$\",\"$Le\",\"22\",{\"className\":\"\",\"href\":\"/blog/page/22\",\"children\":22}],[\"$\",\"$Le\",\"23\",{\"className\":\"\",\"href\":\"/blog/page/23\",\"children\":23}],[\"$\",\"$Le\",\"24\",{\"className\":\"\",\"href\":\"/blog/page/24\",\"children\":24}],[\"$\",\"$Le\",\"25\",{\"className\":\"\",\"href\":\"/blog/page/25\",\"children\":25}],[\"$\",\"$Le\",\"26\",{\"className\":\"\",\"href\":\"/blog/page/26\",\"children\":26}],[\"$\",\"$Le\",\"27\",{\"className\":\"\",\"href\":\"/blog/page/27\",\"children\":27}],[\"$\",\"$Le\",\"28\",{\"className\":\"\",\"href\":\"/blog/page/28\",\"children\":28}],[\"$\",\"$Le\",\"29\",{\"className\":\"\",\"href\":\"/blog/page/29\",\"children\":29}],[\"$\",\"$Le\",\"30\",{\"className\":\"\",\"href\":\"/blog/page/30\",\"children\":30}],[\"$\",\"$Le\",\"31\",{\"className\":\"\",\"href\":\"/blog/page/31\",\"children\":31}],[\"$\",\"$Le\",\"32\",{\"className\":\"\",\"href\":\"/blog/page/32\",\"children\":32}],[\"$\",\"$Le\",\"33\",{\"className\":\"\",\"href\":\"/blog/page/33\",\"children\":33}],[\"$\",\"$Le\",\"34\",{\"className\":\"\",\"href\":\"/blog/page/34\",\"children\":34}],[\"$\",\"$Le\",\"35\",{\"className\":\"\",\"href\":\"/blog/page/35\",\"children\":35}],[\"$\",\"$Le\",\"36\",{\"className\":\"\",\"href\":\"/blog/page/36\",\"children\":36}],[\"$\",\"$Le\",\"37\",{\"className\":\"\",\"href\":\"/blog/page/37\",\"children\":37}],[\"$\",\"$Le\",\"38\",{\"className\":\"\",\"href\":\"/blog/page/38\",\"children\":38}],[\"$\",\"$Le\",\"39\",{\"className\":\"\",\"href\":\"/blog/page/39\",\"children\":39}],[\"$\",\"$Le\",\"40\",{\"className\":\"\",\"href\":\"/blog/page/40\",\"children\":40}],[\"$\",\"$Le\",\"41\",{\"className\":\"\",\"href\":\"/blog/page/41\",\"children\":41}],[\"$\",\"$Le\",\"42\",{\"className\":\"\",\"href\":\"/blog/page/42\",\"children\":42}],[\"$\",\"$Le\",\"43\",{\"className\":\"\",\"href\":\"/blog/page/43\",\"children\":43}],[\"$\",\"$Le\",\"44\",{\"className\":\"\",\"href\":\"/blog/page/44\",\"children\":44}],[\"$\",\"$Le\",\"45\",{\"className\":\"\",\"href\":\"/blog/page/45\",\"children\":45}],[\"$\",\"$Le\",\"46\",{\"className\":\"\",\"href\":\"/blog/page/46\",\"children\":46}],[\"$\",\"$Le\",\"47\",{\"className\":\"\",\"href\":\"/blog/page/47\",\"children\":47}],[\"$\",\"$Le\",\"48\",{\"className\":\"\",\"href\":\"/blog/page/48\",\"children\":48}],[\"$\",\"$Le\",\"49\",{\"className\":\"\",\"href\":\"/blog/page/49\",\"children\":49}],[\"$\",\"$Le\",\"50\",{\"className\":\"\",\"href\":\"/blog/page/50\",\"children\":50}],[\"$\",\"$Le\",\"51\",{\"className\":\"\",\"href\":\"/blog/page/51\",\"children\":51}],[\"$\",\"$Le\",\"52\",{\"className\":\"\",\"href\":\"/blog/page/52\",\"children\":52}],[\"$\",\"$Le\",\"53\",{\"className\":\"\",\"href\":\"/blog/page/53\",\"children\":53}],[\"$\",\"$Le\",\"54\",{\"className\":\"\",\"href\":\"/blog/page/54\",\"children\":54}],[\"$\",\"$Le\",\"55\",{\"className\":\"\",\"href\":\"/blog/page/55\",\"children\":55}],[\"$\",\"$Le\",\"56\",{\"className\":\"\",\"href\":\"/blog/page/56\",\"children\":56}],[\"$\",\"$Le\",\"57\",{\"className\":\"\",\"href\":\"/blog/page/57\",\"children\":57}],[\"$\",\"$Le\",\"58\",{\"className\":\"\",\"href\":\"/blog/page/58\",\"children\":58}],[\"$\",\"$Le\",\"59\",{\"className\":\"\",\"href\":\"/blog/page/59\",\"children\":59}],[\"$\",\"$Le\",\"60\",{\"className\":\"\",\"href\":\"/blog/page/60\",\"children\":60}],[\"$\",\"$Le\",\"61\",{\"className\":\"\",\"href\":\"/blog/page/61\",\"children\":61}],[\"$\",\"$Le\",\"62\",{\"className\":\"\",\"href\":\"/blog/page/62\",\"children\":62}],[\"$\",\"$Le\",\"63\",{\"className\":\"\",\"href\":\"/blog/page/63\",\"children\":63}],[\"$\",\"$Le\",\"64\",{\"className\":\"\",\"href\":\"/blog/page/64\",\"children\":64}],[\"$\",\"$Le\",\"65\",{\"className\":\"\",\"href\":\"/blog/page/65\",\"children\":65}],[\"$\",\"$Le\",\"66\",{\"className\":\"\",\"href\":\"/blog/page/66\",\"children\":66}],[\"$\",\"$Le\",\"67\",{\"className\":\"\",\"href\":\"/blog/page/67\",\"children\":67}],[\"$\",\"$Le\",\"68\",{\"className\":\"\",\"href\":\"/blog/page/68\",\"children\":68}],[\"$\",\"$Le\",\"69\",{\"className\":\"\",\"href\":\"/blog/page/69\",\"children\":69}],[\"$\",\"$Le\",\"70\",{\"className\":\"\",\"href\":\"/blog/page/70\",\"children\":70}],[\"$\",\"$Le\",\"71\",{\"className\":\"\",\"href\":\"/blog/page/71\",\"children\":71}],[\"$\",\"$Le\",\"72\",{\"className\":\"\",\"href\":\"/blog/page/72\",\"children\":72}],[\"$\",\"$Le\",\"73\",{\"className\":\"\",\"href\":\"/blog/page/73\",\"children\":73}],[\"$\",\"$Le\",\"74\",{\"className\":\"\",\"href\":\"/blog/page/74\",\"children\":74}],[\"$\",\"$Le\",\"75\",{\"className\":\"\",\"href\":\"/blog/page/75\",\"children\":75}],[\"$\",\"$Le\",\"76\",{\"className\":\"\",\"href\":\"/blog/page/76\",\"children\":76}],[\"$\",\"$Le\",\"77\",{\"className\":\"\",\"href\":\"/blog/page/77\",\"children\":77}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,""])</script></body></html>