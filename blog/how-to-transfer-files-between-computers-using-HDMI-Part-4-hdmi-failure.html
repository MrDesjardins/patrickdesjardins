<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/c9a5bc6a7c948fb0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/images/blog/hdmi-file-transfer-video-frame-bw-lines.png"/><link rel="stylesheet" href="/_next/static/css/f7004a68ac8d367c.css" crossorigin="" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/e917b4f00bcb2347.css" crossorigin="" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-692a33e6ebc06ff4.js" crossorigin=""/><script src="/_next/static/chunks/fd9d1056-cc48c28d170fddc2.js" async="" crossorigin=""></script><script src="/_next/static/chunks/69-c7efea4b65083e7f.js" async="" crossorigin=""></script><script src="/_next/static/chunks/main-app-f550f103b66f998a.js" async="" crossorigin=""></script><script src="/_next/static/chunks/674-a46cce5ee161a346.js" async=""></script><script src="/_next/static/chunks/app/blog/%5Bslug%5D/page-e23445258eb56deb.js" async=""></script><title>Patrick Desjardins Website and Blog</title><meta name="next-size-adjust"/><script src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js" crossorigin="" noModule=""></script></head><body class="layout_bodystyle__4ncsS"><div class="__className_aaf875"><div class="layout_container__Tovb9"><header class="layout_siteTitle__k5U8g">Patrick Desjardins Blog</header><nav><ul class="layout_navLinks__mf70r"><li class="layout_navLinkItem__1L8fB"><a class="layout_navLinkText__bt28R" href="/">Main Page</a><a class="layout_navLinkText__bt28R" href="/blog">Blog</a><a class="layout_navLinkText__bt28R" href="/blog/for/2024">2024</a><a class="layout_navLinkText__bt28R" href="/blog/for/2023">2023</a><a class="layout_navLinkText__bt28R" href="/blog/for/2022">2022</a><a class="layout_navLinkText__bt28R" href="/blog/for/2021">2021</a><a class="layout_navLinkText__bt28R" href="/blog/for/2020">2020</a><a class="layout_navLinkText__bt28R" href="/blog/for/2019">2019</a><a class="layout_navLinkText__bt28R" href="/blog/for/2018">2018</a><a class="layout_navLinkText__bt28R" href="/blog/for/2017">2017</a><a class="layout_navLinkText__bt28R" href="/blog/for/2016">2016</a><a class="layout_navLinkText__bt28R" href="/blog/for/2015">2015</a><a class="layout_navLinkText__bt28R" href="/blog/for/2014">2014</a><a class="layout_navLinkText__bt28R" href="/blog/for/2013">2013</a><a class="layout_navLinkText__bt28R" href="/blog/for/2012">2012</a><a class="layout_navLinkText__bt28R" href="/blog/for/2011">2011</a></li></ul></nav><div><img alt="Patrick Desjardins picture from a conference" loading="lazy" width="1000" height="300" decoding="async" data-nimg="1" class="layout_blogTopPicture__RJHNN" style="color:transparent" src="/images/backgrounds/patrickdesjardins_conference_bw.jpeg"/></div><main class="layout_main__mXTwS"><h1>How to Transfer Files Between Computers Using HDMI (Part 4: HDMI Failure)</h1><div class="layout_blogPostContainer__WYELx"><p class="layout_blogPostDate__LUvx5">Posted on: <!-- -->2023-05-26</p><p>Reading the video without going by the video card and the HDMI cable was a success. However, when it was the time to send the video in these additional steps, the video received was corrupted. The failure was subtle as the footage could play and had the red frame and some colors on the top. However, the accuracy of the color was altered, making the data unreadable on extraction.</p>
<h1>Hypothesis</h1>
<ul>
<li>Pixel color are unreliable</li>
<li>Pixel color bleeds into their neighbor</li>
</ul>
<h1>First Change: Each character in 1 pixel is 0 or 1.</h1>
<p>To create room for inaccuracy, we can have black or white pixel instead of relying on the 255 values possible for the R, G and B. The problem is the video will be a lot bigger. Each character is 8 bits, and we were able to store in 1 pixel 3 characters. Now, by using only black or white color, we can represent 0 and 1 value. It means we need 8 pixels for a single character (1 character = 1 byte = 8 bits). It is 24x less efficient.</p>
<p>Some calculation shows that using HD resolution at 30fps we have 1920x1080x30/8 byte per second or: 7 776 000 bytes per second or 7.7 megs/second. Far from our 100 megs/second but still viable if we can extract the content without alteration.</p>
<p>The change will fix the first hypothesis that the color is unreliable. With the black/white approach, even if a pixel is not a totally white value with <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>(255,255,255)</span></span></code></span> or totally black <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>(0,0,0)</span></span></code></span>, we can go to the closest value. For example, if there is a pixel with <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>(10,13,32)</span></span></code></span> we can say that it is closer to white and thus the value represent a bit with a value of <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>0</span></span></code></span>.
The first change requires adding a new option to the CLI, which would let us switch between different algo. We had the first one that I now call &quot;RGB&quot; and in this first change, we add a &quot;bw&quot; for the black and white algorithm.</p>
<h2>Result of the modification</h2>
<p>The first change resulted, as expected in a bigger file, and the visual was more apparent: the end-of-file character is represented like any other character with 8 pixels that keep filling the frame until the end for the small test. Thus, it visually looks like lines.</p>
<p><img src="/images/blog/hdmi-file-transfer-video-frame-bw-lines.png" alt=""/></p>
<p>A new error message appears when extracting the text. Instead of the previous <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>mcbpc damaged</span></span></code></span>, this time it is about a market bit missing.</p>
<figure data-rehype-pretty-code-figure=""><pre style="background-color:#fff;color:#24292e" tabindex="0" data-language="sh" data-theme="github-light"><code data-language="sh" data-theme="github-light" style="display:grid"><span data-line=""><span>Running `target/debug/hdmifiletransporter -m extract -i outputs/out_from_hdmi_bw_1.avi -o outputs/text_bw_1.txt --fps 30 --height 1080 --width 1920 --size 1 -a bw`</span></span>
<span data-line=""><span>[mpeg4 @ 0x55aa4bc17100] 1. marker bit missing in 3. esc</span></span>
<span data-line=""><span>[mpeg4 @ 0x55aa4bc17100] Error at MB: 8038</span></span></code></pre></figure>
<h2>Hypothesis of Failure</h2>
<p>The first change might fail because of the way I am using ffmpeg. I am recording, and I am killing the process once I see on the source computer a couple of red screen. However, VLC, Windows Media Player and Clipchamp can all read the file. So it does not look to be corrupted.</p>
<p>While investigating, I found out that the count of frame recorded was 304 (about 10 seconds of recording), but the count of <em>relevant frame</em> which are between two red frames, were always zero. Indeed! The black and white algorithm reads the pixel and constantly moves the color to white or black, so the red color was never picked up. While it does not explain the error seen, it shows a problem to fix. An alteration on the code to proceed the pixel differently was required.</p>
<h1>Second Change: Handling the Starting and Ending Frame</h1>
<p>As mentioned, the red frame was not handled with the black-and-white algorithm. The change was to reach each frame with the full color and return a frame information that contained the black and white data as well as a boolean flag indicating if the frame was a &quot;red one&quot;, also known as the &quot;starting frame&quot;. The code changed for the RGB (color) algorithm as well to ensure similarity in the flow.</p>
<p>Once the change was made, I pulled the change in the second computer and ran the video while recording with the second one.</p>
<h2>Hypothesis of Failure</h2>
<p>This time, the generated file couldn&#x27;t be opened at all.</p>
<p>A step back to ffmpeg:</p>
<figure data-rehype-pretty-code-figure=""><pre style="background-color:#fff;color:#24292e" tabindex="0" data-language="sh" data-theme="github-light"><code data-language="sh" data-theme="github-light" style="display:grid"><span data-line=""><span>ffmpeg -r 30 -f dshow -s 1920x1080 -vcodec mjpeg -i video=&quot;USB Video&quot; -r 30 out.mp4</span></span></code></pre></figure>
<p>We might have an issue with the <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>vcodec</span></span></code></span> used. The choice was because the capture card stream data using <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>mjpeg</span></span></code></span> (<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>ffmpeg -f dshow -list_options true -i video= &quot;USB Video&quot;</span></span></code></span>). Maybe, we should capture in raw and then manipulate the data received and figure out which option is the best. I found out in the <a href="http://ffmpeg.org/ffmpeg.html#Stream-copy">ffmpeg documentation an option called stream copy</a>.</p>
<p>Using <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>-codec:v copy</span></span></code></span> we tell <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>ffmpeg</span></span></code></span> to copy all the video frame</p>
<figure data-rehype-pretty-code-figure=""><pre style="background-color:#fff;color:#24292e" tabindex="0" data-language="sh" data-theme="github-light"><code data-language="sh" data-theme="github-light" style="display:grid"><span data-line=""><span>ffmpeg -f vfwcap -r 30 -i video= &quot;USB Video&quot; -codec:v copy rawvideo.nut</span></span></code></pre></figure>
<p>Then, we need to use the raw format and convert it into a video format that the video player can read The input (<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>-i&#x27;) is the raw video from the previous step. The </span></span></code></span>-codec:v<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>is the desired output video format. The</span></span></code></span>-crf 0<span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>means to be lossless. The</span></span></code></span>-preset` indicates how the compression ratio occurs. Slower it goes, the less erroneous the compression.</p>
<p>You can get more information in the <a href="https://trac.ffmpeg.org/wiki/Encode/H.264">H.264 ffmpeg documentation</a>.</p>
<figure data-rehype-pretty-code-figure=""><pre style="background-color:#fff;color:#24292e" tabindex="0" data-language="sh" data-theme="github-light"><code data-language="sh" data-theme="github-light" style="display:grid"><span data-line=""><span>ffmpeg -i rawvideo.nut -codec:v libx264 -crf 0 -preset medium -pix_fmt yuv420p -movflags +faststart output.mkv</span></span></code></pre></figure>
<p>At this point, I was getting several issues. The first one was the size of the video recorded was humongous with several megs for few seconds. Then, the process of creating the data was very slow. For example, the second command to get the <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>mkv</span></span></code></span> took over 20 minutes for less than 10 seconds.</p>
<h1>Third Change: Step Back</h1>
<p>At this point, I decided to use the approach of having big pixels. Since the beginning, a <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>size</span></span></code></span> parameter gives the option to generate many pixels for the same information. Hence, instead of using the value <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>1</span></span></code></span> and having the whole bit value into 1 pixel, using <span data-rehype-pretty-code-figure=""><code data-language="plaintext" data-theme="github-light" style="background-color:#fff;color:#24292e"><span data-line=""><span>20</span></span></code></span>, you can get 20x20 pixels to hold the black or white color. The reading uses an average which then can be easily distinguishable when we have two values that are far away. Now that the bits were quickly visible I noticed something off.</p>
<h2>Hypothesis of Failure</h2>
<p>The hypothesis was that the drawing into the video using the black and white algorithm was quickly true: the data was not appropriately written with 1 bit off every byte, making the extraction impossible.</p>
<h1>Fourth Change: Duplicate Red Frame</h1>
<p>The code was modified, and unit tests added. Finally, the command to read the pixel came back to the first one:</p>
<figure data-rehype-pretty-code-figure=""><pre style="background-color:#fff;color:#24292e" tabindex="0" data-language="sh" data-theme="github-light"><code data-language="sh" data-theme="github-light" style="display:grid"><span data-line=""><span>ffmpeg -r 30 -f dshow -s 1920x1080 -vcodec mjpeg -i video=&quot;USB Video&quot; -r 30 out_bw_red_fix_2.mp4</span></span></code></pre></figure>
<p>The result was extracted using:</p>
<figure data-rehype-pretty-code-figure=""><pre style="background-color:#fff;color:#24292e" tabindex="0" data-language="sh" data-theme="github-light"><code data-language="sh" data-theme="github-light" style="display:grid"><span data-line=""><span>cargo run -- -m extract -i outputs/out_bw_red_fix_2.mp4 -o outputs/text1.txt --fps 30 --height 1080 --width 1920 --size 1 -a bw</span></span></code></pre></figure>
<p>However, the file was empty. After some debugging, I discovered that the logic of finding the red frame that set the start and the end had a flaw: If the ffmpeg recorsd twice the same red frame next to each other (duplicate reading), it would have zero frames of data. This discovery also found that good frame were duplicated. While the generated video had no duplicated frame, the transmission and recording caused the frame to duplicate here and there. The fix was to ensure we ignore the data of a frame if the content is exactly the same as the previous one.</p>
<p>To achieve this validation, a quick CRC32 can be applied to the frame&#x27;s byte and ensure that no consecutive checksum is the same.</p>
<h1>Working Solution or Not?</h1>
<p>This time we go with a size of 10 with the duplication fix applied.</p>
<p>On the source computer:
&quot;`sh
cargo run -- -m inject -i testAssets/text1.txt -o outputs/out_bw_no_dup.mp4 -o --fps 30 --height 1080 --width 1920 --size 10 -a bw</p>
<figure data-rehype-pretty-code-figure=""><pre style="background-color:#fff;color:#24292e" tabindex="0" data-language="plaintext" data-theme="github-light"><code data-language="plaintext" data-theme="github-light" style="display:grid"><span data-line=""> </span>
<span data-line=""><span>The video plays fullscreen and on the target computer:</span></span>
<span data-line=""> </span>
<span data-line=""><span>```sh</span></span>
<span data-line=""><span>cd outputs</span></span>
<span data-line=""><span>ffmpeg -r 30 -f dshow -s 1920x1080 -vcodec mjpeg -i video=&quot;USB Video&quot; -r 30 out_bw_no_dup.mp4</span></span>
<span data-line=""><span>cargo run -- -m extract -i outputs/out_bw_no_dup.mp4 -o outputs/text1.txt --fps 30 --height 1080 --width 1920 --size 10 -a bw</span></span></code></pre></figure>
<p>It worked!</p>
<p>The same test with a size of 1 pixel was also working!</p>
<h1>Conclusion</h1>
<p>The next article will get into a more realistic use case: one big zip file. Using something outside text will reveal not only a massive flaw of one of the decisions taken at the inception of this project but will expose why only the black-and-white solution will work in the future.</p></div></main><div class="layout_paginationBar__jnuuR"><div class="layout_paginationTitle__PsOw5">Chronological Blog Articles by Page</div><div class="layout_paginationLinks__LdBaH"><a class="" href="/blog/page/1">1</a><a class="" href="/blog/page/2">2</a><a class="" href="/blog/page/3">3</a><a class="" href="/blog/page/4">4</a><a class="" href="/blog/page/5">5</a><a class="" href="/blog/page/6">6</a><a class="" href="/blog/page/7">7</a><a class="" href="/blog/page/8">8</a><a class="" href="/blog/page/9">9</a><a class="" href="/blog/page/10">10</a><a class="" href="/blog/page/11">11</a><a class="" href="/blog/page/12">12</a><a class="" href="/blog/page/13">13</a><a class="" href="/blog/page/14">14</a><a class="" href="/blog/page/15">15</a><a class="" href="/blog/page/16">16</a><a class="" href="/blog/page/17">17</a><a class="" href="/blog/page/18">18</a><a class="" href="/blog/page/19">19</a><a class="" href="/blog/page/20">20</a><a class="" href="/blog/page/21">21</a><a class="" href="/blog/page/22">22</a><a class="" href="/blog/page/23">23</a><a class="" href="/blog/page/24">24</a><a class="" href="/blog/page/25">25</a><a class="" href="/blog/page/26">26</a><a class="" href="/blog/page/27">27</a><a class="" href="/blog/page/28">28</a><a class="" href="/blog/page/29">29</a><a class="" href="/blog/page/30">30</a><a class="" href="/blog/page/31">31</a><a class="" href="/blog/page/32">32</a><a class="" href="/blog/page/33">33</a><a class="" href="/blog/page/34">34</a><a class="" href="/blog/page/35">35</a><a class="" href="/blog/page/36">36</a><a class="" href="/blog/page/37">37</a><a class="" href="/blog/page/38">38</a><a class="" href="/blog/page/39">39</a><a class="" href="/blog/page/40">40</a><a class="" href="/blog/page/41">41</a><a class="" href="/blog/page/42">42</a><a class="" href="/blog/page/43">43</a><a class="" href="/blog/page/44">44</a><a class="" href="/blog/page/45">45</a><a class="" href="/blog/page/46">46</a><a class="" href="/blog/page/47">47</a><a class="" href="/blog/page/48">48</a><a class="" href="/blog/page/49">49</a><a class="" href="/blog/page/50">50</a><a class="" href="/blog/page/51">51</a><a class="" href="/blog/page/52">52</a><a class="" href="/blog/page/53">53</a><a class="" href="/blog/page/54">54</a><a class="" href="/blog/page/55">55</a><a class="" href="/blog/page/56">56</a><a class="" href="/blog/page/57">57</a><a class="" href="/blog/page/58">58</a><a class="" href="/blog/page/59">59</a><a class="" href="/blog/page/60">60</a><a class="" href="/blog/page/61">61</a><a class="" href="/blog/page/62">62</a><a class="" href="/blog/page/63">63</a><a class="" href="/blog/page/64">64</a><a class="" href="/blog/page/65">65</a><a class="" href="/blog/page/66">66</a><a class="" href="/blog/page/67">67</a><a class="" href="/blog/page/68">68</a><a class="" href="/blog/page/69">69</a><a class="" href="/blog/page/70">70</a><a class="" href="/blog/page/71">71</a><a class="" href="/blog/page/72">72</a><a class="" href="/blog/page/73">73</a><a class="" href="/blog/page/74">74</a><a class="" href="/blog/page/75">75</a><a class="" href="/blog/page/76">76</a><a class="" href="/blog/page/77">77</a></div></div></div></div><script src="/_next/static/chunks/webpack-692a33e6ebc06ff4.js" crossorigin="" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/f7004a68ac8d367c.css\",\"style\",{\"crossOrigin\":\"\"}]\n0:\"$L2\"\n"])</script><script>self.__next_f.push([1,"3:HL[\"/_next/static/media/c9a5bc6a7c948fb0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n4:HL[\"/_next/static/css/e917b4f00bcb2347.css\",\"style\",{\"crossOrigin\":\"\"}]\n"])</script><script>self.__next_f.push([1,"5:I[7690,[],\"\"]\n8:I[5613,[],\"\"]\na:I[1778,[],\"\"]\nc:I[8955,[],\"\"]\n9:[\"slug\",\"how-to-transfer-files-between-computers-using-HDMI-Part-4-hdmi-failure\",\"d\"]\nd:[]\n"])</script><script>self.__next_f.push([1,"2:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/f7004a68ac8d367c.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]],[\"$\",\"$L5\",null,{\"buildId\":\"U9WHEHP9m9dAVmOepwIU5\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/blog/how-to-transfer-files-between-computers-using-HDMI-Part-4-hdmi-failure\",\"initialTree\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"how-to-transfer-files-between-computers-using-HDMI-Part-4-hdmi-failure\",\"d\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":\\\"how-to-transfer-files-between-computers-using-HDMI-Part-4-hdmi-failure\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"how-to-transfer-files-between-computers-using-HDMI-Part-4-hdmi-failure\",\"d\"],{\"children\":[\"__PAGE__\",{},[\"$L6\",\"$L7\",null]]},[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\",\"$9\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/e917b4f00bcb2347.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]]}]]},[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}]]},[null,[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"title\",null,{\"children\":\"Patrick Desjardins Website and Blog\"}],[\"$\",\"meta\",null,{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1, shrink-to-fit=no\"}]]}],[\"$\",\"body\",null,{\"className\":\"layout_bodystyle__4ncsS\",\"children\":[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}]}]]}],null]],\"initialHead\":[false,\"$Lb\"],\"globalErrorComponent\":\"$c\",\"missingSlots\":\"$Wd\"}]]\n"])</script><script>self.__next_f.push([1,"e:I[5250,[\"674\",\"static/chunks/674-a46cce5ee161a346.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-e23445258eb56deb.js\"],\"\"]\nf:I[1749,[\"674\",\"static/chunks/674-a46cce5ee161a346.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-e23445258eb56deb.js\"],\"Image\"]\nb:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"2\",{\"name\":\"next-size-adjust\"}]]\n6:null\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"div\",null,{\"className\":\"__className_aaf875\",\"children\":[\"$\",\"div\",null,{\"className\":\"layout_container__Tovb9\",\"children\":[[\"$\",\"header\",null,{\"className\":\"layout_siteTitle__k5U8g\",\"children\":\"Patrick Desjardins Blog\"}],[\"$\",\"nav\",null,{\"children\":[\"$\",\"ul\",null,{\"className\":\"layout_navLinks__mf70r\",\"children\":[\"$\",\"li\",null,{\"className\":\"layout_navLinkItem__1L8fB\",\"children\":[[\"$\",\"$Le\",null,{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/\",\"children\":\"Main Page\"}],[\"$\",\"$Le\",null,{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog\",\"children\":\"Blog\"}],[[\"$\",\"$Le\",\"2024\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2024\",\"children\":2024}],[\"$\",\"$Le\",\"2023\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2023\",\"children\":2023}],[\"$\",\"$Le\",\"2022\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2022\",\"children\":2022}],[\"$\",\"$Le\",\"2021\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2021\",\"children\":2021}],[\"$\",\"$Le\",\"2020\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2020\",\"children\":2020}],[\"$\",\"$Le\",\"2019\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2019\",\"children\":2019}],[\"$\",\"$Le\",\"2018\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2018\",\"children\":2018}],[\"$\",\"$Le\",\"2017\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2017\",\"children\":2017}],[\"$\",\"$Le\",\"2016\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2016\",\"children\":2016}],[\"$\",\"$Le\",\"2015\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2015\",\"children\":2015}],[\"$\",\"$Le\",\"2014\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2014\",\"children\":2014}],[\"$\",\"$Le\",\"2013\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2013\",\"children\":2013}],[\"$\",\"$Le\",\"2012\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2012\",\"children\":2012}],[\"$\",\"$Le\",\"2011\",{\"className\":\"layout_navLinkText__bt28R\",\"href\":\"/blog/for/2011\",\"children\":2011}]]]}]}]}],[\"$\",\"div\",null,{\"children\":[\"$\",\"$Lf\",null,{\"className\":\"layout_blogTopPicture__RJHNN\",\"alt\":\"Patrick Desjardins picture from a conference\",\"src\":\"/images/backgrounds/patrickdesjardins_conference_bw.jpeg\",\"width\":1000,\"height\":300}]}],[\"$\",\"main\",null,{\"className\":\"layout_main__mXTwS\",\"children\":[[\"$\",\"h1\",null,{\"children\":\"How to Transfer Files Between Computers Using HDMI (Part 4: HDMI Failure)\"}],[\"$\",\"div\",null,{\"className\":\"layout_blogPostContainer__WYELx\",\"children\":[[\"$\",\"p\",null,{\"className\":\"layout_blogPostDate__LUvx5\",\"children\":[\"Posted on: \",\"2023-05-26\"]}],[[\"$\",\"p\",null,{\"children\":\"Reading the video without going by the video card and the HDMI cable was a success. However, when it was the time to send the video in these additional steps, the video received was corrupted. The failure was subtle as the footage could play and had the red frame and some colors on the top. However, the accuracy of the color was altered, making the data unreadable on extraction.\"}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Hypothesis\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Pixel color are unreliable\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Pixel color bleeds into their neighbor\"}],\"\\n\"]}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"First Change: Each character in 1 pixel is 0 or 1.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"To create room for inaccuracy, we can have black or white pixel instead of relying on the 255 values possible for the R, G and B. The problem is the video will be a lot bigger. Each character is 8 bits, and we were able to store in 1 pixel 3 characters. Now, by using only black or white color, we can represent 0 and 1 value. It means we need 8 pixels for a single character (1 character = 1 byte = 8 bits). It is 24x less efficient.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Some calculation shows that using HD resolution at 30fps we have 1920x1080x30/8 byte per second or: 7 776 000 bytes per second or 7.7 megs/second. Far from our 100 megs/second but still viable if we can extract the content without alteration.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"The change will fix the first hypothesis that the color is unreliable. With the black/white approach, even if a pixel is not a totally white value with \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"(255,255,255)\"}]}]}]}],\" or totally black \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"(0,0,0)\"}]}]}]}],\", we can go to the closest value. For example, if there is a pixel with \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"(10,13,32)\"}]}]}]}],\" we can say that it is closer to white and thus the value represent a bit with a value of \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"0\"}]}]}]}],\".\\nThe first change requires adding a new option to the CLI, which would let us switch between different algo. We had the first one that I now call \\\"RGB\\\" and in this first change, we add a \\\"bw\\\" for the black and white algorithm.\"]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Result of the modification\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The first change resulted, as expected in a bigger file, and the visual was more apparent: the end-of-file character is represented like any other character with 8 pixels that keep filling the frame until the end for the small test. Thus, it visually looks like lines.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"src\":\"/images/blog/hdmi-file-transfer-video-frame-bw-lines.png\",\"alt\":\"\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"A new error message appears when extracting the text. Instead of the previous \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"mcbpc damaged\"}]}]}]}],\", this time it is about a market bit missing.\"]}],\"\\n\",[\"$\",\"figure\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"tabIndex\":\"0\",\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"style\":{\"display\":\"grid\"},\"children\":[[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"Running `target/debug/hdmifiletransporter -m extract -i outputs/out_from_hdmi_bw_1.avi -o outputs/text_bw_1.txt --fps 30 --height 1080 --width 1920 --size 1 -a bw`\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"[mpeg4 @ 0x55aa4bc17100] 1. marker bit missing in 3. esc\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"[mpeg4 @ 0x55aa4bc17100] Error at MB: 8038\"}]}]]}]}]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Hypothesis of Failure\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The first change might fail because of the way I am using ffmpeg. I am recording, and I am killing the process once I see on the source computer a couple of red screen. However, VLC, Windows Media Player and Clipchamp can all read the file. So it does not look to be corrupted.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"While investigating, I found out that the count of frame recorded was 304 (about 10 seconds of recording), but the count of \",[\"$\",\"em\",null,{\"children\":\"relevant frame\"}],\" which are between two red frames, were always zero. Indeed! The black and white algorithm reads the pixel and constantly moves the color to white or black, so the red color was never picked up. While it does not explain the error seen, it shows a problem to fix. An alteration on the code to proceed the pixel differently was required.\"]}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Second Change: Handling the Starting and Ending Frame\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"As mentioned, the red frame was not handled with the black-and-white algorithm. The change was to reach each frame with the full color and return a frame information that contained the black and white data as well as a boolean flag indicating if the frame was a \\\"red one\\\", also known as the \\\"starting frame\\\". The code changed for the RGB (color) algorithm as well to ensure similarity in the flow.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Once the change was made, I pulled the change in the second computer and ran the video while recording with the second one.\"}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Hypothesis of Failure\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"This time, the generated file couldn't be opened at all.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"A step back to ffmpeg:\"}],\"\\n\",[\"$\",\"figure\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"tabIndex\":\"0\",\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"style\":{\"display\":\"grid\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"ffmpeg -r 30 -f dshow -s 1920x1080 -vcodec mjpeg -i video=\\\"USB Video\\\" -r 30 out.mp4\"}]}]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"We might have an issue with the \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"vcodec\"}]}]}]}],\" used. The choice was because the capture card stream data using \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"mjpeg\"}]}]}]}],\" (\",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"ffmpeg -f dshow -list_options true -i video= \\\"USB Video\\\"\"}]}]}]}],\"). Maybe, we should capture in raw and then manipulate the data received and figure out which option is the best. I found out in the \",[\"$\",\"a\",null,{\"href\":\"http://ffmpeg.org/ffmpeg.html#Stream-copy\",\"children\":\"ffmpeg documentation an option called stream copy\"}],\".\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Using \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"-codec:v copy\"}]}]}]}],\" we tell \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"ffmpeg\"}]}]}]}],\" to copy all the video frame\"]}],\"\\n\",[\"$\",\"figure\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"tabIndex\":\"0\",\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"style\":{\"display\":\"grid\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"ffmpeg -f vfwcap -r 30 -i video= \\\"USB Video\\\" -codec:v copy rawvideo.nut\"}]}]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"Then, we need to use the raw format and convert it into a video format that the video player can read The input (\",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"-i') is the raw video from the previous step. The \"}]}]}]}],\"-codec:v\",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"is the desired output video format. The\"}]}]}]}],\"-crf 0\",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"means to be lossless. The\"}]}]}]}],\"-preset` indicates how the compression ratio occurs. Slower it goes, the less erroneous the compression.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"You can get more information in the \",[\"$\",\"a\",null,{\"href\":\"https://trac.ffmpeg.org/wiki/Encode/H.264\",\"children\":\"H.264 ffmpeg documentation\"}],\".\"]}],\"\\n\",[\"$\",\"figure\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"tabIndex\":\"0\",\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"style\":{\"display\":\"grid\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"ffmpeg -i rawvideo.nut -codec:v libx264 -crf 0 -preset medium -pix_fmt yuv420p -movflags +faststart output.mkv\"}]}]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"At this point, I was getting several issues. The first one was the size of the video recorded was humongous with several megs for few seconds. Then, the process of creating the data was very slow. For example, the second command to get the \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"mkv\"}]}]}]}],\" took over 20 minutes for less than 10 seconds.\"]}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Third Change: Step Back\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"At this point, I decided to use the approach of having big pixels. Since the beginning, a \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"size\"}]}]}]}],\" parameter gives the option to generate many pixels for the same information. Hence, instead of using the value \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"1\"}]}]}]}],\" and having the whole bit value into 1 pixel, using \",[\"$\",\"span\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"20\"}]}]}]}],\", you can get 20x20 pixels to hold the black or white color. The reading uses an average which then can be easily distinguishable when we have two values that are far away. Now that the bits were quickly visible I noticed something off.\"]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Hypothesis of Failure\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The hypothesis was that the drawing into the video using the black and white algorithm was quickly true: the data was not appropriately written with 1 bit off every byte, making the extraction impossible.\"}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Fourth Change: Duplicate Red Frame\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The code was modified, and unit tests added. Finally, the command to read the pixel came back to the first one:\"}],\"\\n\",[\"$\",\"figure\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"tabIndex\":\"0\",\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"style\":{\"display\":\"grid\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"ffmpeg -r 30 -f dshow -s 1920x1080 -vcodec mjpeg -i video=\\\"USB Video\\\" -r 30 out_bw_red_fix_2.mp4\"}]}]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The result was extracted using:\"}],\"\\n\",[\"$\",\"figure\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"tabIndex\":\"0\",\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"sh\",\"data-theme\":\"github-light\",\"style\":{\"display\":\"grid\"},\"children\":[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"cargo run -- -m extract -i outputs/out_bw_red_fix_2.mp4 -o outputs/text1.txt --fps 30 --height 1080 --width 1920 --size 1 -a bw\"}]}]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"However, the file was empty. After some debugging, I discovered that the logic of finding the red frame that set the start and the end had a flaw: If the ffmpeg recorsd twice the same red frame next to each other (duplicate reading), it would have zero frames of data. This discovery also found that good frame were duplicated. While the generated video had no duplicated frame, the transmission and recording caused the frame to duplicate here and there. The fix was to ensure we ignore the data of a frame if the content is exactly the same as the previous one.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"To achieve this validation, a quick CRC32 can be applied to the frame's byte and ensure that no consecutive checksum is the same.\"}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Working Solution or Not?\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"This time we go with a size of 10 with the duplication fix applied.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"On the source computer:\\n\\\"`sh\\ncargo run -- -m inject -i testAssets/text1.txt -o outputs/out_bw_no_dup.mp4 -o --fps 30 --height 1080 --width 1920 --size 10 -a bw\"}],\"\\n\",[\"$\",\"figure\",null,{\"data-rehype-pretty-code-figure\":\"\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"backgroundColor\":\"#fff\",\"color\":\"#24292e\"},\"tabIndex\":\"0\",\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"children\":[\"$\",\"code\",null,{\"data-language\":\"plaintext\",\"data-theme\":\"github-light\",\"style\":{\"display\":\"grid\"},\"children\":[[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":\" \"}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"The video plays fullscreen and on the target computer:\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":\" \"}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"```sh\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"cd outputs\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"ffmpeg -r 30 -f dshow -s 1920x1080 -vcodec mjpeg -i video=\\\"USB Video\\\" -r 30 out_bw_no_dup.mp4\"}]}],\"\\n\",[\"$\",\"span\",null,{\"data-line\":\"\",\"children\":[\"$\",\"span\",null,{\"children\":\"cargo run -- -m extract -i outputs/out_bw_no_dup.mp4 -o outputs/text1.txt --fps 30 --height 1080 --width 1920 --size 10 -a bw\"}]}]]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"It worked!\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The same test with a size of 1 pixel was also working!\"}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"Conclusion\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The next article will get into a more realistic use case: one big zip file. Using something outside text will reveal not only a massive flaw of one of the decisions taken at the inception of this project but will expose why only the black-and-white solution will work in the future.\"}]]]}]]}],[\"$\",\"div\",null,{\"className\":\"layout_paginationBar__jnuuR\",\"children\":[[\"$\",\"div\",null,{\"className\":\"layout_paginationTitle__PsOw5\",\"children\":\"Chronological Blog Articles by Page\"}],[\"$\",\"div\",null,{\"className\":\"layout_paginationLinks__LdBaH\",\"children\":[[\"$\",\"$Le\",\"1\",{\"className\":\"\",\"href\":\"/blog/page/1\",\"children\":1}],[\"$\",\"$Le\",\"2\",{\"className\":\"\",\"href\":\"/blog/page/2\",\"children\":2}],[\"$\",\"$Le\",\"3\",{\"className\":\"\",\"href\":\"/blog/page/3\",\"children\":3}],[\"$\",\"$Le\",\"4\",{\"className\":\"\",\"href\":\"/blog/page/4\",\"children\":4}],[\"$\",\"$Le\",\"5\",{\"className\":\"\",\"href\":\"/blog/page/5\",\"children\":5}],[\"$\",\"$Le\",\"6\",{\"className\":\"\",\"href\":\"/blog/page/6\",\"children\":6}],[\"$\",\"$Le\",\"7\",{\"className\":\"\",\"href\":\"/blog/page/7\",\"children\":7}],[\"$\",\"$Le\",\"8\",{\"className\":\"\",\"href\":\"/blog/page/8\",\"children\":8}],[\"$\",\"$Le\",\"9\",{\"className\":\"\",\"href\":\"/blog/page/9\",\"children\":9}],[\"$\",\"$Le\",\"10\",{\"className\":\"\",\"href\":\"/blog/page/10\",\"children\":10}],[\"$\",\"$Le\",\"11\",{\"className\":\"\",\"href\":\"/blog/page/11\",\"children\":11}],[\"$\",\"$Le\",\"12\",{\"className\":\"\",\"href\":\"/blog/page/12\",\"children\":12}],[\"$\",\"$Le\",\"13\",{\"className\":\"\",\"href\":\"/blog/page/13\",\"children\":13}],[\"$\",\"$Le\",\"14\",{\"className\":\"\",\"href\":\"/blog/page/14\",\"children\":14}],[\"$\",\"$Le\",\"15\",{\"className\":\"\",\"href\":\"/blog/page/15\",\"children\":15}],[\"$\",\"$Le\",\"16\",{\"className\":\"\",\"href\":\"/blog/page/16\",\"children\":16}],[\"$\",\"$Le\",\"17\",{\"className\":\"\",\"href\":\"/blog/page/17\",\"children\":17}],[\"$\",\"$Le\",\"18\",{\"className\":\"\",\"href\":\"/blog/page/18\",\"children\":18}],[\"$\",\"$Le\",\"19\",{\"className\":\"\",\"href\":\"/blog/page/19\",\"children\":19}],[\"$\",\"$Le\",\"20\",{\"className\":\"\",\"href\":\"/blog/page/20\",\"children\":20}],[\"$\",\"$Le\",\"21\",{\"className\":\"\",\"href\":\"/blog/page/21\",\"children\":21}],[\"$\",\"$Le\",\"22\",{\"className\":\"\",\"href\":\"/blog/page/22\",\"children\":22}],[\"$\",\"$Le\",\"23\",{\"className\":\"\",\"href\":\"/blog/page/23\",\"children\":23}],[\"$\",\"$Le\",\"24\",{\"className\":\"\",\"href\":\"/blog/page/24\",\"children\":24}],[\"$\",\"$Le\",\"25\",{\"className\":\"\",\"href\":\"/blog/page/25\",\"children\":25}],[\"$\",\"$Le\",\"26\",{\"className\":\"\",\"href\":\"/blog/page/26\",\"children\":26}],[\"$\",\"$Le\",\"27\",{\"className\":\"\",\"href\":\"/blog/page/27\",\"children\":27}],[\"$\",\"$Le\",\"28\",{\"className\":\"\",\"href\":\"/blog/page/28\",\"children\":28}],[\"$\",\"$Le\",\"29\",{\"className\":\"\",\"href\":\"/blog/page/29\",\"children\":29}],[\"$\",\"$Le\",\"30\",{\"className\":\"\",\"href\":\"/blog/page/30\",\"children\":30}],[\"$\",\"$Le\",\"31\",{\"className\":\"\",\"href\":\"/blog/page/31\",\"children\":31}],[\"$\",\"$Le\",\"32\",{\"className\":\"\",\"href\":\"/blog/page/32\",\"children\":32}],[\"$\",\"$Le\",\"33\",{\"className\":\"\",\"href\":\"/blog/page/33\",\"children\":33}],[\"$\",\"$Le\",\"34\",{\"className\":\"\",\"href\":\"/blog/page/34\",\"children\":34}],[\"$\",\"$Le\",\"35\",{\"className\":\"\",\"href\":\"/blog/page/35\",\"children\":35}],[\"$\",\"$Le\",\"36\",{\"className\":\"\",\"href\":\"/blog/page/36\",\"children\":36}],[\"$\",\"$Le\",\"37\",{\"className\":\"\",\"href\":\"/blog/page/37\",\"children\":37}],[\"$\",\"$Le\",\"38\",{\"className\":\"\",\"href\":\"/blog/page/38\",\"children\":38}],[\"$\",\"$Le\",\"39\",{\"className\":\"\",\"href\":\"/blog/page/39\",\"children\":39}],[\"$\",\"$Le\",\"40\",{\"className\":\"\",\"href\":\"/blog/page/40\",\"children\":40}],[\"$\",\"$Le\",\"41\",{\"className\":\"\",\"href\":\"/blog/page/41\",\"children\":41}],[\"$\",\"$Le\",\"42\",{\"className\":\"\",\"href\":\"/blog/page/42\",\"children\":42}],[\"$\",\"$Le\",\"43\",{\"className\":\"\",\"href\":\"/blog/page/43\",\"children\":43}],[\"$\",\"$Le\",\"44\",{\"className\":\"\",\"href\":\"/blog/page/44\",\"children\":44}],[\"$\",\"$Le\",\"45\",{\"className\":\"\",\"href\":\"/blog/page/45\",\"children\":45}],[\"$\",\"$Le\",\"46\",{\"className\":\"\",\"href\":\"/blog/page/46\",\"children\":46}],[\"$\",\"$Le\",\"47\",{\"className\":\"\",\"href\":\"/blog/page/47\",\"children\":47}],[\"$\",\"$Le\",\"48\",{\"className\":\"\",\"href\":\"/blog/page/48\",\"children\":48}],[\"$\",\"$Le\",\"49\",{\"className\":\"\",\"href\":\"/blog/page/49\",\"children\":49}],[\"$\",\"$Le\",\"50\",{\"className\":\"\",\"href\":\"/blog/page/50\",\"children\":50}],[\"$\",\"$Le\",\"51\",{\"className\":\"\",\"href\":\"/blog/page/51\",\"children\":51}],[\"$\",\"$Le\",\"52\",{\"className\":\"\",\"href\":\"/blog/page/52\",\"children\":52}],[\"$\",\"$Le\",\"53\",{\"className\":\"\",\"href\":\"/blog/page/53\",\"children\":53}],[\"$\",\"$Le\",\"54\",{\"className\":\"\",\"href\":\"/blog/page/54\",\"children\":54}],[\"$\",\"$Le\",\"55\",{\"className\":\"\",\"href\":\"/blog/page/55\",\"children\":55}],[\"$\",\"$Le\",\"56\",{\"className\":\"\",\"href\":\"/blog/page/56\",\"children\":56}],[\"$\",\"$Le\",\"57\",{\"className\":\"\",\"href\":\"/blog/page/57\",\"children\":57}],[\"$\",\"$Le\",\"58\",{\"className\":\"\",\"href\":\"/blog/page/58\",\"children\":58}],[\"$\",\"$Le\",\"59\",{\"className\":\"\",\"href\":\"/blog/page/59\",\"children\":59}],[\"$\",\"$Le\",\"60\",{\"className\":\"\",\"href\":\"/blog/page/60\",\"children\":60}],[\"$\",\"$Le\",\"61\",{\"className\":\"\",\"href\":\"/blog/page/61\",\"children\":61}],[\"$\",\"$Le\",\"62\",{\"className\":\"\",\"href\":\"/blog/page/62\",\"children\":62}],[\"$\",\"$Le\",\"63\",{\"className\":\"\",\"href\":\"/blog/page/63\",\"children\":63}],[\"$\",\"$Le\",\"64\",{\"className\":\"\",\"href\":\"/blog/page/64\",\"children\":64}],[\"$\",\"$Le\",\"65\",{\"className\":\"\",\"href\":\"/blog/page/65\",\"children\":65}],[\"$\",\"$Le\",\"66\",{\"className\":\"\",\"href\":\"/blog/page/66\",\"children\":66}],[\"$\",\"$Le\",\"67\",{\"className\":\"\",\"href\":\"/blog/page/67\",\"children\":67}],[\"$\",\"$Le\",\"68\",{\"className\":\"\",\"href\":\"/blog/page/68\",\"children\":68}],[\"$\",\"$Le\",\"69\",{\"className\":\"\",\"href\":\"/blog/page/69\",\"children\":69}],[\"$\",\"$Le\",\"70\",{\"className\":\"\",\"href\":\"/blog/page/70\",\"children\":70}],[\"$\",\"$Le\",\"71\",{\"className\":\"\",\"href\":\"/blog/page/71\",\"children\":71}],[\"$\",\"$Le\",\"72\",{\"className\":\"\",\"href\":\"/blog/page/72\",\"children\":72}],[\"$\",\"$Le\",\"73\",{\"className\":\"\",\"href\":\"/blog/page/73\",\"children\":73}],[\"$\",\"$Le\",\"74\",{\"className\":\"\",\"href\":\"/blog/page/74\",\"children\":74}],[\"$\",\"$Le\",\"75\",{\"className\":\"\",\"href\":\"/blog/page/75\",\"children\":75}],[\"$\",\"$Le\",\"76\",{\"className\":\"\",\"href\":\"/blog/page/76\",\"children\":76}],[\"$\",\"$Le\",\"77\",{\"className\":\"\",\"href\":\"/blog/page/77\",\"children\":77}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,""])</script></body></html>