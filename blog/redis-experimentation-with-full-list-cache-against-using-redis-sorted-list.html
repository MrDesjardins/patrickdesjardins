<!DOCTYPE html><html lang="en" class="layout_htmlstyle__PseMz"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/4cb872a2a77e328a.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/dabd5e64a469b0e1.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/be8a59717d6d5849.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/97e0a79122e618e4.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-3bbba27772baeadb.js"/><script src="/_next/static/chunks/2200cc46-73d9c2dcf2e9794f.js" async=""></script><script src="/_next/static/chunks/657-3551bff086733983.js" async=""></script><script src="/_next/static/chunks/main-app-67ffb56f87b9fb11.js" async=""></script><script src="/_next/static/chunks/156-2b9f703633e98ef7.js" async=""></script><script src="/_next/static/chunks/836-7e37630a3372363c.js" async=""></script><script src="/_next/static/chunks/app/blog/%5Bslug%5D/page-2829e3c199d313ca.js" async=""></script><title>Patrick Desjardins Blog - Redis Experimentation with Full List Cache against using Redis Sorted List</title><meta name="description" content="Redis Experimentation with Full List Cache against using Redis Sorted List"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="layout_bodystyle__4ncsS"><div class="layout_blogbodystyle___Uc1w"><div class="BlogBody_BlogBody__600mT"><header class="BlogBody_siteTitle__f7uyb">Patrick Desjardins Blog</header><nav><ul class="BlogBody_navLinks__ZV12t"><li class="BlogBody_navLinkItem__Pml2e"><a class="BlogBody_navLinkText__ZtH2y" href="/">Main Page</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog">Blog</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/search">Search</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2026">2026</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2025">2025</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2024">2024</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2023">2023</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2022">2022</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2021">2021</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2020">2020</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2019">2019</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2018">2018</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2017">2017</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2016">2016</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2015">2015</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2014">2014</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2013">2013</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2012">2012</a><a class="BlogBody_navLinkText__ZtH2y" href="/blog/for/2011">2011</a></li></ul></nav><div class="BlogBody_blogPictureContainer__IAbPL"><img alt="Patrick Desjardins picture from a conference" loading="lazy" width="800" height="260" decoding="async" data-nimg="1" class="BlogBody_blogTopPicture__L6lao" style="color:transparent" src="/images/backgrounds/patrickdesjardins_conference_bw.webp"/></div><main class="BlogBody_main__XrdKY"><h1 class="BlogBody_heading__bYRBe">Redis Experimentation with Full List Cache against using Redis Sorted List</h1><div class="Page_blogPostContainer__AUIcf"><p class="Page_blogPostDate__wVWWB">Posted on: <!-- -->2015-10-15</p><p>I am improving the performance of a system right now with <a href="http://redis.io/">Redis</a> and the library <a href="https://github.com/StackExchange/StackExchange.Redis">StackExchange</a>. Onne particular case was that I needed to cache a list of data that are ordered by rank from a value that change often. One requirement is that it&#x27;s possible that two items can have the same rank. For example:</p>
<pre class="language-plaintext"><code class="language-plaintext code-highlight"><span class="code-line"> Rank - Data - Value 1 - User 1 - 100 2 - User 2 - 99 3 - User 4 - 99 4 - User 5 - 97 
</span></code></pre>
<p>The data is in fact a serialized object that contains multiples classes. For not making this article too heavy, I will just use a string. Nevertheless, keep in mind that this is not a simple string unique identifier. The value column is required by Redis when using the <a href="http://redis.io/commands/zadd">Sorted List</a>. In reality, this value is inside the data, in a property.</p>
<p>This is also information that must be paged because the list can go around five thousand entries.</p>
<p>The first step was to measure the time when using the database. I got an average of <strong>264ms</strong> per query for 20 items on a set of 200 items. The database contains thousand of entry, the page is using a clause to filter down depending of other criteria defined inside the data (inside the class that we serialize). The next step was to use Redis as a simple cache -- once we get the result of the database we store it for few times. The first hit will have the same average, because it goes to the database, but the subsequent request will go inside Redis instead of the database. This was producing an improvement of 50% faster, with <strong>125ms</strong> in average. The key was determined by the type of list, by the filter attribute and the page number. For example, &quot;MyListOfObjectXXX_PartitionYYY_Page_1&quot;. The speed was interesting for me, I was aiming around 100 ms but I was satisfy with the result. The time also contains the time to deserialize the object to create a generic list of all 20 results. I count the deserialization process time in my benchmark because I was counting the ORM time to instantiate the object too. My concern with that solution is that every object can change its value at any time. The value does change the rank by consequence. Since I am also caching the data with a separate key for each instance, I duplicate this information in the cache. The size of the cache can be a problem in the long run, but the bigger problem is that the information become desynchronize. In fact, the source of truth is the individual cached version in the system. It looks like this : &quot;MyData_Key_1&quot;. I set an expiry because this is not the real source of data. I will not invalidate that data like the rest of the software when values change from the entity. I will let them expire and than change it. It means that a user that drill down from the list can get an up-to-date data. This is the cost to pay (so far) for a one minute delay.</p>
<pre class="language-csharp"><code class="language-csharp code-highlight"><span class="code-line"> db<span class="token punctuation">.</span><span class="token function">StringSet</span><span class="token punctuation">(</span>MyListOfObjectFoo_PartitionRed_Page_1<span class="token punctuation">,</span> myListOfDataForPage1<span class="token punctuation">,</span> TimeSpan<span class="token punctuation">.</span><span class="token function">FromMinutes</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
</span></code></pre>
<p>To overcome this issue, Redis offers to be able to store an ordered list that is sorted by a value. What is interesting is that the value can be the same which will produce the same rank. So far, this is exactly the answer of the problem. However, that solution does not fix the problem of having to duplicate the data in the cache. The sorted list solution can query by range, so it&#x27;s interesting for paging, but not by unique key. Thus, it solves only the problem of having desynchronized value since I can push easily in the sorted list an entry in a specify (updated) rank.</p>
<pre class="language-csharp"><code class="language-csharp code-highlight"><span class="code-line"> <span class="token comment">// Initial push db.SortedSetAdd(&quot;MyListOfObjectFoo_PartitionRed_Page_1&quot;, new[] { new SortedSetEntry(&quot;User 1&quot;,100), new SortedSetEntry(&quot;User 2&quot;,99), new SortedSetEntry(&quot;User 3&quot;,99)});</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token comment">// Later when one entity change with a value of 100. This will produce two rank 1. db.SortedSetAdd(&quot;MyListOfObjectFoo&quot;, objectToCache, 100); </span>
</span></code></pre>
<p>This was surprising in many ways. First of all, the main problem was that if you have several same ranks that it is not possible to have a second ordering value from the object. You are stock with value you set which is a double. This allow you to do some mathematics trick but if you would like to sort by alphabetic order than you need to manually in C# do your second sort. I didn&#x27;t go more deep with that solution because of the second problem. The second bigger problem was the performance. To get the information, you use the get by range method.</p>
<pre class="language-csharp"><code class="language-csharp code-highlight"><span class="code-line"> db<span class="token punctuation">.</span><span class="token function">SortedSetRangeByRank</span><span class="token punctuation">(</span><span class="token string">&quot;MyListOfObjectFoo&quot;</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span> 
</span></code></pre>
<p>From that, you need to loop and deserialize all values which is the same tax to pay that we have when caching the whole page in 1 Redis key-value entry. However, <strong>the performance was disastrous</strong>. My average on three run was 1900ms. This was really surprising. I double check everything because it wasn&#x27;t making any sense to me. My initial hypothesis was that this was highly optimized for this kind of scenario -- I was wrong. However, the fault is not Redis. After some investigation, I found that the serialization, done with Json.Net library, got some harder time deserializing 20 times a very complex objects than a list of 20 objects. This is mostly because when serializing a list, if the complex object has already a reference that this one is not serialized again but use a reference system. For example, instead of having a deep object, Json.Net will use &quot;$ref&quot;: &quot;20&quot;. This has a huge impact in performance.</p>
<p>I finally decided to optimize my model classes and have a more light classes for this page. Instead of using a list of objects that has a lot of sub-rich objects, using a simple list of a basic class with properties did an awesome job. The list that was taking 1900ms to get from Redis and deserialize is not taking less than .17 ms. That is right and not a typo, it is less than a single millisecond.</p>
<p>I am still learning how to maximize the use of Redis and so far like the flexibility that it offers compared to Memcached that I used for more than a decade. So far it&#x27;s interesting and will keep you inform with any new optimization I can find. In short term, I think a solution may be to cache not the whole complex object but just a part of it in an aggregate view of objects.</p></div></main><div class="BlogBody_paginationBar__1gsMc"><div class="BlogBody_paginationTitle__H_eFX">Chronological Blog Articles by Page</div><div class="BlogBody_paginationLinks__nk8zd"><a class="" href="/blog/page/1">1</a><a class="" href="/blog/page/2">2</a><a class="" href="/blog/page/3">3</a><a class="" href="/blog/page/4">4</a><a class="" href="/blog/page/5">5</a><a class="" href="/blog/page/6">6</a><a class="" href="/blog/page/7">7</a><a class="" href="/blog/page/8">8</a><a class="" href="/blog/page/9">9</a><a class="" href="/blog/page/10">10</a><a class="" href="/blog/page/11">11</a><a class="" href="/blog/page/12">12</a><a class="" href="/blog/page/13">13</a><a class="" href="/blog/page/14">14</a><a class="" href="/blog/page/15">15</a><a class="" href="/blog/page/16">16</a><a class="" href="/blog/page/17">17</a><a class="" href="/blog/page/18">18</a><a class="" href="/blog/page/19">19</a><a class="" href="/blog/page/20">20</a><a class="" href="/blog/page/21">21</a><a class="" href="/blog/page/22">22</a><a class="" href="/blog/page/23">23</a><a class="" href="/blog/page/24">24</a><a class="" href="/blog/page/25">25</a><a class="" href="/blog/page/26">26</a><a class="" href="/blog/page/27">27</a><a class="" href="/blog/page/28">28</a><a class="" href="/blog/page/29">29</a><a class="" href="/blog/page/30">30</a><a class="" href="/blog/page/31">31</a><a class="" href="/blog/page/32">32</a><a class="" href="/blog/page/33">33</a><a class="" href="/blog/page/34">34</a><a class="" href="/blog/page/35">35</a><a class="" href="/blog/page/36">36</a><a class="" href="/blog/page/37">37</a><a class="" href="/blog/page/38">38</a><a class="" href="/blog/page/39">39</a><a class="" href="/blog/page/40">40</a><a class="" href="/blog/page/41">41</a><a class="" href="/blog/page/42">42</a><a class="" href="/blog/page/43">43</a><a class="" href="/blog/page/44">44</a><a class="" href="/blog/page/45">45</a><a class="" href="/blog/page/46">46</a><a class="" href="/blog/page/47">47</a><a class="" href="/blog/page/48">48</a><a class="" href="/blog/page/49">49</a><a class="" href="/blog/page/50">50</a><a class="" href="/blog/page/51">51</a><a class="" href="/blog/page/52">52</a><a class="" href="/blog/page/53">53</a><a class="" href="/blog/page/54">54</a><a class="" href="/blog/page/55">55</a><a class="" href="/blog/page/56">56</a><a class="" href="/blog/page/57">57</a><a class="" href="/blog/page/58">58</a><a class="" href="/blog/page/59">59</a><a class="" href="/blog/page/60">60</a><a class="" href="/blog/page/61">61</a><a class="" href="/blog/page/62">62</a><a class="" href="/blog/page/63">63</a><a class="" href="/blog/page/64">64</a><a class="" href="/blog/page/65">65</a><a class="" href="/blog/page/66">66</a><a class="" href="/blog/page/67">67</a><a class="" href="/blog/page/68">68</a><a class="" href="/blog/page/69">69</a><a class="" href="/blog/page/70">70</a><a class="" href="/blog/page/71">71</a><a class="" href="/blog/page/72">72</a><a class="" href="/blog/page/73">73</a><a class="" href="/blog/page/74">74</a><a class="" href="/blog/page/75">75</a><a class="" href="/blog/page/76">76</a><a class="" href="/blog/page/77">77</a><a class="" href="/blog/page/78">78</a><a class="" href="/blog/page/79">79</a><a class="" href="/blog/page/80">80</a><a class="" href="/blog/page/81">81</a></div></div></div></div><script src="/_next/static/chunks/webpack-3bbba27772baeadb.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/4cb872a2a77e328a.css\",\"style\"]\n2:HL[\"/_next/static/css/dabd5e64a469b0e1.css\",\"style\"]\n3:HL[\"/_next/static/css/be8a59717d6d5849.css\",\"style\"]\n4:HL[\"/_next/static/css/97e0a79122e618e4.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"5:I[1200,[],\"\"]\n8:I[6405,[],\"\"]\na:I[5337,[],\"\"]\nb:I[156,[\"156\",\"static/chunks/156-2b9f703633e98ef7.js\",\"836\",\"static/chunks/836-7e37630a3372363c.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-2829e3c199d313ca.js\"],\"\"]\nd:I[4688,[],\"\"]\n9:[\"slug\",\"redis-experimentation-with-full-list-cache-against-using-redis-sorted-list\",\"d\"]\ne:[]\n"])</script><script>self.__next_f.push([1,"0:[\"$\",\"$L5\",null,{\"buildId\":\"QX6SFNKyjUBUA95F0Br9H\",\"assetPrefix\":\"\",\"urlParts\":[\"\",\"blog\",\"redis-experimentation-with-full-list-cache-against-using-redis-sorted-list\"],\"initialTree\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"redis-experimentation-with-full-list-cache-against-using-redis-sorted-list\",\"d\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":\\\"redis-experimentation-with-full-list-cache-against-using-redis-sorted-list\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"redis-experimentation-with-full-list-cache-against-using-redis-sorted-list\",\"d\"],{\"children\":[\"__PAGE__\",{},[[\"$L6\",\"$L7\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/be8a59717d6d5849.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/97e0a79122e618e4.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]],null],null]},[null,[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\",\"$9\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/dabd5e64a469b0e1.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"div\",null,{\"className\":\"layout_blogbodystyle___Uc1w\",\"children\":[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]}]],null],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/4cb872a2a77e328a.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"layout_htmlstyle__PseMz\",\"children\":[\"$\",\"body\",null,{\"className\":\"layout_bodystyle__4ncsS\",\"children\":[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"style\":{\"display\":\"flex\",\"alignItems\":\"center\",\"justifyContent\":\"center\",\"height\":\"100vh\"},\"children\":[\"$\",\"div\",null,{\"style\":{\"width\":\"50%\",\"height\":\"20%\",\"backgroundColor\":\"#ffeded\",\"borderRadius\":12,\"padding\":12,\"textAlign\":\"center\"},\"children\":[[\"$\",\"h1\",null,{\"children\":\"Not Found\"}],[\"$\",\"p\",null,{\"children\":\"Could not find requested resource\"}],[\"$\",\"$Lb\",null,{\"href\":\"/\",\"children\":\"Return Home\"}]]}]}],\"notFoundStyles\":[]}]}]}]],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Lc\"],\"globalErrorComponent\":\"$d\",\"missingSlots\":\"$We\"}]\n"])</script><script>self.__next_f.push([1,"f:I[836,[\"156\",\"static/chunks/156-2b9f703633e98ef7.js\",\"836\",\"static/chunks/836-7e37630a3372363c.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-2829e3c199d313ca.js\"],\"Image\"]\n10:T515, in average. The key was determined by the type of list, by the filter attribute and the page number. For example, \"MyListOfObjectXXX_PartitionYYY_Page_1\". The speed was interesting for me, I was aiming around 100 ms but I was satisfy with the result. The time also contains the time to deserialize the object to create a generic list of all 20 results. I count the deserialization process time in my benchmark because I was counting the ORM time to instantiate the object too. My concern with that solution is that every object can change its value at any time. The value does change the rank by consequence. Since I am also caching the data with a separate key for each instance, I duplicate this information in the cache. The size of the cache can be a problem in the long run, but the bigger problem is that the information become desynchronize. In fact, the source of truth is the individual cached version in the system. It looks like this : \"MyData_Key_1\". I set an expiry because this is not the real source of data. I will not invalidate that data like the rest of the software when values change from the entity. I will let them expire and than change it. It means that a user that drill down from the list can get an up-to-date data. This is the cost to pay (so far) for a one minute delay."])</script><script>self.__next_f.push([1,"7:[\"$\",\"div\",null,{\"className\":\"BlogBody_BlogBody__600mT\",\"children\":[[\"$\",\"header\",null,{\"className\":\"BlogBody_siteTitle__f7uyb\",\"children\":\"Patrick Desjardins Blog\"}],[\"$\",\"nav\",null,{\"children\":[\"$\",\"ul\",null,{\"className\":\"BlogBody_navLinks__ZV12t\",\"children\":[\"$\",\"li\",null,{\"className\":\"BlogBody_navLinkItem__Pml2e\",\"children\":[[\"$\",\"$Lb\",null,{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/\",\"children\":\"Main Page\"}],[\"$\",\"$Lb\",null,{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog\",\"children\":\"Blog\"}],[\"$\",\"$Lb\",null,{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/search\",\"children\":\"Search\"}],[[\"$\",\"$Lb\",\"2026\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2026\",\"children\":2026}],[\"$\",\"$Lb\",\"2025\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2025\",\"children\":2025}],[\"$\",\"$Lb\",\"2024\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2024\",\"children\":2024}],[\"$\",\"$Lb\",\"2023\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2023\",\"children\":2023}],[\"$\",\"$Lb\",\"2022\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2022\",\"children\":2022}],[\"$\",\"$Lb\",\"2021\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2021\",\"children\":2021}],[\"$\",\"$Lb\",\"2020\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2020\",\"children\":2020}],[\"$\",\"$Lb\",\"2019\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2019\",\"children\":2019}],[\"$\",\"$Lb\",\"2018\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2018\",\"children\":2018}],[\"$\",\"$Lb\",\"2017\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2017\",\"children\":2017}],[\"$\",\"$Lb\",\"2016\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2016\",\"children\":2016}],[\"$\",\"$Lb\",\"2015\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2015\",\"children\":2015}],[\"$\",\"$Lb\",\"2014\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2014\",\"children\":2014}],[\"$\",\"$Lb\",\"2013\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2013\",\"children\":2013}],[\"$\",\"$Lb\",\"2012\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2012\",\"children\":2012}],[\"$\",\"$Lb\",\"2011\",{\"className\":\"BlogBody_navLinkText__ZtH2y\",\"href\":\"/blog/for/2011\",\"children\":2011}]]]}]}]}],[\"$\",\"div\",null,{\"className\":\"BlogBody_blogPictureContainer__IAbPL\",\"children\":[\"$\",\"$Lf\",null,{\"className\":\"BlogBody_blogTopPicture__L6lao\",\"alt\":\"Patrick Desjardins picture from a conference\",\"src\":\"/images/backgrounds/patrickdesjardins_conference_bw.webp\",\"width\":800,\"height\":260}]}],[\"$\",\"main\",null,{\"className\":\"BlogBody_main__XrdKY\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"BlogBody_heading__bYRBe\",\"children\":\"Redis Experimentation with Full List Cache against using Redis Sorted List\"}],[\"$\",\"div\",null,{\"className\":\"Page_blogPostContainer__AUIcf\",\"children\":[[\"$\",\"p\",null,{\"className\":\"Page_blogPostDate__wVWWB\",\"children\":[\"Posted on: \",\"2015-10-15\"]}],[[\"$\",\"p\",null,{\"children\":[\"I am improving the performance of a system right now with \",[\"$\",\"a\",null,{\"href\":\"http://redis.io/\",\"children\":\"Redis\"}],\" and the library \",[\"$\",\"a\",null,{\"href\":\"https://github.com/StackExchange/StackExchange.Redis\",\"children\":\"StackExchange\"}],\". Onne particular case was that I needed to cache a list of data that are ordered by rank from a value that change often. One requirement is that it's possible that two items can have the same rank. For example:\"]}],\"\\n\",[\"$\",\"pre\",null,{\"className\":\"language-plaintext\",\"children\":[\"$\",\"code\",null,{\"className\":\"language-plaintext code-highlight\",\"children\":[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\" Rank - Data - Value 1 - User 1 - 100 2 - User 2 - 99 3 - User 4 - 99 4 - User 5 - 97 \\n\"}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"The data is in fact a serialized object that contains multiples classes. For not making this article too heavy, I will just use a string. Nevertheless, keep in mind that this is not a simple string unique identifier. The value column is required by Redis when using the \",[\"$\",\"a\",null,{\"href\":\"http://redis.io/commands/zadd\",\"children\":\"Sorted List\"}],\". In reality, this value is inside the data, in a property.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"This is also information that must be paged because the list can go around five thousand entries.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"The first step was to measure the time when using the database. I got an average of \",[\"$\",\"strong\",null,{\"children\":\"264ms\"}],\" per query for 20 items on a set of 200 items. The database contains thousand of entry, the page is using a clause to filter down depending of other criteria defined inside the data (inside the class that we serialize). The next step was to use Redis as a simple cache -- once we get the result of the database we store it for few times. The first hit will have the same average, because it goes to the database, but the subsequent request will go inside Redis instead of the database. This was producing an improvement of 50% faster, with \",[\"$\",\"strong\",null,{\"children\":\"125ms\"}],\"$10\"]}],\"\\n\",[\"$\",\"pre\",null,{\"className\":\"language-csharp\",\"children\":[\"$\",\"code\",null,{\"className\":\"language-csharp code-highlight\",\"children\":[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\" db\",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\".\"}],[\"$\",\"span\",null,{\"className\":\"token function\",\"children\":\"StringSet\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"(\"}],\"MyListOfObjectFoo_PartitionRed_Page_1\",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\" myListOfDataForPage1\",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\" TimeSpan\",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\".\"}],[\"$\",\"span\",null,{\"className\":\"token function\",\"children\":\"FromMinutes\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"token number\",\"children\":\"1\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\")\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\")\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\";\"}],\" \\n\"]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"To overcome this issue, Redis offers to be able to store an ordered list that is sorted by a value. What is interesting is that the value can be the same which will produce the same rank. So far, this is exactly the answer of the problem. However, that solution does not fix the problem of having to duplicate the data in the cache. The sorted list solution can query by range, so it's interesting for paging, but not by unique key. Thus, it solves only the problem of having desynchronized value since I can push easily in the sorted list an entry in a specify (updated) rank.\"}],\"\\n\",[\"$\",\"pre\",null,{\"className\":\"language-csharp\",\"children\":[\"$\",\"code\",null,{\"className\":\"language-csharp code-highlight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\" \",[\"$\",\"span\",null,{\"className\":\"token comment\",\"children\":\"// Initial push db.SortedSetAdd(\\\"MyListOfObjectFoo_PartitionRed_Page_1\\\", new[] { new SortedSetEntry(\\\"User 1\\\",100), new SortedSetEntry(\\\"User 2\\\",99), new SortedSetEntry(\\\"User 3\\\",99)});\"}],\"\\n\"]}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":\"\\n\"}],[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[[\"$\",\"span\",null,{\"className\":\"token comment\",\"children\":\"// Later when one entity change with a value of 100. This will produce two rank 1. db.SortedSetAdd(\\\"MyListOfObjectFoo\\\", objectToCache, 100); \"}],\"\\n\"]}]]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"This was surprising in many ways. First of all, the main problem was that if you have several same ranks that it is not possible to have a second ordering value from the object. You are stock with value you set which is a double. This allow you to do some mathematics trick but if you would like to sort by alphabetic order than you need to manually in C# do your second sort. I didn't go more deep with that solution because of the second problem. The second bigger problem was the performance. To get the information, you use the get by range method.\"}],\"\\n\",[\"$\",\"pre\",null,{\"className\":\"language-csharp\",\"children\":[\"$\",\"code\",null,{\"className\":\"language-csharp code-highlight\",\"children\":[\"$\",\"span\",null,{\"className\":\"code-line\",\"children\":[\" db\",[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\".\"}],[\"$\",\"span\",null,{\"className\":\"token function\",\"children\":\"SortedSetRangeByRank\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"token string\",\"children\":\"\\\"MyListOfObjectFoo\\\"\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token number\",\"children\":\"1\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\",\"}],\" \",[\"$\",\"span\",null,{\"className\":\"token number\",\"children\":\"20\"}],[\"$\",\"span\",null,{\"className\":\"token punctuation\",\"children\":\")\"}],\" \\n\"]}]}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"From that, you need to loop and deserialize all values which is the same tax to pay that we have when caching the whole page in 1 Redis key-value entry. However, \",[\"$\",\"strong\",null,{\"children\":\"the performance was disastrous\"}],\". My average on three run was 1900ms. This was really surprising. I double check everything because it wasn't making any sense to me. My initial hypothesis was that this was highly optimized for this kind of scenario -- I was wrong. However, the fault is not Redis. After some investigation, I found that the serialization, done with Json.Net library, got some harder time deserializing 20 times a very complex objects than a list of 20 objects. This is mostly because when serializing a list, if the complex object has already a reference that this one is not serialized again but use a reference system. For example, instead of having a deep object, Json.Net will use \\\"$ref\\\": \\\"20\\\". This has a huge impact in performance.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"I finally decided to optimize my model classes and have a more light classes for this page. Instead of using a list of objects that has a lot of sub-rich objects, using a simple list of a basic class with properties did an awesome job. The list that was taking 1900ms to get from Redis and deserialize is not taking less than .17 ms. That is right and not a typo, it is less than a single millisecond.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"I am still learning how to maximize the use of Redis and so far like the flexibility that it offers compared to Memcached that I used for more than a decade. So far it's interesting and will keep you inform with any new optimization I can find. In short term, I think a solution may be to cache not the whole complex object but just a part of it in an aggregate view of objects.\"}]]]}]]}],[\"$\",\"div\",null,{\"className\":\"BlogBody_paginationBar__1gsMc\",\"children\":[[\"$\",\"div\",null,{\"className\":\"BlogBody_paginationTitle__H_eFX\",\"children\":\"Chronological Blog Articles by Page\"}],[\"$\",\"div\",null,{\"className\":\"BlogBody_paginationLinks__nk8zd\",\"children\":[[\"$\",\"$Lb\",\"1\",{\"className\":\"\",\"href\":\"/blog/page/1\",\"children\":1}],[\"$\",\"$Lb\",\"2\",{\"className\":\"\",\"href\":\"/blog/page/2\",\"children\":2}],[\"$\",\"$Lb\",\"3\",{\"className\":\"\",\"href\":\"/blog/page/3\",\"children\":3}],[\"$\",\"$Lb\",\"4\",{\"className\":\"\",\"href\":\"/blog/page/4\",\"children\":4}],[\"$\",\"$Lb\",\"5\",{\"className\":\"\",\"href\":\"/blog/page/5\",\"children\":5}],[\"$\",\"$Lb\",\"6\",{\"className\":\"\",\"href\":\"/blog/page/6\",\"children\":6}],[\"$\",\"$Lb\",\"7\",{\"className\":\"\",\"href\":\"/blog/page/7\",\"children\":7}],[\"$\",\"$Lb\",\"8\",{\"className\":\"\",\"href\":\"/blog/page/8\",\"children\":8}],[\"$\",\"$Lb\",\"9\",{\"className\":\"\",\"href\":\"/blog/page/9\",\"children\":9}],[\"$\",\"$Lb\",\"10\",{\"className\":\"\",\"href\":\"/blog/page/10\",\"children\":10}],[\"$\",\"$Lb\",\"11\",{\"className\":\"\",\"href\":\"/blog/page/11\",\"children\":11}],[\"$\",\"$Lb\",\"12\",{\"className\":\"\",\"href\":\"/blog/page/12\",\"children\":12}],[\"$\",\"$Lb\",\"13\",{\"className\":\"\",\"href\":\"/blog/page/13\",\"children\":13}],[\"$\",\"$Lb\",\"14\",{\"className\":\"\",\"href\":\"/blog/page/14\",\"children\":14}],[\"$\",\"$Lb\",\"15\",{\"className\":\"\",\"href\":\"/blog/page/15\",\"children\":15}],[\"$\",\"$Lb\",\"16\",{\"className\":\"\",\"href\":\"/blog/page/16\",\"children\":16}],[\"$\",\"$Lb\",\"17\",{\"className\":\"\",\"href\":\"/blog/page/17\",\"children\":17}],[\"$\",\"$Lb\",\"18\",{\"className\":\"\",\"href\":\"/blog/page/18\",\"children\":18}],[\"$\",\"$Lb\",\"19\",{\"className\":\"\",\"href\":\"/blog/page/19\",\"children\":19}],[\"$\",\"$Lb\",\"20\",{\"className\":\"\",\"href\":\"/blog/page/20\",\"children\":20}],[\"$\",\"$Lb\",\"21\",{\"className\":\"\",\"href\":\"/blog/page/21\",\"children\":21}],[\"$\",\"$Lb\",\"22\",{\"className\":\"\",\"href\":\"/blog/page/22\",\"children\":22}],[\"$\",\"$Lb\",\"23\",{\"className\":\"\",\"href\":\"/blog/page/23\",\"children\":23}],[\"$\",\"$Lb\",\"24\",{\"className\":\"\",\"href\":\"/blog/page/24\",\"children\":24}],[\"$\",\"$Lb\",\"25\",{\"className\":\"\",\"href\":\"/blog/page/25\",\"children\":25}],[\"$\",\"$Lb\",\"26\",{\"className\":\"\",\"href\":\"/blog/page/26\",\"children\":26}],[\"$\",\"$Lb\",\"27\",{\"className\":\"\",\"href\":\"/blog/page/27\",\"children\":27}],[\"$\",\"$Lb\",\"28\",{\"className\":\"\",\"href\":\"/blog/page/28\",\"children\":28}],[\"$\",\"$Lb\",\"29\",{\"className\":\"\",\"href\":\"/blog/page/29\",\"children\":29}],[\"$\",\"$Lb\",\"30\",{\"className\":\"\",\"href\":\"/blog/page/30\",\"children\":30}],[\"$\",\"$Lb\",\"31\",{\"className\":\"\",\"href\":\"/blog/page/31\",\"children\":31}],[\"$\",\"$Lb\",\"32\",{\"className\":\"\",\"href\":\"/blog/page/32\",\"children\":32}],[\"$\",\"$Lb\",\"33\",{\"className\":\"\",\"href\":\"/blog/page/33\",\"children\":33}],[\"$\",\"$Lb\",\"34\",{\"className\":\"\",\"href\":\"/blog/page/34\",\"children\":34}],[\"$\",\"$Lb\",\"35\",{\"className\":\"\",\"href\":\"/blog/page/35\",\"children\":35}],[\"$\",\"$Lb\",\"36\",{\"className\":\"\",\"href\":\"/blog/page/36\",\"children\":36}],[\"$\",\"$Lb\",\"37\",{\"className\":\"\",\"href\":\"/blog/page/37\",\"children\":37}],[\"$\",\"$Lb\",\"38\",{\"className\":\"\",\"href\":\"/blog/page/38\",\"children\":38}],[\"$\",\"$Lb\",\"39\",{\"className\":\"\",\"href\":\"/blog/page/39\",\"children\":39}],[\"$\",\"$Lb\",\"40\",{\"className\":\"\",\"href\":\"/blog/page/40\",\"children\":40}],[\"$\",\"$Lb\",\"41\",{\"className\":\"\",\"href\":\"/blog/page/41\",\"children\":41}],[\"$\",\"$Lb\",\"42\",{\"className\":\"\",\"href\":\"/blog/page/42\",\"children\":42}],[\"$\",\"$Lb\",\"43\",{\"className\":\"\",\"href\":\"/blog/page/43\",\"children\":43}],[\"$\",\"$Lb\",\"44\",{\"className\":\"\",\"href\":\"/blog/page/44\",\"children\":44}],[\"$\",\"$Lb\",\"45\",{\"className\":\"\",\"href\":\"/blog/page/45\",\"children\":45}],[\"$\",\"$Lb\",\"46\",{\"className\":\"\",\"href\":\"/blog/page/46\",\"children\":46}],[\"$\",\"$Lb\",\"47\",{\"className\":\"\",\"href\":\"/blog/page/47\",\"children\":47}],[\"$\",\"$Lb\",\"48\",{\"className\":\"\",\"href\":\"/blog/page/48\",\"children\":48}],[\"$\",\"$Lb\",\"49\",{\"className\":\"\",\"href\":\"/blog/page/49\",\"children\":49}],[\"$\",\"$Lb\",\"50\",{\"className\":\"\",\"href\":\"/blog/page/50\",\"children\":50}],[\"$\",\"$Lb\",\"51\",{\"className\":\"\",\"href\":\"/blog/page/51\",\"children\":51}],[\"$\",\"$Lb\",\"52\",{\"className\":\"\",\"href\":\"/blog/page/52\",\"children\":52}],[\"$\",\"$Lb\",\"53\",{\"className\":\"\",\"href\":\"/blog/page/53\",\"children\":53}],[\"$\",\"$Lb\",\"54\",{\"className\":\"\",\"href\":\"/blog/page/54\",\"children\":54}],[\"$\",\"$Lb\",\"55\",{\"className\":\"\",\"href\":\"/blog/page/55\",\"children\":55}],[\"$\",\"$Lb\",\"56\",{\"className\":\"\",\"href\":\"/blog/page/56\",\"children\":56}],[\"$\",\"$Lb\",\"57\",{\"className\":\"\",\"href\":\"/blog/page/57\",\"children\":57}],[\"$\",\"$Lb\",\"58\",{\"className\":\"\",\"href\":\"/blog/page/58\",\"children\":58}],[\"$\",\"$Lb\",\"59\",{\"className\":\"\",\"href\":\"/blog/page/59\",\"children\":59}],[\"$\",\"$Lb\",\"60\",{\"className\":\"\",\"href\":\"/blog/page/60\",\"children\":60}],[\"$\",\"$Lb\",\"61\",{\"className\":\"\",\"href\":\"/blog/page/61\",\"children\":61}],[\"$\",\"$Lb\",\"62\",{\"className\":\"\",\"href\":\"/blog/page/62\",\"children\":62}],[\"$\",\"$Lb\",\"63\",{\"className\":\"\",\"href\":\"/blog/page/63\",\"children\":63}],[\"$\",\"$Lb\",\"64\",{\"className\":\"\",\"href\":\"/blog/page/64\",\"children\":64}],[\"$\",\"$Lb\",\"65\",{\"className\":\"\",\"href\":\"/blog/page/65\",\"children\":65}],[\"$\",\"$Lb\",\"66\",{\"className\":\"\",\"href\":\"/blog/page/66\",\"children\":66}],[\"$\",\"$Lb\",\"67\",{\"className\":\"\",\"href\":\"/blog/page/67\",\"children\":67}],[\"$\",\"$Lb\",\"68\",{\"className\":\"\",\"href\":\"/blog/page/68\",\"children\":68}],[\"$\",\"$Lb\",\"69\",{\"className\":\"\",\"href\":\"/blog/page/69\",\"children\":69}],[\"$\",\"$Lb\",\"70\",{\"className\":\"\",\"href\":\"/blog/page/70\",\"children\":70}],[\"$\",\"$Lb\",\"71\",{\"className\":\"\",\"href\":\"/blog/page/71\",\"children\":71}],[\"$\",\"$Lb\",\"72\",{\"className\":\"\",\"href\":\"/blog/page/72\",\"children\":72}],[\"$\",\"$Lb\",\"73\",{\"className\":\"\",\"href\":\"/blog/page/73\",\"children\":73}],[\"$\",\"$Lb\",\"74\",{\"className\":\"\",\"href\":\"/blog/page/74\",\"children\":74}],[\"$\",\"$Lb\",\"75\",{\"className\":\"\",\"href\":\"/blog/page/75\",\"children\":75}],[\"$\",\"$Lb\",\"76\",{\"className\":\"\",\"href\":\"/blog/page/76\",\"children\":76}],[\"$\",\"$Lb\",\"77\",{\"className\":\"\",\"href\":\"/blog/page/77\",\"children\":77}],[\"$\",\"$Lb\",\"78\",{\"className\":\"\",\"href\":\"/blog/page/78\",\"children\":78}],[\"$\",\"$Lb\",\"79\",{\"className\":\"\",\"href\":\"/blog/page/79\",\"children\":79}],[\"$\",\"$Lb\",\"80\",{\"className\":\"\",\"href\":\"/blog/page/80\",\"children\":80}],[\"$\",\"$Lb\",\"81\",{\"className\":\"\",\"href\":\"/blog/page/81\",\"children\":81}]]}]]}],null]}]\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Patrick Desjardins Blog - Redis Experimentation with Full List Cache against using Redis Sorted List\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Redis Experimentation with Full List Cache against using Redis Sorted List\"}]]\n6:null\n"])</script></body></html>