{
    "componentChunkName": "component---src-templates-blog-article-tsx",
    "path": "/blog/how-to-transfer-files-between-computers-using-HDMI-Part-2-prototype-code-video",
    "result": {"data":{"mdx":{"frontmatter":{"title":"How to Transfer Files Between Computers Using HDMI (Part 2: Prototype Code Video Creation)","date":"May 16, 2023"},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"How to Transfer Files Between Computers Using HDMI (Part 2: Prototype Code Video Creation)\",\n  \"date\": \"2023-05-16\",\n  \"categories\": [\"rust\", \"hdmi\", \"video\", \"encoding\", \"steganography\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"The second part of transferring a file via video using HDMI will focus on the file-to-video and video-to-file code portions. The following blog article will explain the flaws when communicating via HDMI. However, the prototype in this article works: a video file will contain the data of a file. Not only is the content inside a video file, but it is also inside a video that can run on a machine, and a human can see random colors on the screen. The same Rust script will read the video file and transfer it back into a file, and finally, the file's content is readable and the same as the original.\"), mdx(\"h1\", null, \"Code\"), mdx(\"p\", null, \"The Rust project has a CLI (terminal) application and a library. A user can use \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"cargo\"), \" to use the tool in the secured system. The CLI uses the library portion of the project. The library has two paths: injecting a file into a video and extracting the file from a video. Thus, we have the entire loop.\"), mdx(\"p\", null, \"The code takes a file with an input, asks for a few parameters, and a file to export the video. Here is an example of injecting a text file.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"hdmifiletransporter -m inject -i testAssets/text1.txt -o outputs/out1.avi --fps 30 --height 1080 --width 1920 --size 1\\n\")), mdx(\"p\", null, \"In this example, the file \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"text1.txt\"), \" is injected into a file \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"out1.avi\"), \" that Rust creates using \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"OpenCV\"), \". Other optional parameters, like the resolution and frame per second, can be added. However, these parameters should match the data found by the capture card. In the following article, we will use \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ffmpeg\"), \" to extract the supported resolution and frame per second.\"), mdx(\"p\", null, \"The following command read the video and produce the original file.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"hdmifiletransporter  -m extract -i outputs/out1.avi -o outputs/text1.txt --fps 30 --height 1080 --width 1920 --size 1\\n\")), mdx(\"p\", null, \"The parameters are similar and should match the original value.\"), mdx(\"h1\", null, \"Injection Logic\"), mdx(\"p\", null, \"The injection of the file into a video consists of getting the data into frames. Each frame is a table of the height by the width. The Rust program reads each byte from the file and creates a piece of a pixel with it. Each pixel has three portions: R, G, and B, that is, 1 byte each. It fits characters well (that are not Unicode). The \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"size\"), \" parameter tells how wide and tall each pixel is. Currently, the idea is that we use \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"1\"), \", and every three characters of the file is a single pixel. However, in the future, we could make it bigger to mitigate possible alterations during the communication with HDMI (to be determined). \"), mdx(\"p\", null, \"Because the injected file's content may not fit a full color, we have an end-of-file character we can inject at any time. Also, the end-of-file character fills the rest of the frame to ensure a full frame. The end-of-file is \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"4u8\"), \". Depending on the size of the injected file, a few or many frames are created and put together. The OpenCV library sticks all the frames together and generates a video with our requirements like size, frame per second (fps), etc. The last step is introducing a frame full of red pixels as the first frame. The goal is to have a clear signal that the video is starting. As described in the first article, a computer streams the video in a loop. We can start reading the stream at any time, and we need to generate a video with more than less to ensure the entire file. With a red frame injected, we can figure out where the start and end are.\"), mdx(\"h1\", null, \"Extraction Logic\"), mdx(\"p\", null, \"The steps are mostly the reverse. First, we read the video using OpenCV and looped all frames. Next, we need to find the first frame, which is red. Once we have the frame, we mark it as a \\\"relevant\\\" frame and keep appending frames until we reach another frame. If (and when) a second frame is reached, we know the video restarted and thus did not need anything from that point.\"), mdx(\"p\", null, \"With all the relevant frames in order, we need to loop each pixel using OpenCV methods to extract video data. Each pixel color is then read and translated into a character. Finally, each character is added to a list. The list of characters forms the same file as the original one.\"), mdx(\"h1\", null, \"Code\"), mdx(\"p\", null, \"The code is available on GitHub. However, at this stage, a few critical details are now mentioned that will require changing the presented solution.\"));\n}\n;\nMDXContent.isMDXComponent = true;"}},"pageContext":{"id":"5c3ec5ca-961c-5273-8d75-8534fa2703f6","totalPages":76}},
    "staticQueryHashes": ["3159585216"]}